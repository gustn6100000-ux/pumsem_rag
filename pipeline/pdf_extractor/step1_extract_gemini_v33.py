"""
í•˜ì´ë¸Œë¦¬ë“œ PDF ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ v3.3
- pdfplumber: í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¬´ë£Œ)
- Gemini Vision: í…Œì´ë¸”ë§Œ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ ì¶”ì¶œ
- ëª©ì°¨ ì—°ë™: êµ¬ì¡° ì •ë³´(ì±•í„°/ì„¹ì…˜) ìë™ ì‚½ì…

ìˆ˜ì • ë‚´ì—­ (v3.2 â†’ v3.3):
  - í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ: ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ ê°ì§€ â†’ ê³¼ë„í•œ ë³‘í•© ë°©ì§€
  - í…Œì´ë¸” í¬ë¡­: ì•„ë˜ìª½ íŒ¨ë”© ëŒ€í­ í™•ëŒ€ (ë³¸ë¬¸ ì˜ë¦¼ ë°©ì§€)
  - bbox ê²€ì¦: ë¹„ì •ìƒ ì‘ì€ í…Œì´ë¸” ê°ì§€ â†’ ì „ì²´ í˜ì´ì§€ Gemini í´ë°±
  - Gemini í”„ë¡¬í”„íŠ¸: ì˜ë¦° í…Œì´ë¸”/ë³µì¡í•œ êµ¬ì¡° ëŒ€ì‘ ê°•í™”

í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
pip install pdfplumber google-generativeai pdf2image pillow python-dotenv

ì‚¬ìš©ë²•:
python step1_extract_gemini.py [ì˜µì…˜] <PDFíŒŒì¼ê²½ë¡œ>

ì˜µì…˜:
  --text-only, -t   í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ (ë¹ ë¦„)
  --toc <íŒŒì¼>      ëª©ì°¨ íŒŒì¼ ê²½ë¡œ (êµ¬ì¡° ì •ë³´ ì‚½ì…)
  --pages <ì§€ì •>    ì²˜ë¦¬í•  í˜ì´ì§€ (ì˜ˆ: 10, 16-30, 1,3,5-10, 20-)
"""

import os
import sys
import time
import platform
import logging
from pathlib import Path
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì—ì„œ ì°¾ìŒ)
load_dotenv(Path(__file__).parent / ".env")
import pdfplumber
import google.generativeai as genai
from PIL import Image
from pdf2image import convert_from_path
import toc_parser

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# --- ì„¤ì • ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-3-flash-preview")

if not GEMINI_API_KEY:
    raise ValueError(
        "âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
        "   .env íŒŒì¼ì— GEMINI_API_KEY=your_key í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ê±°ë‚˜\n"
        "   ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”."
    )

# Poppler ê²½ë¡œ (í”Œë«í¼ë³„ ìë™ ë¶„ê¸°)
def _detect_poppler_path() -> str | None:
    """OSì— ë”°ë¼ Poppler ê²½ë¡œë¥¼ ìë™ ê°ì§€"""
    if platform.system() == "Windows":
        candidates = [
            r"C:\poppler\poppler-24.08.0\Library\bin",
            r"C:\Program Files\poppler\Library\bin",
            r"C:\poppler\bin",
        ]
        env_path = os.environ.get("POPPLER_PATH")
        if env_path:
            candidates.insert(0, env_path)
        for path in candidates:
            if os.path.exists(path):
                return path
        logger.warning("Windowsì—ì„œ Poppler ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. POPPLER_PATH í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return None
    else:
        return None

POPPLER_PATH = _detect_poppler_path()

# ë¬´ë£Œ í‹°ì–´ ë”œë ˆì´ (ì´ˆ) - 15 RPM ì œí•œ ê³ ë ¤
FREE_TIER_DELAY = 4

# ë¶€ë¬¸ëª… íŒ¨í„´ (í™•ì¥)
DIVISION_NAMES = (
    "ê³µí†µë¶€ë¬¸|í† ëª©ë¶€ë¬¸|ê±´ì¶•ë¶€ë¬¸|ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸|"
    "ì „ê¸°ë¶€ë¬¸|í†µì‹ ë¶€ë¬¸|ì¡°ê²½ë¶€ë¬¸|ì†Œë°©ë¶€ë¬¸|"
    "ê¸°ê³„ë¶€ë¬¸|ì„¤ë¹„ë¶€ë¬¸|ì „ê¸°ì„¤ë¹„ë¶€ë¬¸"
)

# --- í…Œì´ë¸” bbox ê²€ì¦ ì„¤ì • ---
# í˜ì´ì§€ ë†’ì´ ëŒ€ë¹„ ì´ ë¹„ìœ¨ ë¯¸ë§Œì´ë©´ "í—¤ë”ë§Œ ì¡íŒ" ë¹„ì •ìƒ í…Œì´ë¸”ë¡œ íŒë‹¨
TABLE_MIN_HEIGHT_RATIO = 0.08  # 8%
# í¬ë¡­ ì‹œ ì•„ë˜ìª½ ì¶”ê°€ íŒ¨ë”© (í¬ì¸íŠ¸ ë‹¨ìœ„)
TABLE_BOTTOM_EXTRA_PADDING = 40

# -----------


class UsageTracker:
    """Gemini API ì‚¬ìš©ëŸ‰ ì¶”ì  í´ë˜ìŠ¤"""

    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.call_count = 0

    def add(self, input_tokens: int, output_tokens: int):
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        self.call_count += 1

    @property
    def total_tokens(self) -> int:
        return self.total_input_tokens + self.total_output_tokens

    def summary(self) -> str:
        if self.call_count == 0:
            return "Gemini í˜¸ì¶œ ì—†ìŒ"
        est_cost = (self.total_input_tokens / 1_000_000 * 0.50) + (self.total_output_tokens / 1_000_000 * 1.50)
        return (
            f"ğŸ“ˆ Gemini ì‚¬ìš©ëŸ‰ ìš”ì•½:\n"
            f"   - API í˜¸ì¶œ: {self.call_count}íšŒ\n"
            f"   - ì…ë ¥ í† í°: {self.total_input_tokens:,}\n"
            f"   - ì¶œë ¥ í† í°: {self.total_output_tokens:,}\n"
            f"   - ì´ í† í°: {self.total_tokens:,}\n"
            f"   - ì˜ˆìƒ ë¹„ìš© (ìœ ë£Œ ì‹œ): ${est_cost:.4f} (ì•½ {int(est_cost * 1400)}ì›)"
        )


def parse_page_spec(spec: str, total_pages: int) -> list[int]:
    """
    í˜ì´ì§€ ì§€ì • ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ 0-indexed í˜ì´ì§€ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.
    
    ì§€ì› í˜•ì‹:
    - "10" â†’ 1~10 í˜ì´ì§€ (ê¸°ì¡´ í˜¸í™˜)
    - "5-15" â†’ 5~15 í˜ì´ì§€
    - "20-" â†’ 20~ë
    - "-10" â†’ 1~10 í˜ì´ì§€  
    - "1,3,5-10" â†’ 1, 3, 5~10 í˜ì´ì§€
    """
    spec = spec.strip()
    indices = set()
    
    parts = [p.strip() for p in spec.split(',') if p.strip()]
    
    for part in parts:
        if '-' in part:
            if part.startswith('-'):
                end = int(part[1:])
                start = 1
            elif part.endswith('-'):
                start = int(part[:-1])
                end = total_pages
            else:
                start_str, end_str = part.split('-', 1)
                start = int(start_str)
                end = int(end_str)
            
            for p in range(start, end + 1):
                if 1 <= p <= total_pages:
                    indices.add(p - 1)
        else:
            p = int(part)
            if len(parts) == 1 and ',' not in spec and '-' not in spec:
                for i in range(min(p, total_pages)):
                    indices.add(i)
            else:
                if 1 <= p <= total_pages:
                    indices.add(p - 1)
    
    return sorted(indices)


# ì „ì—­ íŠ¸ë˜ì»¤ ì¸ìŠ¤í„´ìŠ¤
tracker = UsageTracker()

# Gemini API ì´ˆê¸°í™”
genai.configure(api_key=GEMINI_API_KEY)

# ì•ˆì „ ì„¤ì • (í•„í„° ì™„í™”)
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]


def _parse_usage_metadata(response) -> tuple[int, int]:
    """ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ"""
    input_tokens = 0
    output_tokens = 0
    if hasattr(response, 'usage_metadata') and response.usage_metadata:
        input_tokens = getattr(response.usage_metadata, 'prompt_token_count', 0) or 0
        output_tokens = getattr(response.usage_metadata, 'candidates_token_count', 0) or 0
    return input_tokens, output_tokens


def extract_page_footer_metadata(text: str) -> dict:
    """í˜ì´ì§€ í•˜ë‹¨ í‘¸í„°ì—ì„œ ë¶€ë¬¸ëª…ê³¼ ì¥ ì •ë³´ ì¶”ì¶œ"""
    import re
    
    result = {"chapter": "", "section": "", "page_num": 0}
    
    if not text:
        return result
    
    match = re.search(r'(ì œ\d+ì¥\s*[ê°€-í£]+(?:\s+[ê°€-í£]+)*)\s+\|?\s*(\d+)(?:\s|$)', text)
    if match:
        result["section"] = match.group(1).strip()
        result["page_num"] = int(match.group(2))
    
    pattern = rf'(\d+)\s+({DIVISION_NAMES})'
    match = re.search(pattern, text)
    if match:
        page = int(match.group(1))
        chapter = match.group(2)
        if result["page_num"] == 0:
            result["page_num"] = page
        result["chapter"] = chapter
    
    return result


def detect_tables(page) -> list:
    """í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ìœ„ì¹˜(bbox) ëª©ë¡ ë°˜í™˜"""
    try:
        tables = page.find_tables()
        return [table.bbox for table in tables]
    except Exception as e:
        logger.warning(f"í…Œì´ë¸” ê°ì§€ ì‹¤íŒ¨: {e}")
        return []


def validate_and_fix_table_bboxes(table_bboxes: list, page_height: float, page_width: float) -> tuple[list, bool]:
    """
    [ê°œì„ 3] í…Œì´ë¸” bbox ê²€ì¦ ë° ë³´ì •
    
    - ë¹„ì •ìƒì ìœ¼ë¡œ ì‘ì€ bbox (í—¤ë”ë§Œ ì¡íŒ ê²½ìš°) ê°ì§€
    - ì•„ë˜ìª½ìœ¼ë¡œ bbox í™•ì¥ ì‹œë„
    
    Returns:
        (ë³´ì •ëœ bboxes, ì „ì²´í˜ì´ì§€ í´ë°± í•„ìš” ì—¬ë¶€)
    """
    if not table_bboxes:
        return table_bboxes, False
    
    fixed_bboxes = []
    needs_fullpage_fallback = False
    
    for i, bbox in enumerate(table_bboxes):
        x0, y0, x1, y1 = bbox
        table_height = y1 - y0
        height_ratio = table_height / page_height
        
        if height_ratio < TABLE_MIN_HEIGHT_RATIO:
            # ë¹„ì •ìƒì ìœ¼ë¡œ ì‘ì€ í…Œì´ë¸” â€” í—¤ë”ë§Œ ì¡í˜”ì„ ê°€ëŠ¥ì„±
            logger.info(
                f"í…Œì´ë¸” {i+1} bbox ë†’ì´ ë¹„ì •ìƒ ({height_ratio:.1%}, "
                f"{table_height:.0f}pt / {page_height:.0f}pt)"
            )
            
            # ë‹¤ìŒ í…Œì´ë¸”ì´ ìˆìœ¼ë©´ ê·¸ ìœ„ê¹Œì§€, ì—†ìœ¼ë©´ í˜ì´ì§€ í•˜ë‹¨ 80%ê¹Œì§€ í™•ì¥
            if i + 1 < len(table_bboxes):
                next_top = table_bboxes[i + 1][1]
                new_y1 = next_top - 5  # ë‹¤ìŒ í…Œì´ë¸” ì§ì „ê¹Œì§€
            else:
                new_y1 = min(page_height * 0.85, page_height - 30)
            
            new_height = new_y1 - y0
            new_ratio = new_height / page_height
            
            if new_ratio > 0.5:
                # í™•ì¥í•´ë„ í˜ì´ì§€ ì ˆë°˜ ì´ìƒì´ë©´ ì „ì²´ í˜ì´ì§€ í´ë°±
                logger.info(f"  â†’ í™•ì¥ ì‹œ í˜ì´ì§€ {new_ratio:.0%} ì°¨ì§€ â†’ ì „ì²´ í˜ì´ì§€ Gemini ì²˜ë¦¬")
                needs_fullpage_fallback = True
                break
            else:
                logger.info(f"  â†’ bbox ì•„ë˜ë¡œ í™•ì¥: {table_height:.0f}pt â†’ {new_height:.0f}pt")
                fixed_bboxes.append((x0, y0, x1, new_y1))
        else:
            fixed_bboxes.append(bbox)
    
    return fixed_bboxes, needs_fullpage_fallback


def extract_text_outside_tables(page, table_bboxes: list) -> str:
    """í…Œì´ë¸” ì˜ì—­ì„ ì œì™¸í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    try:
        if table_bboxes:
            filtered_page = page
            failed_bboxes = []
            for bbox in table_bboxes:
                try:
                    filtered_page = filtered_page.outside_bbox(bbox)
                except Exception as e:
                    logger.warning(f"outside_bbox ì‹¤íŒ¨ (bbox={bbox}): {e}")
                    failed_bboxes.append(bbox)
            
            if len(failed_bboxes) == len(table_bboxes):
                logger.warning("ëª¨ë“  í…Œì´ë¸” ì˜ì—­ ì œì™¸ ì‹¤íŒ¨, ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                text = page.extract_text()
            else:
                text = filtered_page.extract_text()
        else:
            text = page.extract_text()
        
        return text.strip() if text else ""
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""


def extract_text_regions_with_positions(page, table_bboxes: list) -> list[dict]:
    """
    í…ìŠ¤íŠ¸ë¥¼ í…Œì´ë¸” ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì˜ì—­ì˜ yì¢Œí‘œì™€ í•¨ê»˜ ë°˜í™˜.
    """
    if not table_bboxes:
        text = page.extract_text()
        if text and text.strip():
            return [{"y": 0, "type": "text", "content": format_text_with_linebreaks(text.strip())}]
        return []
    
    sorted_bboxes = sorted(table_bboxes, key=lambda b: b[1])
    
    page_width = page.width
    page_height = page.height
    
    text_regions = []
    
    boundaries = []
    boundaries.append(0)
    for bbox in sorted_bboxes:
        boundaries.append(bbox[1])
        boundaries.append(bbox[3])
    boundaries.append(page_height)
    
    for i in range(0, len(boundaries) - 1, 2):
        top = boundaries[i]
        bottom = boundaries[i + 1] if i + 1 < len(boundaries) else page_height
        
        if bottom - top < 5:
            continue
        
        try:
            crop_bbox = (0, top, page_width, bottom)
            cropped = page.within_bbox(crop_bbox)
            text = cropped.extract_text()
            if text and text.strip():
                formatted = format_text_with_linebreaks(text.strip())
                if formatted:
                    text_regions.append({
                        "y": top,
                        "type": "text",
                        "content": formatted
                    })
        except Exception as e:
            logger.debug(f"í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ ì‹¤íŒ¨ (top={top:.0f}, bottom={bottom:.0f}): {e}")
    
    return text_regions


def _is_sentence_ending(line: str) -> bool:
    """
    [ê°œì„ 1] í•œêµ­ì–´ ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ ê°ì§€
    
    ì¤„ì´ ë¬¸ì¥ ì¢…ê²°ë¡œ ëë‚˜ë©´ True â†’ ë‹¤ìŒ ì¤„ì„ ì´ì–´ë¶™ì´ì§€ ì•ŠìŒ
    """
    import re
    
    line = line.rstrip()
    if not line:
        return False
    
    # í•œêµ­ì–´ ë¬¸ì¥ ì¢…ê²° íŒ¨í„´
    # ë‹¤. í•œë‹¤. ëœë‹¤. ìˆë‹¤. ì—†ë‹¤. ê°™ë‹¤. í•œë‹¤. ì•ŠëŠ”ë‹¤. ì´ë‹¤. 
    # ~ìš”. ~ì„. ~ìŒ. ~í•¨. ~ë¨.
    # ~ê²ƒ (ì¢…ê²° ëª…ì‚¬)
    # ) ë˜ëŠ” ] ë¡œ ëë‚˜ëŠ” ê²½ìš° (ê´„í˜¸ ë‹«í˜)
    # : ë¡œ ëë‚˜ëŠ” ê²½ìš° (í•­ëª© ì†Œê°œ)
    ending_patterns = [
        r'ë‹¤\.$',           # ~ë‹¤.
        r'ë‹¤\)$',           # ~ë‹¤)
        r'ë‹¤"$',           # ~ë‹¤"
        r'[ìš”ì„ìŒí•¨ë¨]\.$',  # ~ìš”. ~ì„. ~ìŒ. ~í•¨. ~ë¨.
        r'ê²ƒ$',            # ~ê²ƒ
        r'[\.]\s*$',       # . ìœ¼ë¡œ ëë‚¨
        r'\)$',            # ) ë¡œ ëë‚¨
        r'\]$',            # ] ë¡œ ëë‚¨
        r':$',             # : ë¡œ ëë‚¨
    ]
    
    for pattern in ending_patterns:
        if re.search(pattern, line):
            return True
    
    return False


def format_text_with_linebreaks(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ - PDF ì¤„ë°”ê¿ˆ ë³‘í•© ë° ì •ë¦¬
    
    [ê°œì„ 1] ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ ê°ì§€ + ì¤„ ê¸¸ì´ ì œí•œìœ¼ë¡œ ê³¼ë„í•œ ë³‘í•© ë°©ì§€
    """
    import re
    
    if not text:
        return ""
    
    # 0. ì„¹ì…˜ ì œëª© íŒ¨í„´ ì•ì— ì¤„ë°”ê¿ˆ ì‚½ì… (ë³‘í•© ì „ ì²˜ë¦¬)
    text = re.sub(r'(?<=[^\n])(\d+-\d+-\d+\s+)', r'\n\n\1', text)
    text = re.sub(r'(?<=[ë‹¤\.\)\]]) (\d+\.\s+)', r'\n\1', text)
    text = re.sub(r'(?<=[ë‹¤\.\)\]]) ([ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\.\s+)', r'\n\1', text)
    text = re.sub(r'(?<=[^\n])(\[ì£¼\])', r'\n\n\1', text)
    text = re.sub(r'(?<=[ë‹¤\.\)\]]) ([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³])', r'\n\1', text)
    
    # ë¶€ë¬¸ëª… íŒ¨í„´ ë¶„ë¦¬ (ì„¹ì…˜ ID X-Y-Zì˜ ë§ˆì§€ë§‰ ìˆ«ìëŠ” ì œì™¸)
    text = re.sub(rf'(?<![-\d])(\d+\s*(?:{DIVISION_NAMES}|ì ìš©ê¸°ì¤€|ì œ\d+ì¥))', r'\n\1', text)
    
    # 1. PDF ì¤„ë°”ê¿ˆìœ¼ë¡œ ëŠê¸´ ë¬¸ì¥ ë³‘í•©
    text = re.sub(r'([ê°€-í£])\n([ê°€-í£]{0,2}ë‹¤[\.\\, ])', r'\1\2', text)
    text = re.sub(r'([ê°€-í£])\n(ë‹¤)$', r'\1\2', text, flags=re.MULTILINE)
    
    # 2. ë‹¨ì¼ ì¤„ë°”ê¿ˆ â†’ ê³µë°± ë³€í™˜ (ê°œì„ : ë¬¸ì¥ ì¢…ê²°/ì¤„ ê¸¸ì´ ê°ì§€)
    lines = text.split('\n')
    result = []
    for line in lines:
        stripped = line.strip()
        if not stripped:
            result.append('')
            continue
        
        # ë²ˆí˜¸/ê¸°í˜¸ë¡œ ì‹œì‘í•˜ë©´ í•­ìƒ ìƒˆ ì¤„ ìœ ì§€
        if re.match(
            rf'^(\d+[-.]|[ê°€-í•˜]\.|[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³]|\[ì£¼\]|\d+-\d+-\d+|\d+\s*(?:{DIVISION_NAMES}|ì ìš©ê¸°ì¤€|ì œ\d+ì¥))',
            stripped
        ):
            result.append(stripped)
        elif result and result[-1]:
            prev_line = result[-1]
            
            # [ê°œì„ 1] ì´ì „ ì¤„ì´ ë¬¸ì¥ ì¢…ê²°ì´ë©´ ì´ì–´ë¶™ì´ì§€ ì•ŠìŒ
            if _is_sentence_ending(prev_line):
                result.append(stripped)
            # [ê°œì„ 1] ì´ì „ ì¤„ì´ ì´ë¯¸ 80ì ì´ìƒì´ë©´ ì´ì–´ë¶™ì´ì§€ ì•ŠìŒ
            elif len(prev_line) >= 80:
                result.append(stripped)
            else:
                result[-1] = prev_line + ' ' + stripped
        else:
            result.append(stripped)
    
    text = '\n'.join(result)
    
    # 3. ì—°ì† ì¤„ë°”ê¿ˆ ì •ë¦¬ (3ê°œ ì´ìƒ â†’ 2ê°œë¡œ)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # 4. ì—°ì† ê³µë°± ì •ë¦¬
    text = re.sub(r' {2,}', ' ', text)
    
    return text.strip()


def crop_table_image(
    page_image: Image.Image, 
    bbox: tuple, 
    page_height: float, 
    page_width: float,
    extended: bool = False
) -> Image.Image:
    """
    í…Œì´ë¸” ì˜ì—­ì„ ì´ë¯¸ì§€ë¡œ í¬ë¡­
    
    [ê°œì„ 2] extended=True ì‹œ ì•„ë˜ìª½ íŒ¨ë”©ì„ ëŒ€í­ í™•ëŒ€í•˜ì—¬ ë³¸ë¬¸ ì˜ë¦¼ ë°©ì§€
    """
    x0, y0, x1, y1 = bbox
    
    scale_x = page_image.width / page_width
    scale_y = page_image.height / page_height
    
    img_x0 = int(x0 * scale_x)
    img_y0 = int(y0 * scale_y)
    img_x1 = int(x1 * scale_x)
    img_y1 = int(y1 * scale_y)
    
    # ê¸°ë³¸ íŒ¨ë”©
    padding_x = 10
    padding_top = 10
    
    # [ê°œì„ 2] ì•„ë˜ìª½ íŒ¨ë”©: ê¸°ë³¸ 10 â†’ í™•ì¥ ì‹œ TABLE_BOTTOM_EXTRA_PADDING ì¶”ê°€
    if extended:
        padding_bottom = int(TABLE_BOTTOM_EXTRA_PADDING * scale_y)
    else:
        padding_bottom = 10
    
    img_x0 = max(0, img_x0 - padding_x)
    img_y0 = max(0, img_y0 - padding_top)
    img_x1 = min(page_image.width, img_x1 + padding_x)
    img_y1 = min(page_image.height, img_y1 + padding_bottom)
    
    return page_image.crop((img_x0, img_y0, img_x1, img_y1))


def extract_table_with_gemini(image: Image.Image, table_num: int) -> tuple[str, int, int]:
    """
    í…Œì´ë¸” ì´ë¯¸ì§€ë¥¼ Gemini Visionìœ¼ë¡œ íŒŒì‹±
    
    [ê°œì„ 4] í”„ë¡¬í”„íŠ¸ ê°•í™”: ì˜ë¦° í…Œì´ë¸”/ë³µì¡í•œ êµ¬ì¡° ëŒ€ì‘
    """
    model = genai.GenerativeModel(GEMINI_MODEL)
    
    # [ê°œì„ 4] í”„ë¡¬í”„íŠ¸ ê°•í™”
    prompt = """ì´ ê±´ì„¤ ê´€ë ¨ í…Œì´ë¸” ì´ë¯¸ì§€ë¥¼ HTML í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë³€í™˜í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ë°˜ë“œì‹œ <table>, <thead>, <tbody> íƒœê·¸ë¥¼ ëª¨ë‘ ì‚¬ìš©
2. ë³‘í•©ëœ ì…€ì€ rowspan/colspan ì •í™•íˆ í‘œí˜„
3. í—¤ë”ê°€ ì—¬ëŸ¬ ì¤„ì´ë©´ <thead>ì— ëª¨ë‘ í¬í•¨
4. <tbody>ì— ëª¨ë“  ë°ì´í„° í–‰ì„ ë¹ ì§ì—†ì´ í¬í•¨ â€” ë³¸ë¬¸ í–‰ì„ ì ˆëŒ€ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”
5. ìˆ«ì, ë‹¨ìœ„, ê·œê²©ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì •í™•íˆ ì¶”ì¶œ
6. ì´ë¯¸ì§€ í•˜ë‹¨ì´ ì˜ë ¤ ë³´ì—¬ë„, ë³´ì´ëŠ” ëª¨ë“  í–‰ì„ ëê¹Œì§€ ì¶”ì¶œ
7. ì„¤ëª…ì´ë‚˜ ì½”ë“œë¸”ë¡ ì—†ì´ <table>...</table> HTMLë§Œ ì¶œë ¥
"""
    
    time.sleep(FREE_TIER_DELAY)
    
    max_retries = 2
    for attempt in range(max_retries):
        try:
            response = model.generate_content([prompt, image], safety_settings=SAFETY_SETTINGS)
            
            input_tokens, output_tokens = _parse_usage_metadata(response)
            tracker.add(input_tokens, output_tokens)
            
            result = response.text.strip()
            
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if result.startswith("```"):
                lines = result.split("\n")
                if lines[-1].strip() == "```":
                    result = "\n".join(lines[1:-1])
                else:
                    result = "\n".join(lines[1:])
            
            print(f"      âœ… í…Œì´ë¸” {table_num} ì™„ë£Œ (í† í°: {input_tokens}+{output_tokens})")
            return result, input_tokens, output_tokens
        
        except Exception as e:
            error_str = str(e)
            
            if "429" in error_str and attempt < max_retries - 1:
                print(f"      âš ï¸ í• ë‹¹ëŸ‰ ì´ˆê³¼! 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})...")
                time.sleep(60)
                continue
            
            logger.error(f"í…Œì´ë¸” {table_num} ì¶”ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
            return f"<!-- í…Œì´ë¸” {table_num} ì¶”ì¶œ ì‹¤íŒ¨: {error_str[:100]} -->", 0, 0
    
    return f"<!-- í…Œì´ë¸” {table_num} ì¶”ì¶œ ì‹¤íŒ¨ -->", 0, 0


def extract_full_page_with_gemini(image: Image.Image, page_num: int) -> tuple[str, int, int]:
    """
    í˜ì´ì§€ ì „ì²´ë¥¼ Geminië¡œ íŒŒì‹±
    
    [ê°œì„ 3] bbox ê²€ì¦ ì‹¤íŒ¨ ì‹œ í´ë°±ìœ¼ë¡œ ì‚¬ìš©
    [ê°œì„ 4] í”„ë¡¬í”„íŠ¸ ê°•í™”
    """
    model = genai.GenerativeModel(GEMINI_MODEL)
    
    # [ê°œì„ 4] ì „ì²´ í˜ì´ì§€ í”„ë¡¬í”„íŠ¸ ê°•í™”
    prompt = """ì´ ê±´ì„¤ ê´€ë ¨ ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ + HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. í…Œì´ë¸”ì€ ë°˜ë“œì‹œ HTML <table> í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   - <thead>ì™€ <tbody>ë¥¼ ë°˜ë“œì‹œ êµ¬ë¶„
   - ëª¨ë“  ë°ì´í„° í–‰ì„ ë¹ ì§ì—†ì´ <tbody>ì— í¬í•¨
   - ë³‘í•© ì…€ì€ rowspan/colspan ì‚¬ìš©
2. ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹
3. ìˆ«ì, ë‹¨ìœ„, ê·œê²©ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì •í™•íˆ ì¶”ì¶œ
4. í…Œì´ë¸” ì•ë’¤ í…ìŠ¤íŠ¸ë„ ëª¨ë‘ í¬í•¨
5. ì„¤ëª… ì—†ì´ ë³€í™˜ ê²°ê³¼ë§Œ ì¶œë ¥
"""
    
    time.sleep(FREE_TIER_DELAY)
    
    try:
        response = model.generate_content([prompt, image], safety_settings=SAFETY_SETTINGS)
        
        input_tokens, output_tokens = _parse_usage_metadata(response)
        tracker.add(input_tokens, output_tokens)
        
        print(f"    âœ… ì „ì²´ í˜ì´ì§€ {page_num} Gemini ì™„ë£Œ (í† í°: {input_tokens}+{output_tokens})")
        return response.text.strip(), input_tokens, output_tokens
        
    except Exception as e:
        logger.error(f"ì „ì²´ í˜ì´ì§€ {page_num} ì˜¤ë¥˜: {e}")
        return "", 0, 0


def _build_section_markers(page_sections: list) -> str:
    """ì„¹ì…˜ ë§ˆì»¤ ë¬¸ìì—´ ìƒì„±"""
    if not page_sections:
        return ""
    markers = ""
    for sec in page_sections:
        markers += f"<!-- SECTION: {sec['id']} | {sec['title']} | ë¶€ë¬¸:{sec['chapter']} | ì¥:{sec['section']} -->\n"
    markers += "\n"
    return markers


def _build_page_marker(page_num: int, current_context: dict) -> str:
    """í˜ì´ì§€ ë§ˆì»¤ ë¬¸ìì—´ ìƒì„±"""
    context_str = ""
    if current_context.get("chapter") or current_context.get("section"):
        parts = [p for p in [current_context.get("chapter", ""), current_context.get("section", "")] if p]
        context_str = f" | {' > '.join(parts)}" if parts else ""
    return f"<!-- PAGE {page_num}{context_str} -->\n\n"


def _build_context_marker(active_section: dict) -> str:
    """í˜„ì¬ í™œì„± ì„¹ì…˜ì— ëŒ€í•œ CONTEXT ë§ˆì»¤ ìƒì„± (ì„¹ì…˜ì´ ê³„ì†ë˜ëŠ” í˜ì´ì§€ìš©)"""
    if not active_section:
        return ""
    return f"<!-- CONTEXT: {active_section['id']} | {active_section['title']} | ë¶€ë¬¸:{active_section['chapter']} | ì¥:{active_section['section']} -->\n\n"


def _process_toc_context(
    full_text: str,
    page_map: dict,
    current_context: dict
) -> tuple[dict, list, int]:
    """í‘¸í„°/ëª©ì°¨ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
    footer_meta = extract_page_footer_metadata(full_text)
    pdf_page_num = footer_meta.get("page_num", 0)
    
    if footer_meta.get("chapter"):
        current_context["chapter"] = footer_meta["chapter"]
    if footer_meta.get("section"):
        current_context["section"] = footer_meta["section"]
    
    page_sections = []
    if pdf_page_num > 0 and page_map:
        current_context = toc_parser.get_current_context(pdf_page_num, page_map, current_context)
        page_sections = current_context.get("sections", [])
    
    return current_context, page_sections, pdf_page_num


def process_pdf_text_only(pdf_path: str, section_map: dict = None, page_indices: list[int] = None) -> str:
    """PDFë¥¼ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œë¡œ ì²˜ë¦¬"""
    print(f"ğŸ“„ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œë¡œ PDF ì²˜ë¦¬ ì¤‘: {pdf_path}")
    
    page_map = {}
    if section_map:
        page_map = toc_parser.build_page_to_sections_map(section_map)
        print(f"    ğŸ“š í˜ì´ì§€ ê¸°ë°˜ ëª©ì°¨ ë§¤í•‘: {len(page_map)}ê°œ í˜ì´ì§€")
    
    current_context = {"chapter": "", "section": "", "sections": []}
    markdown_output = ""
    
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        
        if page_indices is None:
            indices_to_process = list(range(total_pages))
        else:
            indices_to_process = [i for i in page_indices if i < total_pages]
        
        print(f"ğŸ“„ ì´ {total_pages}í˜ì´ì§€ ì¤‘ {len(indices_to_process)}í˜ì´ì§€ ì²˜ë¦¬ ì˜ˆì •")
        
        for idx, i in enumerate(indices_to_process):
            page = pdf.pages[i]
            page_num = i + 1
            print(f"\nğŸ”„ í˜ì´ì§€ {page_num} ({idx+1}/{len(indices_to_process)}) ì²˜ë¦¬ ì¤‘...")
            
            text = page.extract_text() or ""
            
            if section_map:
                current_context, page_sections, pdf_page_num = _process_toc_context(
                    text, page_map, current_context
                )
                if page_sections:
                    print(f"    ğŸ“– ëª©ì°¨ ë§¤í•‘: {len(page_sections)}ê°œ ì„¹ì…˜ (PDF í˜ì´ì§€ {pdf_page_num})")
            else:
                page_sections = []
                pdf_page_num = 0
            
            markdown_output += _build_page_marker(page_num, current_context)
            
            if page_sections:
                # ìƒˆ ì„¹ì…˜ ì‹œì‘ â†’ SECTION ë§ˆì»¤
                markdown_output += _build_section_markers(page_sections)
            elif section_map and pdf_page_num > 0:
                # ì„¹ì…˜ ê³„ì† â†’ CONTEXT ë§ˆì»¤
                active_section = toc_parser.get_active_section(pdf_page_num, section_map)
                if active_section:
                    markdown_output += _build_context_marker(active_section)
                    print(f"    ğŸ“– ì»¨í…ìŠ¤íŠ¸ ìœ ì§€: {active_section['id']} (PDF í˜ì´ì§€ {pdf_page_num})")
            
            if text:
                formatted_text = format_text_with_linebreaks(text)
                markdown_output += formatted_text + "\n\n"
                print(f"    âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(text):,} chars)")
            else:
                print(f"    âš ï¸ í…ìŠ¤íŠ¸ ì—†ìŒ")
    
    return markdown_output


def process_pdf(pdf_path: str, section_map: dict = None, page_indices: list[int] = None) -> str:
    """
    PDFë¥¼ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
    
    [ê°œì„ 2] í…Œì´ë¸” í¬ë¡­ ì‹œ ì•„ë˜ìª½ íŒ¨ë”© í™•ëŒ€
    [ê°œì„ 3] bbox ê²€ì¦ â†’ ë¹„ì •ìƒ ì‹œ ì „ì²´ í˜ì´ì§€ Gemini í´ë°±
    """
    print(f"ğŸ“„ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ PDF ì²˜ë¦¬ ì¤‘: {pdf_path}")

    markdown_output = ""

    page_map = {}
    if section_map:
        page_map = toc_parser.build_page_to_sections_map(section_map)
        print(f"    ğŸ“š í˜ì´ì§€ ê¸°ë°˜ ëª©ì°¨ ë§¤í•‘: {len(page_map)}ê°œ í˜ì´ì§€")

    current_context = {"chapter": "", "section": "", "sections": []}

    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)

        if page_indices is None:
            indices_to_process = list(range(total_pages))
        else:
            indices_to_process = [i for i in page_indices if i < total_pages]

        print(f"ğŸ“„ ì´ {total_pages}í˜ì´ì§€ ì¤‘ {len(indices_to_process)}í˜ì´ì§€ ì²˜ë¦¬ ì˜ˆì •")

        for idx, i in enumerate(indices_to_process):
            plumber_page = pdf.pages[i]
            page_num = i + 1
            print(f"\nğŸ”„ í˜ì´ì§€ {page_num} ({idx+1}/{len(indices_to_process)}) ì²˜ë¦¬ ì¤‘...")
            
            full_text = plumber_page.extract_text() or ""
            
            current_context, page_sections, pdf_page_num = _process_toc_context(
                full_text, page_map, current_context
            )
            if page_sections:
                print(f"    ğŸ“– ëª©ì°¨ ë§¤í•‘: {len(page_sections)}ê°œ ì„¹ì…˜ (PDF í˜ì´ì§€ {pdf_page_num})")
            
            markdown_output += _build_page_marker(page_num, current_context)
            
            if page_sections:
                # ìƒˆ ì„¹ì…˜ ì‹œì‘ â†’ SECTION ë§ˆì»¤
                markdown_output += _build_section_markers(page_sections)
            elif section_map and pdf_page_num > 0:
                # ì„¹ì…˜ ê³„ì† â†’ CONTEXT ë§ˆì»¤
                active_section = toc_parser.get_active_section(pdf_page_num, section_map)
                if active_section:
                    markdown_output += _build_context_marker(active_section)
                    print(f"    ğŸ“– ì»¨í…ìŠ¤íŠ¸ ìœ ì§€: {active_section['id']} (PDF í˜ì´ì§€ {pdf_page_num})")

            
            # 1. í…Œì´ë¸” ê°ì§€
            table_bboxes = detect_tables(plumber_page)
            print(f"    ğŸ“Š í…Œì´ë¸” {len(table_bboxes)}ê°œ ê°ì§€")
            
            # 2. í…Œì´ë¸” ë¯¸ê°ì§€ â†’ í…ìŠ¤íŠ¸ë§Œ (ì´ë¯¸ì§€ ë³€í™˜ ë¶ˆí•„ìš”)
            if len(table_bboxes) == 0:
                text = plumber_page.extract_text()
                if text:
                    formatted_text = format_text_with_linebreaks(text)
                    markdown_output += formatted_text + "\n\n"
                continue

            # 3. í…Œì´ë¸”ì´ ìˆìœ¼ë¯€ë¡œ í•´ë‹¹ í˜ì´ì§€ë§Œ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            try:
                convert_kwargs = {"pdf_path": pdf_path, "first_page": page_num, "last_page": page_num}
                if POPPLER_PATH:
                    convert_kwargs["poppler_path"] = POPPLER_PATH
                page_image = convert_from_path(**convert_kwargs)[0]
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page_num} ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
                print(f"    âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ")
                text = plumber_page.extract_text()
                if text:
                    formatted_text = format_text_with_linebreaks(text)
                    markdown_output += formatted_text + "\n\n"
                continue

            # [ê°œì„ 3] bbox ê²€ì¦ ë° ë³´ì •
            fixed_bboxes, needs_fallback = validate_and_fix_table_bboxes(
                table_bboxes, plumber_page.height, plumber_page.width
            )
            
            # [ê°œì„ 3] ì „ì²´ í˜ì´ì§€ í´ë°±
            if needs_fallback:
                print(f"    ğŸ”„ ë¹„ì •ìƒ í…Œì´ë¸” ê°ì§€ â†’ ì „ì²´ í˜ì´ì§€ Gemini ì²˜ë¦¬ë¡œ ì „í™˜")
                page_content, _, _ = extract_full_page_with_gemini(page_image, page_num)
                if page_content:
                    markdown_output += page_content + "\n\n"
                continue
            
            if fixed_bboxes != table_bboxes:
                print(f"    ğŸ”§ í…Œì´ë¸” bbox ë³´ì •ë¨: {len(table_bboxes)}ê°œ â†’ {len(fixed_bboxes)}ê°œ")
            
            # 3. í…ìŠ¤íŠ¸ ì˜ì—­ ë¶„í•  ì¶”ì¶œ (ë³´ì •ëœ bbox ì‚¬ìš©)
            elements = extract_text_regions_with_positions(plumber_page, fixed_bboxes)
            
            # 4. í…Œì´ë¸” ì²˜ë¦¬ (Gemini Vision)
            for j, bbox in enumerate(fixed_bboxes):
                table_num = j + 1
                print(f"    ğŸ–¼ï¸ í…Œì´ë¸” {table_num} í¬ë¡­ ë° Gemini ì „ì†¡...")
                
                # [ê°œì„ 2] í™•ì¥ íŒ¨ë”©ìœ¼ë¡œ í¬ë¡­
                table_img = crop_table_image(
                    page_image,
                    bbox,
                    plumber_page.height,
                    plumber_page.width,
                    extended=True  # ì•„ë˜ìª½ íŒ¨ë”© í™•ëŒ€
                )
                
                table_html, _, _ = extract_table_with_gemini(table_img, table_num)
                
                if table_html:
                    elements.append({'y': bbox[1], 'type': 'table', 'content': table_html})
            
            # 5. yì¢Œí‘œ ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥
            elements.sort(key=lambda x: x['y'])
            
            for elem in elements:
                markdown_output += elem['content'] + "\n\n"
    
    return markdown_output


def main():
    pdf_path = None
    text_only_mode = False
    toc_path = None
    page_spec = None
    log_file = Path(__file__).parent / "step1_log.txt"
    
    args = sys.argv[1:]
    i = 0
    while i < len(args):
        arg = args[i]
        if arg in ('--text-only', '-t'):
            text_only_mode = True
        elif arg == '--toc' and i + 1 < len(args):
            i += 1
            toc_path = args[i]
        elif arg == '--pages' and i + 1 < len(args):
            i += 1
            page_spec = args[i]
        elif not arg.startswith('-'):
            pdf_path = arg
        i += 1
    
    if not pdf_path:
        print("=" * 50)
        print("í•˜ì´ë¸Œë¦¬ë“œ PDF ì¶”ì¶œê¸° v3.3")
        print("Python(í…ìŠ¤íŠ¸) + Gemini(í…Œì´ë¸”) + ëª©ì°¨ ì—°ë™")
        print("=" * 50)
        print()
        print("ì‚¬ìš©ë²•: py step1_extract_gemini.py [ì˜µì…˜] <PDFíŒŒì¼ê²½ë¡œ>")
        print()
        print("ì˜µì…˜:")
        print("  --text-only, -t   í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ (í…Œì´ë¸” ì—†ëŠ” ë¬¸ì„œìš©, ë¹ ë¦„)")
        print("  --toc <íŒŒì¼>      ëª©ì°¨ íŒŒì¼ ê²½ë¡œ (êµ¬ì¡° ì •ë³´ ì‚½ì…)")
        print("  --pages <ì§€ì •>    ì²˜ë¦¬í•  í˜ì´ì§€ (ì˜ˆ: 10, 16-30, 1,3,5-10, 20-)")
        print()
        print("í˜ì´ì§€ ì§€ì • ì˜ˆì‹œ:")
        print("  --pages 15        â†’ 1~15í˜ì´ì§€")
        print("  --pages 16-30     â†’ 16~30í˜ì´ì§€")
        print("  --pages 1,3,5-10  â†’ 1, 3, 5~10í˜ì´ì§€")
        print("  --pages 20-       â†’ 20í˜ì´ì§€~ë")
        print()
        print("ì„¤ì •:")
        print(f"  - Gemini Model: {GEMINI_MODEL}")
        print(f"  - API Key: {'ì„¤ì •ë¨ âœ…' if GEMINI_API_KEY else 'ë¯¸ì„¤ì • âŒ'}")
        print(f"  - Poppler Path: {POPPLER_PATH or 'ì‹œìŠ¤í…œ ê¸°ë³¸'}")
        print(f"  - ë”œë ˆì´: {FREE_TIER_DELAY}ì´ˆ (ë¬´ë£Œ í‹°ì–´)")
        print(f"  - í”Œë«í¼: {platform.system()}")
        print()
        print("v3.3 ê°œì„ ì‚¬í•­:")
        print("  - í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ: ë¬¸ì¥ ì¢…ê²° ê°ì§€ë¡œ ê³¼ë„í•œ ë³‘í•© ë°©ì§€")
        print("  - í…Œì´ë¸” í¬ë¡­: ì•„ë˜ìª½ íŒ¨ë”© í™•ëŒ€ (ë³¸ë¬¸ ì˜ë¦¼ ë°©ì§€)")
        print("  - bbox ê²€ì¦: ë¹„ì •ìƒ í…Œì´ë¸” â†’ ì „ì²´ í˜ì´ì§€ Gemini í´ë°±")
        print("  - Gemini í”„ë¡¬í”„íŠ¸: thead/tbody í•„ìˆ˜, í–‰ ìƒëµ ê¸ˆì§€")
        sys.exit(1)
    
    if not os.path.exists(pdf_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        sys.exit(1)
    
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
    
    page_indices = None
    if page_spec:
        page_indices = parse_page_spec(page_spec, total_pages)
        if not page_indices:
            print(f"âŒ ìœ íš¨í•œ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {page_spec} (ì´ {total_pages}í˜ì´ì§€)")
            sys.exit(1)
        print(f"ğŸ“‹ í˜ì´ì§€ ì§€ì •: {page_spec} â†’ {len(page_indices)}í˜ì´ì§€ ì²˜ë¦¬ ì˜ˆì •")
    
    section_map = None
    if toc_path:
        if not os.path.exists(toc_path):
            print(f"âŒ ëª©ì°¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {toc_path}")
            sys.exit(1)
        
        if toc_path.endswith('.json'):
            import json
            print(f"ğŸ“– ëª©ì°¨ JSON íŒŒì¼ ë¡œë“œ ì¤‘: {toc_path}")
            with open(toc_path, 'r', encoding='utf-8') as f:
                toc_data = json.load(f)
            section_map = toc_data.get('section_map', {})
            print(f"    âœ… JSONì—ì„œ {len(section_map)}ê°œ ì„¹ì…˜ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
        else:
            print(f"ğŸ“– ëª©ì°¨ íŒŒì¼ íŒŒì‹± ì¤‘: {toc_path}")
            section_map = toc_parser.parse_toc_file(toc_path)
            print(f"    âœ… {len(section_map)}ê°œ í˜ì´ì§€ì— ëŒ€í•œ ëª©ì°¨ ì •ë³´ íŒŒì‹± ì™„ë£Œ")

    class Tee:
        def __init__(self, *files):
            self.files = files
        def write(self, obj):
            for f in self.files:
                f.write(obj)
                f.flush()
        def flush(self):
            for f in self.files:
                f.flush()
    
    with open(log_file, "w", encoding="utf-8") as log:
        original_stdout = sys.stdout
        sys.stdout = Tee(sys.stdout, log)
        
        try:
            if text_only_mode:
                print("ğŸš€ í…ìŠ¤íŠ¸ ì „ìš© PDF ì¶”ì¶œ ì‹œì‘")
                print(f"   íŒŒì¼: {pdf_path}")
                print(f"   ë°©ì‹: pdfplumber (í…ìŠ¤íŠ¸ ì „ìš©)")
                if page_indices:
                    print(f"   í˜ì´ì§€: {len(page_indices)}í˜ì´ì§€ ì„ íƒë¨")
                if section_map:
                    print(f"   ëª©ì°¨: {len(section_map)}ê°œ ì„¹ì…˜ ë§¤í•‘")
                print()
                
                md = process_pdf_text_only(pdf_path, section_map=section_map, page_indices=page_indices)
            else:
                print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ PDF ì¶”ì¶œ ì‹œì‘")
                print(f"   íŒŒì¼: {pdf_path}")
                print(f"   ëª¨ë¸: {GEMINI_MODEL}")
                print(f"   ë°©ì‹: Python(í…ìŠ¤íŠ¸) + Gemini(í…Œì´ë¸”)")
                if page_indices:
                    print(f"   í˜ì´ì§€: {len(page_indices)}í˜ì´ì§€ ì„ íƒë¨")
                if section_map:
                    print(f"   ëª©ì°¨: {len(section_map)}ê°œ ì„¹ì…˜ ë§¤í•‘")
                print()
                
                md = process_pdf(pdf_path, section_map=section_map, page_indices=page_indices)
            
            if md:
                # ì¶œë ¥ ê²½ë¡œ ìƒì„±: download_file/ë‚ ì§œ_ì›ë³¸íŒŒì¼ëª…_í˜ì´ì§€ë²”ìœ„.md
                from datetime import datetime
                
                pdf_stem = Path(pdf_path).stem
                date_str = datetime.now().strftime("%Y%m%d")
                
                # í˜ì´ì§€ ë²”ìœ„ ë¬¸ìì—´ ìƒì„±
                if page_indices:
                    page_range_str = f"_p{min(page_indices)+1}-{max(page_indices)+1}"
                else:
                    page_range_str = ""
                
                # download_file í´ë” ê²½ë¡œ (python_code í´ë” ë‚´)
                script_dir = Path(__file__).parent
                output_dir = script_dir / "download_file"
                output_dir.mkdir(parents=True, exist_ok=True)
                
                # ê¸°ë³¸ íŒŒì¼ëª…
                base_name = f"{date_str}_{pdf_stem}{page_range_str}"
                output_path = output_dir / f"{base_name}.md"
                
                # ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
                counter = 1
                while output_path.exists():
                    output_path = output_dir / f"{base_name}_{counter}.md"
                    counter += 1
                
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(md)
                
                print()
                print("=" * 50)
                print("âœ… ì¶”ì¶œ ì™„ë£Œ!")
                print("=" * 50)
                print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼: {output_path}")
                print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {len(md):,} bytes")
                print()
                
                if tracker.call_count > 0:
                    print(tracker.summary())
            else:
                print("âŒ ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
        finally:
            sys.stdout = original_stdout


if __name__ == "__main__":
    main()

"""
Gemini vs DeepSeek ìƒ˜í”Œ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
====================================
ê¸°ì¡´ Gemini llm_entities.jsonì—ì„œ 20ê°œ ì²­í¬ë¥¼ ìƒ˜í”Œë§,
ë™ì¼ ì²­í¬ë¥¼ DeepSeek-V3ë¡œ ì¬ì¶”ì¶œí•˜ì—¬ í’ˆì§ˆ ë¹„êµ.
"""
import json
import os
import random
import asyncio
from pathlib import Path
from openai import AsyncOpenAI
from dotenv import load_dotenv

SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
PHASE2_OUTPUT = PROJECT_ROOT / "phase2_output"
PHASE1_OUTPUT = PROJECT_ROOT / "phase1_output"

load_dotenv(PROJECT_ROOT / ".env")

# â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLE_SIZE = 20
GEMINI_FILE = PHASE2_OUTPUT / "llm_entities.json"
CHUNKS_FILE = PHASE1_OUTPUT / "chunks.json"
OUTPUT_FILE = PHASE2_OUTPUT / "gemini_vs_deepseek_comparison.json"
REPORT_FILE = PROJECT_ROOT / "docs" / "20260213_Gemini_vs_DeepSeek_ë¹„êµ.md"

client = AsyncOpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
)

# â”€â”€â”€ Step2ì™€ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """You are a Korean construction cost estimation data extractor.
Given a text chunk from a Korean construction cost handbook (í’ˆì…ˆ),
extract entities and relationships in JSON format.

Output JSON schema:
{
  "entities": [
    {"entity_id": "...", "name": "...", "type": "WorkType|Material|Equipment|Labor|Standard|Note", "properties": {...}}
  ],
  "relationships": [
    {"source_entity_id": "...", "target_entity_id": "...", "type": "USES_MATERIAL|REQUIRES_EQUIPMENT|REQUIRES_LABOR|APPLIES_STANDARD|HAS_NOTE", "properties": {...}}
  ]
}

Rules:
- entity_id format: {type}_{chunk_id}_{seq} (e.g. WorkType_ch001_1)
- Extract ALL entities mentioned: work types, materials, equipment, labor, standards, notes
- Include quantity/unit/spec in properties when available
- Respond ONLY with valid JSON, no markdown fences
"""


async def extract_with_deepseek(chunk_id: str, text: str) -> dict:
    """ë‹¨ì¼ ì²­í¬ë¥¼ DeepSeek-V3ë¡œ ì¶”ì¶œ"""
    try:
        resp = await client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"Chunk ID: {chunk_id}\n\n{text}"},
            ],
            response_format={"type": "json_object"},
            temperature=0.1,
            max_tokens=4096,
            timeout=60,
        )
        content = resp.choices[0].message.content
        return json.loads(content)
    except Exception as e:
        return {"error": str(e), "entities": [], "relationships": []}


async def main():
    # 1. Gemini ê²°ê³¼ ë¡œë“œ
    print("ğŸ“‚ Gemini ê²°ê³¼ ë¡œë“œ...")
    gemini_data = json.loads(GEMINI_FILE.read_text(encoding="utf-8"))
    gemini_extractions = {ext["chunk_id"]: ext for ext in gemini_data.get("extractions", [])}
    
    # 2. ì²­í¬ ë¡œë“œ
    print("ğŸ“‚ ì²­í¬ ë¡œë“œ...")
    chunks_data = json.loads(CHUNKS_FILE.read_text(encoding="utf-8"))
    chunks = {c["chunk_id"]: c for c in chunks_data.get("chunks", [])}
    
    # 3. ìƒ˜í”Œë§: Geminiê°€ ì¶”ì¶œí•œ ì²­í¬ ì¤‘ ë‹¤ì–‘í•œ íƒ€ì… í¬í•¨
    available = [cid for cid in gemini_extractions if cid in chunks]
    random.seed(42)
    sample_ids = random.sample(available, min(SAMPLE_SIZE, len(available)))
    print(f"\nğŸ¯ ìƒ˜í”Œ {len(sample_ids)}ê°œ ì„ íƒ")
    
    # 4. DeepSeek ì¶”ì¶œ
    print("ğŸ¤– DeepSeek-V3 ì¶”ì¶œ ì‹œì‘...")
    tasks = []
    for cid in sample_ids:
        text = chunks[cid].get("text", "")
        tables = chunks[cid].get("tables", "")
        full_text = f"{text}\n\n{tables}" if tables else text
        tasks.append(extract_with_deepseek(cid, full_text))
    
    deepseek_results = await asyncio.gather(*tasks)
    print(f"  âœ… DeepSeek ì¶”ì¶œ ì™„ë£Œ: {len(deepseek_results)}ê±´")
    
    # 5. ë¹„êµ ë¶„ì„
    comparison = []
    total_gemini_entities = 0
    total_deepseek_entities = 0
    total_gemini_rels = 0
    total_deepseek_rels = 0
    
    for cid, ds_result in zip(sample_ids, deepseek_results):
        gm = gemini_extractions[cid]
        gm_entities = gm.get("entities", [])
        gm_rels = gm.get("relationships", [])
        ds_entities = ds_result.get("entities", [])
        ds_rels = ds_result.get("relationships", [])
        
        total_gemini_entities += len(gm_entities)
        total_deepseek_entities += len(ds_entities)
        total_gemini_rels += len(gm_rels)
        total_deepseek_rels += len(ds_rels)
        
        # ì—”í‹°í‹° íƒ€ì…ë³„ ë¹„êµ
        gm_types = {}
        for e in gm_entities:
            t = e.get("type", "Unknown")
            gm_types[t] = gm_types.get(t, 0) + 1
        ds_types = {}
        for e in ds_entities:
            t = e.get("type", "Unknown")
            ds_types[t] = ds_types.get(t, 0) + 1
        
        comparison.append({
            "chunk_id": cid,
            "title": chunks[cid].get("title", ""),
            "gemini": {
                "entities": len(gm_entities),
                "relationships": len(gm_rels),
                "types": gm_types,
            },
            "deepseek": {
                "entities": len(ds_entities),
                "relationships": len(ds_rels),
                "types": ds_types,
                "error": ds_result.get("error"),
            },
        })
    
    # 6. JSON ì €ì¥
    result = {
        "sample_size": len(sample_ids),
        "summary": {
            "gemini_total_entities": total_gemini_entities,
            "deepseek_total_entities": total_deepseek_entities,
            "gemini_total_relationships": total_gemini_rels,
            "deepseek_total_relationships": total_deepseek_rels,
            "entity_ratio": round(total_deepseek_entities / max(total_gemini_entities, 1), 2),
            "rel_ratio": round(total_deepseek_rels / max(total_gemini_rels, 1), 2),
        },
        "comparisons": comparison,
    }
    OUTPUT_FILE.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"\nğŸ“„ ë¹„êµ JSON: {OUTPUT_FILE}")
    
    # 7. ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    md = []
    md.append("# Gemini vs DeepSeek-V3 ìƒ˜í”Œ ë¹„êµ ê²°ê³¼\n")
    md.append(f"> **ìƒ˜í”Œ ìˆ˜**: {len(sample_ids)}ê°œ ì²­í¬ (seed=42)\n")
    md.append(f"> **ë¹„êµì¼**: 2026-02-13\n")
    md.append("\n---\n")
    md.append("\n## ì „ì²´ ìš”ì•½\n")
    md.append("| í•­ëª© | Gemini | DeepSeek-V3 | ë¹„ìœ¨ |")
    md.append("|---|---|---|---|")
    md.append(f"| ì—”í‹°í‹° í•©ê³„ | {total_gemini_entities} | {total_deepseek_entities} | Ã—{result['summary']['entity_ratio']} |")
    md.append(f"| ê´€ê³„ í•©ê³„ | {total_gemini_rels} | {total_deepseek_rels} | Ã—{result['summary']['rel_ratio']} |")
    md.append(f"| í‰ê·  ì—”í‹°í‹°/ì²­í¬ | {total_gemini_entities/len(sample_ids):.1f} | {total_deepseek_entities/len(sample_ids):.1f} | |")
    md.append(f"| í‰ê·  ê´€ê³„/ì²­í¬ | {total_gemini_rels/len(sample_ids):.1f} | {total_deepseek_rels/len(sample_ids):.1f} | |")
    md.append("\n---\n")
    md.append("\n## ì²­í¬ë³„ ìƒì„¸ ë¹„êµ\n")
    md.append("| # | ì²­í¬ | ì œëª© | Gemini E | DS E | Gemini R | DS R |")
    md.append("|---|---|---|---|---|---|---|")
    for i, c in enumerate(comparison, 1):
        title_short = (c["title"] or "")[:25]
        err = " âš ï¸" if c["deepseek"].get("error") else ""
        md.append(f"| {i} | `{c['chunk_id']}` | {title_short} | {c['gemini']['entities']} | {c['deepseek']['entities']}{err} | {c['gemini']['relationships']} | {c['deepseek']['relationships']} |")
    
    md.append("\n---\n")
    md.append("\n## íƒ€ì…ë³„ ë¶„í¬ ë¹„êµ (í•©ì‚°)\n")
    
    # íƒ€ì…ë³„ í•©ì‚°
    all_gm_types = {}
    all_ds_types = {}
    for c in comparison:
        for t, cnt in c["gemini"]["types"].items():
            all_gm_types[t] = all_gm_types.get(t, 0) + cnt
        for t, cnt in c["deepseek"]["types"].items():
            all_ds_types[t] = all_ds_types.get(t, 0) + cnt
    
    all_types = sorted(set(list(all_gm_types.keys()) + list(all_ds_types.keys())))
    md.append("| íƒ€ì… | Gemini | DeepSeek | ì°¨ì´ |")
    md.append("|---|---|---|---|")
    for t in all_types:
        gv = all_gm_types.get(t, 0)
        dv = all_ds_types.get(t, 0)
        diff = dv - gv
        sign = "+" if diff > 0 else ""
        md.append(f"| {t} | {gv} | {dv} | {sign}{diff} |")
    
    errors = [c for c in comparison if c["deepseek"].get("error")]
    if errors:
        md.append(f"\n> âš ï¸ DeepSeek ì—ëŸ¬ {len(errors)}ê±´: í•´ë‹¹ ì²­í¬ëŠ” ë¹„êµì—ì„œ ì œì™¸ ê¶Œì¥\n")
    
    REPORT_FILE.write_text("\n".join(md), encoding="utf-8")
    print(f"ğŸ“Š ë¦¬í¬íŠ¸: {REPORT_FILE}")


if __name__ == "__main__":
    asyncio.run(main())

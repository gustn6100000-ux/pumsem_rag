# -*- coding: utf-8 -*-
"""Phase 0-2: ë°ì´í„° ë³€í˜• ê²½ë¡œ ì¶”ì 

13-2-3 ê°•ê´€ìš©ì ‘ ë°ì´í„°ê°€ ê° íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ì—ì„œ ì–´ë–»ê²Œ ë³€í˜•ë˜ëŠ”ì§€ ì¶”ì í•œë‹¤.

ê²½ë¡œ: llm_entities.json â†’ merged_entities.json â†’ normalized_entities.json â†’ Supabase DB

ì‚¬ìš©ë²•:
    python trace_data_transform.py
"""

import json
import re
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent))
from config import (
    TABLE_ENTITIES_FILE,
    LLM_ENTITIES_FILE,
    MERGED_ENTITIES_FILE,
    PHASE2_OUTPUT,
)

sys.stdout.reconfigure(encoding="utf-8")

NORMALIZED_FILE = PHASE2_OUTPUT / "normalized_entities.json"
TARGET_SECTION = "13-2-3"

# ì›ë³¸ ê¸°ëŒ€ê°’ (MD íŒŒì¼ì—ì„œ í™•ì¸í•œ ê°’)
EXPECTED_VALUES = {
    ("Ï†200", "SCH 20", "ìš©ì ‘ê³µ"): 0.287,
    ("Ï†200", "SCH 40", "í”ŒëœíŠ¸ ìš©ì ‘ê³µ"): 0.287,
    ("Ï†200", "SCH 60", "í”ŒëœíŠ¸ ìš©ì ‘ê³µ"): 0.325,
    ("Ï†200", "SCH 80", "í”ŒëœíŠ¸ ìš©ì ‘ê³µ"): 0.362,
    ("Ï†15", "SCH 40", "í”ŒëœíŠ¸ ìš©ì ‘ê³µ"): 0.066,
    ("Ï†15", "SCH 80", "í”ŒëœíŠ¸ ìš©ì ‘ê³µ"): 0.075,
    ("Ï†350", "SCH 20", "ìš©ì ‘ê³µ"): 0.442,
}


def load_json(path):
    """JSON íŒŒì¼ ë¡œë“œ (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ dict)"""
    if not path.exists():
        print(f"  âš ï¸ íŒŒì¼ ì—†ìŒ: {path}")
        return {}
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def search_in_extractions(data, section_id):
    """extraction ë°ì´í„°ì—ì„œ íŠ¹ì • sectionì˜ ì—”í‹°í‹°/ê´€ê³„ ê²€ìƒ‰"""
    results = {
        "entities": [],
        "relationships": [],
    }

    # extractions êµ¬ì¡°: {"extractions": [{"chunk_id": ..., "entities": [...], "relationships": [...]}]}
    extractions = data.get("extractions", [])
    if not extractions:
        # normalized_entitiesëŠ” ë‹¤ë¥¸ êµ¬ì¡°ì¼ ìˆ˜ ìˆìŒ
        extractions = data.get("chunks", [])

    for ext in extractions:
        ext_section = ext.get("section_id", "")
        if ext_section != section_id:
            continue

        # ì—”í‹°í‹°
        for ent in ext.get("entities", []):
            results["entities"].append({
                "name": ent.get("name", ""),
                "type": ent.get("type", ""),
                "spec": ent.get("spec", ""),
                "unit": ent.get("unit", ""),
                "quantity": ent.get("quantity"),
                "source_method": ent.get("source_method", ""),
                "chunk_id": ext.get("chunk_id", ""),
            })

        # ê´€ê³„
        for rel in ext.get("relationships", []):
            results["relationships"].append({
                "source": rel.get("source", ""),
                "target": rel.get("target", ""),
                "type": rel.get("type", ""),
                "quantity": rel.get("quantity"),
                "unit": rel.get("unit", ""),
                "chunk_id": ext.get("chunk_id", ""),
            })

    return results


def find_value_matches(results, diameter, sch, job_name, expected_qty):
    """íŠ¹ì • ê·œê²©/ì§ì¢…/ìˆ˜ëŸ‰ ë§¤ì¹­ ê²€ìƒ‰"""
    matches = []

    # ì—”í‹°í‹°ì—ì„œ ì°¾ê¸°
    for ent in results["entities"]:
        name = ent.get("name", "")
        qty = ent.get("quantity")

        # ì´ë¦„ì— êµ¬ê²½ê³¼ SCHê°€ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        d_clean = diameter.replace("Ï†", "").replace("Î¦", "")
        if d_clean in name.replace(" ", "") or diameter in name:
            matches.append({
                "where": "entity",
                "name": name,
                "quantity": qty,
                "type": ent.get("type", ""),
                "match_qty": qty == expected_qty if qty is not None else None,
            })

    # ê´€ê³„ì—ì„œ ì°¾ê¸°
    for rel in results["relationships"]:
        source = rel.get("source", "")
        target = rel.get("target", "")
        qty = rel.get("quantity")

        d_clean = diameter.replace("Ï†", "").replace("Î¦", "")
        if (d_clean in source.replace(" ", "") or diameter in source):
            if job_name.replace(" ", "") in target.replace(" ", "") or target.replace(" ", "") in job_name.replace(" ", ""):
                matches.append({
                    "where": "relationship",
                    "source": source,
                    "target": target,
                    "quantity": qty,
                    "match_qty": abs(qty - expected_qty) < 0.001 if qty is not None else None,
                })

    return matches


def trace_all():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¶”ì """
    print("=" * 60)
    print("Phase 0-2: ë°ì´í„° ë³€í˜• ê²½ë¡œ ì¶”ì ")
    print(f"ëŒ€ìƒ: section {TARGET_SECTION}")
    print("=" * 60)

    steps = [
        ("1. table_entities (step1 ê·œì¹™)", TABLE_ENTITIES_FILE),
        ("2. llm_entities (step2 LLM)", LLM_ENTITIES_FILE),
        ("3. merged_entities (step3 ë³‘í•©)", MERGED_ENTITIES_FILE),
        ("4. normalized_entities (step4 ì •ê·œí™”)", NORMALIZED_FILE),
    ]

    step_results = {}
    trace_report = []

    for step_name, file_path in steps:
        print(f"\n{'â”€' * 50}")
        print(f"ğŸ“‚ {step_name}")
        print(f"   íŒŒì¼: {file_path.name}")

        data = load_json(file_path)
        if not data:
            continue

        results = search_in_extractions(data, TARGET_SECTION)
        step_results[step_name] = results

        wt_count = sum(1 for e in results["entities"] if e.get("type") in ("WorkType", "WORK_TYPE"))
        labor_count = sum(1 for e in results["entities"] if e.get("type") in ("Labor", "LABOR"))
        rel_count = len(results["relationships"])

        print(f"   ì—”í‹°í‹° ì´: {len(results['entities'])}ê°œ (WorkType: {wt_count}, Labor: {labor_count})")
        print(f"   ê´€ê³„ ì´: {rel_count}ê°œ")

        # WorkType ì´ë¦„ ìƒ˜í”Œ
        wt_names = sorted(set(
            e["name"] for e in results["entities"]
            if e.get("type") in ("WorkType", "WORK_TYPE")
        ))
        if wt_names:
            print(f"   WorkType ìƒ˜í”Œ: {wt_names[:5]}")

    # ê¸°ëŒ€ê°’ ì¶”ì 
    print(f"\n{'â•' * 60}")
    print("ğŸ“Š ê¸°ëŒ€ê°’ ì¶”ì  (ì›ë³¸ MD ê¸°ì¤€)")
    print(f"{'â•' * 60}")

    for (diameter, sch, job), expected_qty in EXPECTED_VALUES.items():
        print(f"\nğŸ” {diameter} {sch} â†’ {job} = {expected_qty}")

        for step_name, results in step_results.items():
            matches = find_value_matches(results, diameter, sch, job, expected_qty)
            if matches:
                for m in matches:
                    status = "âœ…" if m.get("match_qty") else "âŒ"
                    if m["where"] == "entity":
                        print(f"   {step_name}: {status} entity [{m['name'][:40]}] qty={m['quantity']}")
                    else:
                        print(f"   {step_name}: {status} rel [{m['source'][:30]} â†’ {m['target'][:20]}] qty={m['quantity']}")
            else:
                print(f"   {step_name}: âšª í•´ë‹¹ ì—†ìŒ")

            trace_report.append({
                "diameter": diameter,
                "sch": sch,
                "job": job,
                "expected": expected_qty,
                "step": step_name,
                "found": len(matches) > 0,
                "matches": matches,
            })

    # ì „ì²´ ìš”ì•½
    print(f"\n{'â•' * 60}")
    print("ğŸ“‹ ì „ì²´ ìš”ì•½")
    print(f"{'â•' * 60}")

    for step_name in step_results:
        found = sum(1 for r in trace_report if r["step"] == step_name and r["found"])
        total = sum(1 for r in trace_report if r["step"] == step_name)
        exact = sum(
            1 for r in trace_report
            if r["step"] == step_name and r["found"]
            and any(m.get("match_qty") for m in r.get("matches", []))
        )
        print(f"  {step_name}: ë°œê²¬ {found}/{total}ê±´, ìˆ˜ì¹˜ ì¼ì¹˜ {exact}ê±´")

    # JSON ì €ì¥
    output = {
        "target_section": TARGET_SECTION,
        "expected_values": {f"{d}_{s}_{j}": v for (d, s, j), v in EXPECTED_VALUES.items()},
        "step_summary": {
            step_name: {
                "entity_count": len(results["entities"]),
                "worktype_count": sum(1 for e in results["entities"] if e.get("type") in ("WorkType", "WORK_TYPE")),
                "relationship_count": len(results["relationships"]),
            }
            for step_name, results in step_results.items()
        },
        "trace_report": trace_report,
    }

    output_file = PHASE2_OUTPUT / "data_transform_trace.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ì¶”ì  ê²°ê³¼ ì €ì¥: {output_file}")


if __name__ == "__main__":
    trace_all()

# 다음 세션 실행 계획서: φ 정규화 + RAG 검색 개선

> **작성일**: 2026-02-12 (수) 20:50  
> **선행 보고서**: `20260212_Phase2_세션종합보고서.md`  
> **목표**: RAG 챗봇 검증 PASS 달성 (TC-1~7 수치 정확도 100%)

---

## 0. 문제 정의

### 현상
RAG 챗봇에서 "강관용접 200mm SCH 40 품셈" 질의 시 **잘못된 수치**(0.557)가 반환됨.

### 근본 원인
1. **φ 접두사 중복 엔티티**: `강관용접(200, SCH 40)` (정확) vs `강관용접(φ200, SCH 40)` (부정확)이 공존
2. **벡터 검색 미스매칭**: 임베딩 공간에서 "200mm"가 "(200,"보다 "(250,"에 더 가까움

### 해결 전략 (2단계)

```
[Phase A] 데이터 정제 — φ 정규화로 중복 제거 → step4~7 재실행
[Phase B] 검색 개선  — 키워드 폴백 검색 추가 → Edge Function 수정
```

---

## 1. Phase A: 데이터 정제 (필수, ~30분)

### 1-1. step4 `normalize_name()` 수정

**파일**: `phase2_extraction/step4_normalizer.py` (라인 89~113)

**현재 코드**:
```python
def normalize_name(name: str, entity_type: str) -> str:
    # 1. NFKC
    name = unicodedata.normalize("NFKC", name)
    # 2. Labor 전용 매핑
    # 3. 공백 정규화
    # 4. 단위 정규화
    return name
```

**수정안 — Phase 0에 φ 정규화 추가**:
```python
def normalize_name(name: str, entity_type: str) -> str:
    if not name:
        return ""
    
    # 0. 구경 φ 접두사 정규화 → 통일형 제거
    # Why: step1은 "강관용접(200, SCH 40)"으로 추출하고
    #       step2 LLM은 "강관용접(φ200, SCH 40)"으로 추출하여
    #       동일 엔티티가 2벌로 분리되는 문제 해결
    # 패턴: φ/Φ/ø/∅/ɸ + 숫자 → 숫자만 (φ200 → 200)
    name = re.sub(r'[φΦø∅ɸ]\s*(?=\d)', '', name)
    
    # 1. NFKC
    name = unicodedata.normalize("NFKC", name)
    # ... (이하 동일)
```

**영향 분석**:
- `normalize_name()`은 Phase A에서 **모든 엔티티 이름과 관계의 source/target**에 적용됨
- Phase B의 `make_entity_key()`가 `normalized_name`으로 그룹핑하므로, φ 정규화 후 자동으로 중복 제거됨
- step3의 "테이블 수치 우선" 로직이 정상 작동 → 정확한 step1 수치 보존

**Side Effect 점검**:

| 체크 항목                                  | 리스크 | 대응                                        |
| ------------------------------------------ | ------ | ------------------------------------------- |
| φ가 실제 의미 있는 엔티티 이름 일부인 경우 | 낮음   | `φ + 숫자` 패턴만 제거, `φ` 단독은 보존     |
| 다른 유형 엔티티에 영향                    | 없음   | Section/Note에 φ 패턴 있을 가능성 극히 낮음 |
| 기존 관계 참조 불일치                      | 없음   | Phase E에서 name_map으로 자동 갱신          |

### 1-2. step4~step7 재실행

```bash
# 1. 백업
py _backup_phase2.py

# 2. step4 재실행
py phase2_extraction/step4_normalizer.py

# 3. step5 검증 (선택 — 변경이 적으므로 스킵 가능)
# py phase2_extraction/step5_validator.py

# 4. 관계 테이블 초기화
py _db_check.py --truncate

# 5. step6 적재
py phase2_extraction/step6_supabase_loader.py

# 6. step7 임베딩
py phase2_extraction/step7_embedding_generator.py
```

**예상 소요**: ~15분 (step4: 즉시, step6: 90초, step7: ~30초)  
**예상 비용**: ~$0 (새로 추가된 엔티티 ~수십건만 임베딩)

### 1-3. 검증

```bash
# DB 수치 정확도 직접 확인
py _db_verify.py

# RAG 챗봇 TC-1~6 검증
py _test_rag.py
```

**성공 기준**: 
- `_db_verify.py`에서 `강관용접(200, SCH 40)` = 0.287 ✅
- `_test_rag.py`에서 TC-1~3, TC-5~6 **수치 100% 일치**

---

## 2. Phase B: 검색 개선 (권장, ~20분)

### 2-1. 문제

벡터 검색에서 "200mm"와 "(200,"의 의미적 유사성 파악이 약함.
φ 중복 제거 후에도 벡터 유사도가 다른 규격(250, 300 등)을 최상위로 반환할 수 있음.

### 2-2. 해결: Edge Function `searchEntities()`에 키워드 폴백 추가

**파일**: `supabase/functions/rag-chat/index.ts`

**수정 위치**: `searchEntities()` 함수

**로직**:
```
1. 기존 벡터 검색 실행 (Top 5)
2. 결과에서 사용자 질문의 핵심 키워드(규격, SCH, 구경) 매칭 확인
3. 정확히 매칭되는 엔티티가 없으면 → 키워드 기반 폴백 검색
4. 폴백 결과를 벡터 결과와 병합
```

**Supabase 폴백 SQL**:
```sql
-- 강관용접 + 200 + SCH 40 정확 매칭
SELECT id, name, type, source_section, properties
FROM graph_entities
WHERE type = 'WorkType'
  AND name ILIKE '%강관용접%'
  AND name ILIKE '%200%'
  AND name ILIKE '%SCH 40%'
ORDER BY name
LIMIT 5;
```

### 2-3. 키워드 추출 로직

사용자 질문에서 규격 관련 키워드를 자동 추출:

```typescript
function extractSpecKeywords(question: string): string[] {
    const keywords: string[] = [];
    
    // 구경 추출 (200mm, φ200, 200A 등)
    const diameterMatch = question.match(/(?:φ|ø|∅)?(\d{2,4})\s*(?:mm|A|㎜)?/g);
    if (diameterMatch) keywords.push(...diameterMatch.map(m => m.replace(/[φø∅mmA㎜\s]/g, '')));
    
    // SCH 추출
    const schMatch = question.match(/SCH\s*\d+/gi);
    if (schMatch) keywords.push(...schMatch.map(m => m.replace(/\s/g, ' ')));
    
    return keywords;
}
```

### 2-4. Edge Function 배포

```bash
# 수정 후 배포
supabase functions deploy rag-chat --project-ref bfomacoarwtqzjfxszdr
```

---

## 3. Phase C: 추가 개선 (선택, 장기)

### 3-1. 임베딩 텍스트 개선

현재 `build_embedding_text()`가 생성하는 텍스트:
```
WorkType: 강관용접(200, SCH 40) [규격: 200mm] [인]
```

개선안:
```
건설품셈 강관용접 호칭경 200mm 스케쥴 SCH 40 용접 품셈
```

→ 사용자가 자연어로 질문하는 방식에 맞춰 임베딩 텍스트를 구성하면 벡터 검색 정확도 향상

### 3-2. E5/E6 품질 개선

| 방안          | 설명               | 효과         | 난이도 | 우선순위 |
| ------------- | ------------------ | ------------ | ------ | -------- |
| 프롬프트 개선 | Few-shot 예시 추가 | E5 +0.1~0.2  | 중     | 장기     |
| 2-pass 추출   | 검증 LLM 호출      | E6 -10~15%   | 높     | 장기     |
| 수동 검수     | 의심 29건 확인     | E6 즉시 해결 | 낮     | 선택     |

### 3-3. 이전 적재 잔존 엔티티 정리

```sql
-- 현재 normalized_entities.json에 없는 엔티티 삭제
-- 이전 적재에서 잔존한 351건 (17,442 - 17,091)
-- step6 재실행 후 clean-up 스크립트로 처리
```

---

## 4. 실행 요약

| 순서    | 작업                                  | 예상 시간 | 파일               | 우선순위 |
| ------- | ------------------------------------- | --------- | ------------------ | -------- |
| **A-1** | `step4_normalizer.py` φ 정규화 수정   | 5분       | `normalize_name()` | 🔴 필수   |
| **A-2** | step4 → step6 → step7 재실행          | 15분      | —                  | 🔴 필수   |
| **A-3** | `_db_verify.py` + `_test_rag.py` 검증 | 5분       | —                  | 🔴 필수   |
| **B-1** | Edge Function 키워드 폴백 추가        | 15분      | `index.ts`         | 🟡 권장   |
| **B-2** | 배포 + TC-1~7 재검증                  | 5분       | —                  | 🟡 권장   |
| C-1     | 임베딩 텍스트 개선                    | 30분      | `step7`            | 🟢 선택   |
| C-2     | 잔존 엔티티 정리                      | 10분      | SQL                | 🟢 선택   |

**총 예상**: Phase A+B = **~45분**, 비용 ~$0

---

## 5. 성공 기준

### Phase A 후 (데이터 정제)

```
_db_verify.py:
  ✅ 강관용접(200, SCH 40) → 플랜트용접공 0.287
  ✅ 강관용접(200, SCH 20) → 용접공 0.287
  ✅ 강관용접(200, SCH 80) → 플랜트용접공 0.362

→ φ 접두사 엔티티가 DB에서 소멸 확인
```

### Phase A+B 후 (검색 개선)

```
_test_rag.py:
  ✅ TC-1: "강관용접 200mm SCH 40 품셈" → 플랜트용접공 0.287
  ✅ TC-2: "강관용접 200mm SCH 20 품셈" → 용접공 0.287
  ✅ TC-3: "강관용접 200mm SCH 80 품셈" → 플랜트용접공 0.362
  ✅ TC-5: "강관용접 φ15 SCH 80 품셈" → 플랜트용접공 0.075
  ✅ TC-6: "강관용접 φ350 SCH 20 품셈" → 용접공 0.442

→ 5/5 PASS → 최종 PASS 판정
```

---

## 6. 리스크 & 대응

| 리스크                                    | 가능성 | 대응                                    |
| ----------------------------------------- | ------ | --------------------------------------- |
| φ 정규화로 다른 엔티티 이름 손상          | 낮음   | `φ + 숫자` 패턴만 제거, 단독 φ 보존     |
| φ 제거 후에도 벡터 검색 미스매칭          | 중간   | Phase B 키워드 폴백으로 해소            |
| step4 재실행 후 엔티티 수 대폭 변동       | 낮음   | φ 버전 ~150건 제거 예상 (전체 대비 <1%) |
| Edge Function 수정 후 기존 질의 품질 저하 | 낮음   | 벡터 검색 우선, 폴백은 보충만           |

---

## 7. 체크리스트

### Phase A: 데이터 정제
- [ ] `step4_normalizer.py` → `normalize_name()` 라인 89에 φ 정규화 추가
- [ ] `py _backup_phase2.py` 실행
- [ ] `py phase2_extraction/step4_normalizer.py` 실행
- [ ] step4 출력에서 φ 엔티티 소멸 확인
- [ ] `py _db_check.py --truncate` 실행
- [ ] `py phase2_extraction/step6_supabase_loader.py` 실행
- [ ] `py phase2_extraction/step7_embedding_generator.py` 실행
- [ ] `py _db_verify.py` → 모든 수치 ✅ 확인
- [ ] `py _test_rag.py` → TC-1~6 결과 확인

### Phase B: 검색 개선
- [ ] Edge Function `index.ts` 키워드 폴백 로직 추가
- [ ] `supabase functions deploy rag-chat` 배포
- [ ] `py _test_rag.py` → 5/5 PASS 확인
- [ ] 챗봇 UI에서 수동 검증

### 최종 완료
- [ ] 다음 세션 결과 보고서 작성
- [ ] 임시 스크립트 정리 (`_check_step1.py`, `_check_step3.py`, `_db_debug.py`, `_test_tc1.py`)
- [ ] `_tc1_response.json`, `_db_verify_result.txt` 삭제

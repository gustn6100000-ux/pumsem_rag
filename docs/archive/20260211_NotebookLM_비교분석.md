# 냉정한 분석: NotebookLM vs 품셈 RAG 시스템

> **작성일:** 2026-02-11  
> **목적:** 자체 품셈 RAG 시스템이 NotebookLM보다 나을 수 있는지 객관적 평가

---

## 결론

**조건부 Yes.** 단, "훨씬 좋다"의 정의를 정확히 해야 한다.

- **범용 대화에서는 불가능.** Google의 인프라와 엔지니어링 규모를 1인 개발로 이길 수 없다.
- **품셈 수치 정확도와 산출서 생성에서는 이미 이기고 있고, 더 이길 수 있다.**

---

## 1. 구조적 비교

| 차원                    | NotebookLM                  | 품셈 RAG 시스템             |
| ----------------------- | --------------------------- | --------------------------- |
| **팀 규모**             | Google, 수백 명 엔지니어    | 1인 개발                    |
| **인프라**              | TPU 수만 개, 무한 사전학습  | Supabase + Gemini API       |
| **범용 지능**           | ⭐⭐⭐⭐⭐                       | ⭐⭐ (LLM에 의존)             |
| **UX 완성도**           | ⭐⭐⭐⭐⭐                       | ⭐⭐                          |
| **품셈 테이블 파싱**    | ⭐⭐ (PDF를 통째로 이해 시도) | ⭐⭐⭐⭐⭐ (규칙 기반 정밀 파싱) |
| **수치 정확도**         | ⭐⭐ (환각 위험 높음)         | ⭐⭐⭐⭐⭐ (DB에 구조화된 값)    |
| **엔티티 관계 탐색**    | ❌ (없음)                    | ⭐⭐⭐⭐ (Graph 탐색)           |
| **도메인 커스터마이징** | ❌ (불가능)                  | ⭐⭐⭐⭐⭐ (완전 제어)           |

---

## 2. 핵심 통찰: Scalpel vs Swiss Army Knife

NotebookLM은 **범용 문서 이해 도구**이다. 품셈 RAG 시스템은 **건설 품셈 전문 시스템**이다.

**범용 AI가 절대 못 이기는 영역이 있다:**

### 2.1 정밀한 수치 추출

NotebookLM에 품셈 PDF를 넣고 *"잡철물 현장제작 설치 경량철재 인력 알려줘"* 라고 물으면?

> **NotebookLM:** *"잡철물 제작에는 철공, 용접공, 특별인부, 보통인부가 필요합니다..."* (수치 누락 또는 부정확)

> **품셈 RAG:** *"현장제작 설치(경량철재) — 철공 16.09인, 용접공 4.39인, 특별인부 5.85인, 보통인부 2.93인"* (DB에서 정확한 값)

`W-4384 → L-0255: 16.09인` — 이건 **그래프 DB에 구조화된 팩트**이다. LLM이 추론하는 게 아니다.

### 2.2 관계 탐색의 정확성

*"잡철물 제작에 필요한 모든 자원을 알려줘"* → 품셈 RAG 시스템은 `REQUIRES_LABOR`, `USES_MATERIAL`, `REQUIRES_EQUIPMENT` 관계를 **빠짐없이** 탐색한다. NotebookLM은 문서를 읽고 "감"으로 추출한다.

### 2.3 산출서 형식의 정형화된 출력

건설 현장에서 필요한 건 "대화"가 아니라 **정형화된 산출서 포맷**이다. 이건 NotebookLM이 구조적으로 할 수 없는 일이다.

---

## 3. 반대로, NotebookLM이 이기는 영역 (솔직한 평가)

1. **"이 문서 전체를 요약해줘"** → NotebookLM 압승. 범용 이해력은 이길 수 없다.
2. **오디오 오버뷰** → 경쟁 의미 없음.
3. **다중 문서 교차 질문** (비구조화된 질문) → NotebookLM이 더 자연스럽다.
4. **UX 완성도** → Google 디자인 팀 vs 1인 개발. 현실적으로 격차 크다.

---

## 4. "훨씬 좋게" 만들 수 있는 조건

| 조건               | 현재 상태                         | 필요 조치                       |
| ------------------ | --------------------------------- | ------------------------------- |
| 수치 정확도 100%   | 🟡 진행 중 (전치 테이블 수정 완료) | 나머지 `D_기타` 패턴도 커버     |
| 관계 그래프 완성도 | 🟡 60개 Labor 추가됨               | 전체 파이프라인 재실행으로 완성 |
| 산출서 포맷 출력   | 🟡 기본 구현                       | 실무 포맷 정밀 매칭             |
| 응답 속도          | 🟢 4.2초                           | 충분                            |
| 환각 방지          | 🟢 DB 팩트 기반                    | 핵심 강점                       |

---

## 5. Architect's Insight

> **"Vertical AI beats Horizontal AI in specialized domains."**

이건 산업계에서 이미 증명된 패턴이다:

- **Harvey** (법률 AI) > ChatGPT로 법률 질문
- **Hippocratic** (의료 AI) > NotebookLM으로 의학 논문 질문
- **품셈 RAG 시스템** (건설 AI) > NotebookLM으로 품셈 PDF 질문

핵심은 **경쟁 축을 바꾸는 것**이다.

"누가 더 똑똑한가"가 아니라 **"품셈 질의에 대해 누가 더 정확한 수치를 주는가"** — 이 축에서는 **구조화된 데이터 + 그래프 탐색 + 도메인 파이프라인**이 범용 LLM을 이긴다.

---

## 부록: 오늘 수정한 파이프라인 버그 (실증 사례)

### 문제
"잡철물 제작 인력" 쿼리 시 잘못된 데이터(강교 기본제작공수) 반환

### 근본 원인
테이블 분류기(`classify_table`)가 전치 패턴 테이블(행=인력, 열=WorkType)을 `D_기타`로 잘못 분류  
→ `step1_table_extractor`에서 완전히 스킵  
→ Labor 엔티티와 REQUIRES_LABOR 관계가 DB에 미생성

### 수정

| #   | 파일                          | 수정 내용                                             |
| --- | ----------------------------- | ----------------------------------------------------- |
| 1   | `step2_table_parser.py`       | `classify_table`에 전치 테이블 감지 로직 추가         |
| 2   | `step1_table_extractor.py`    | `extract_from_a_table`에 Case C 전치 패턴 처리 추가   |
| 3   | `hotfix_transposed_tables.py` | 기존 DB 핫픽스: 35개 청크, 60개 Labor, 24개 관계 삽입 |

### 결과
- **수정 전:** 잡철물 WorkType에 REQUIRES_LABOR 관계 0개
- **수정 후:** 6개 WorkType × 4개 Labor = 24개 관계 정상 연결
  - 현장제작 설치_경량철재 → 철공 16.09인, 용접공 4.39인, 특별인부 5.85인, 보통인부 2.93인
  - (+ 5개 WorkType 동일 패턴)

**이것이 바로 NotebookLM이 할 수 없는 일이다.** 품셈 테이블의 구조를 이해하고, 정확한 수치를 DB에 구조화하여 저장하는 것.

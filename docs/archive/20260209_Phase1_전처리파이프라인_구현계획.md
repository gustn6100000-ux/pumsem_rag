# Phase 1: 전처리 파이프라인 구현계획서

> 작성일: 2026-02-09
> 프로젝트: 건설공사 표준품셈 GraphRAG 구축
> 단계: Phase 1 (전처리 파이프라인)

---

## 0. 왜 Phase 1 전처리 파이프라인이 필요한가?

### 핵심 문제: "MD 파일은 사람이 읽는 문서이지, 기계가 이해하는 데이터가 아니다"

현재 PDF→MD 파싱은 100% 완료되었지만(41개 파일, 165,670줄, 3.8MB), 이 MD 파일들은 **GraphRAG 시스템이 직접 사용할 수 없는 상태**다.

```
현재 상태 (MD 파일)          →    필요한 상태 (구조화 데이터)
─────────────────────────        ──────────────────────────
"콘크리트공 3인"  (텍스트)    →    {"type":"Labor", "name":"콘크리트공", "count":3}
<table>...</table> (HTML)     →    [{"구분":"인력운반타설", "콘크리트공":3, "시공량":23}]
"제6장 → 6-1 → 6-1-1" (계층) →    Section(id="6-1-1", parent="6-1", chapter="제6장")
```

### 전처리 없이 바로 Phase 2(엔티티 추출)로 가면?

| 문제 | 결과 |
|------|------|
| LLM에 41개 파일 전체를 넣을 수 없음 | 토큰 한도 초과 (165K줄 = ~200만 토큰) |
| 섹션 경계 불명확 | "6-1-1 레디믹스트콘크리트 타설"의 내용이 어디서 끝나는지 모름 |
| 테이블이 HTML 태그 그대로 | LLM이 `<td>3</td>`를 잘못 해석하거나 누락 |
| 메타데이터 분리 안 됨 | "이 품셈이 어느 부문/장/절에 속하는지" 정보가 텍스트에 섞여 있음 |
| 중복/노이즈 존재 | 같은 주석이 테이블 안팎에 2번 등장하는 경우 있음 |

### 전처리가 해결하는 것

```
[전처리 전]                    [전처리 후]
41개 MD 파일 (비정형)     →    ~1,500개 구조화된 청크 (JSON)
- 섹션 경계 불명확              - 청크마다 정확한 시작/끝
- 테이블 HTML 원본              - 테이블 → 딕셔너리 배열
- 메타데이터 텍스트 혼재         - 메타데이터 별도 필드 분리
- 주석/비고 산재                - 조건/할증 정보 태깅
```

**비유**: PDF→MD는 "종이책을 스캔한 것"이고, 전처리는 "스캔본을 데이터베이스에 넣을 수 있게 정리하는 것"이다. 정리 없이 데이터베이스에 넣으면 쓸모없는 데이터가 된다.

---

## 1. 현재 데이터 현황 요약

### 1.1 입력 데이터

| 항목 | 상세 |
|------|------|
| **MD 파일** | 41개, 5개 부문, 총 3.8MB, 165,670줄 |
| **파일 위치** | `python_code/download_file/*.md` |
| **목차 데이터** | `python_code/toc_parsed.json` (1,284개 섹션) |
| **마커 구조** | `<!-- PAGE -->`, `<!-- SECTION: -->`, `<!-- CONTEXT: -->` |

### 1.2 MD 파일 내부 구조 (실제 분석 결과)

```markdown
<!-- PAGE 1 | 공통부문 > 제6장 철근콘크리트공사 -->              ← 페이지 마커

<!-- SECTION: 6-1 | 콘크리트 | 부문:공통부문 | 장:제6장 -->       ← 섹션 마커 (절)
<!-- SECTION: 6-1-1 | 레디믹스트콘크리트 타설 | ... -->           ← 섹션 마커 (항)

제6장 철근콘크리트공사                                          ← 장 제목 (텍스트)
6-1 콘크리트('25년 보완)                                        ← 절 제목 + 보완연도
◦콘크리트량이 많거나...                                         ← 본문 설명
6-1-1 레디믹스트콘크리트 타설('24년 보완)                        ← 항 제목
(일당)                                                          ← 단위 기준

<table>                                                         ← HTML 테이블 시작
  <thead>...</thead>                                            ← 테이블 헤더 (rowspan/colspan 포함)
  <tbody>                                                       ← 테이블 본문
    <tr><td>콘크리트공</td><td>인</td><td>3</td>...</tr>         ← 품셈 데이터 행
  </tbody>
</table>

[주]                                                            ← 주석 시작
① 직접노무비는...                                               ← 주석 내용
② ...                                                          ← 조건/할증 정보
```

### 1.3 식별된 데이터 패턴 유형

| 패턴 | 빈도 | 예시 |
|------|------|------|
| **품셈 테이블** (인력/장비/수량) | 매우 높음 | 콘크리트공 3인, 굴착기 1대 |
| **시공량 테이블** | 높음 | 무근구조물 63m³, 철근구조물 55m³ |
| **규모 기준 테이블** | 중간 | 직접노무비 1.5억 미만 → 사무소 40m² |
| **조건/할증 설명** | 높음 | "소량(12m³ 이하) 시 50%까지 감" |
| **교차참조** | 중간 | "제X장 X-X-X 참조" |
| **보완연도 표기** | 높음 | ('24년 보완), ('02, '22년 보완) |
| **적용 구분 테이블** | 중간 | 인력운반타설 vs 장비사용타설 |

---

## 2. Phase 1 전체 구조

### 2.1 파이프라인 흐름도

```
[입력]                 [처리 단계]                        [출력]
                   ┌──────────────────┐
41개 MD 파일  ────→│ Step 1           │
                   │ MD 파일 로더 &    │──→ raw_sections[]
toc_parsed.json ──→│ 섹션 분할         │    (섹션 단위 분할)
                   └────────┬─────────┘
                            ↓
                   ┌──────────────────┐
                   │ Step 2           │
                   │ 테이블 파서       │──→ parsed_tables[]
                   │ (HTML→구조화)     │    (딕셔너리 배열)
                   └────────┬─────────┘
                            ↓
                   ┌──────────────────┐
                   │ Step 3           │
                   │ 텍스트 정제 &     │──→ cleaned_sections[]
                   │ 주석/비고 추출    │    (정제된 텍스트+주석)
                   └────────┬─────────┘
                            ↓
                   ┌──────────────────┐
                   │ Step 4           │
                   │ 청크 생성 &       │──→ chunks.json
                   │ 메타데이터 부착    │    (최종 출력)
                   └────────┬─────────┘
                            ↓
                   ┌──────────────────┐
                   │ Step 5           │
                   │ 품질 검증 &       │──→ quality_report.json
                   │ 통계 리포트       │    (검증 결과)
                   └──────────────────┘
```

### 2.2 최종 출력물 구조 (chunks.json)

```json
{
  "metadata": {
    "total_chunks": 1500,
    "total_sections": 1284,
    "generated_at": "2026-02-XX",
    "source_files": 41
  },
  "chunks": [
    {
      "chunk_id": "C-0001",
      "section_id": "6-1-1",
      "title": "레디믹스트콘크리트 타설",
      "department": "공통부문",
      "chapter": "제6장 철근콘크리트공사",
      "section": "6-1 콘크리트",
      "subsection": "6-1-1 레디믹스트콘크리트 타설",
      "page_start": 170,
      "page_end": 171,
      "revision_year": "2024",
      "source_file": "20260208_170-199 OKOK.md",

      "text": "콘크리트량이 많거나 소량이라 할지라도...",
      "tables": [
        {
          "table_id": "T-6-1-1-01",
          "caption": "레디믹스트콘크리트 타설 (일당)",
          "unit_basis": "일당",
          "headers": ["구분", "규격", "단위", "수량", "시공량(무근)", "시공량(철근)"],
          "rows": [
            {"구분":"인력운반타설/콘크리트공", "규격":"-", "단위":"인", "수량":3, "시공량_무근":23, "시공량_철근":20},
            {"구분":"인력운반타설/보통인부", "규격":"-", "단위":"인", "수량":3, "시공량_무근":23, "시공량_철근":20},
            {"구분":"장비사용타설/콘크리트공", "규격":"-", "단위":"인", "수량":3, "시공량_무근":63, "시공량_철근":55},
            {"구분":"장비사용타설/보통인부", "규격":"-", "단위":"인", "수량":1, "시공량_무근":63, "시공량_철근":55},
            {"구분":"장비사용타설/굴착기", "규격":"(0.6~0.8m³)", "단위":"대", "수량":1, "시공량_무근":63, "시공량_철근":55}
          ]
        }
      ],
      "notes": [
        "개소별 소량(12m³ 이하)의 타설 위치가 산재하는 경우 본 시공량을 50%까지 감하여 적용",
        "본 품의 타설유형은 다음의 경우에 적용"
      ],
      "conditions": [
        {"type": "감산", "condition": "소량(12m³ 이하) 산재", "rate": "50%"}
      ],
      "cross_references": [],
      "token_count": 450
    }
  ]
}
```

---

## 3. 각 Step 상세 구현 계획

### Step 1: MD 파일 로더 & 섹션 분할

#### 목적
41개 MD 파일을 읽어서 `<!-- SECTION: -->` 마커 기준으로 개별 섹션으로 분할

#### 구현 파일
`python_code/phase1_preprocessing/step1_section_splitter.py`

#### 핵심 로직

```python
# 1. MD 파일 로드
# 2. <!-- SECTION: X-Y-Z | 제목 | 부문:OO | 장:OO --> 패턴 파싱
# 3. 연속된 SECTION 마커 그룹 처리 (페이지 시작부에 여러 마커가 모이는 패턴)
# 4. toc_parsed.json과 매핑하여 메타데이터 보강
# 5. 섹션별 텍스트 범위 결정 (현재 SECTION 마커 ~ 다음 SECTION 마커 직전)
```

#### 처리해야 할 엣지 케이스

| 케이스 | 설명 | 대응 |
|--------|------|------|
| **연속 SECTION 마커** | 페이지 시작에 2-3개 마커가 연속 등장 | 마커 그룹을 하나의 블록으로 처리, 각각 독립 섹션으로 분리 |
| **SECTION 마커 없는 영역** | 일부 보조 텍스트에 마커 없음 | 직전 섹션에 포함 처리 |
| **장(Chapter) 제목 텍스트** | "제6장 철근콘크리트공사"가 본문에 등장 | 섹션 본문에서 제외하고 메타데이터로 이동 |
| **PAGE 마커와 SECTION 마커 불일치** | 짝수 페이지 마커 보정 이슈 | PAGE 마커는 참고용, SECTION 마커 기준으로 분할 |
| **파일 간 섹션 연속** | 하나의 장이 여러 파일에 걸쳐 있음 | 파일 순서 정렬 후 연결 처리 |

#### 입력/출력

```
입력: 41개 MD 파일 + toc_parsed.json
출력: raw_sections.json
      - 예상 섹션 수: ~1,284개 (toc_parsed.json 기준)
      - 각 섹션: {section_id, title, department, chapter, page, raw_text, source_file}
```

---

### Step 2: HTML 테이블 파서

#### 목적
각 섹션 내 `<table>...</table>` HTML을 구조화된 딕셔너리 배열로 변환

#### 구현 파일
`python_code/phase1_preprocessing/step2_table_parser.py`

#### 핵심 로직

```python
# 1. BeautifulSoup으로 HTML 테이블 파싱
# 2. rowspan/colspan 처리 (품셈 테이블에 매우 빈번)
# 3. 테이블 유형 자동 분류:
#    - Type A: 품셈 테이블 (인력/장비/수량/시공량)
#    - Type B: 규모 기준 테이블 (조건→수치)
#    - Type C: 구분 설명 테이블 (구분→내용)
#    - Type D: 기타 테이블
# 4. 테이블 내 [주] 행 분리 → notes로 이동
# 5. 숫자 값 타입 변환 (문자열 "3" → 정수 3)
```

#### rowspan/colspan 처리 전략

```
원본 HTML (실제 데이터에서 빈번):
┌──────────────┬────┬────┬────┬──────┬──────┐
│              │    │    │    │시공량│시공량│
│   구 분      │규격│단위│수량├──────┼──────┤  ← colspan, rowspan
│              │    │    │    │무근  │철근  │
├──────────────┼────┼────┼────┤      │      │
│인력/콘크리트공│ -  │ 인 │ 3  │  23  │  20  │  ← rowspan으로 시공량 병합
├──────────────┼────┼────┼────┤      │      │
│인력/보통인부  │ -  │ 인 │ 3  │      │      │
└──────────────┴────┴────┴────┴──────┴──────┘

변환 결과 (JSON):
[
  {"구분":"인력운반타설/콘크리트공", "규격":"-", "단위":"인", "수량":3, "시공량_무근":23, "시공량_철근":20},
  {"구분":"인력운반타설/보통인부",   "규격":"-", "단위":"인", "수량":3, "시공량_무근":23, "시공량_철근":20}
]
```

#### 테이블 유형별 처리 규칙

| 유형 | 판별 기준 | 특수 처리 |
|------|----------|----------|
| **Type A: 품셈** | 헤더에 "수량", "단위", "인", "대" 포함 | 인력/장비/자재 분류 태깅 |
| **Type B: 규모기준** | 헤더에 "억", "m²", "규모" 포함 | 조건-값 쌍으로 변환 |
| **Type C: 구분설명** | 2열, 헤더가 "구분"/"내용" | 키-값 쌍으로 변환 |
| **Type D: 기타** | 위에 해당 없음 | 범용 행/열 구조 유지 |

#### 입력/출력

```
입력: raw_sections.json (섹션별 raw_text)
출력: parsed_tables.json
      - 각 섹션의 테이블들: [{table_id, type, caption, headers, rows, notes_in_table}]
      - 테이블 제거된 텍스트: text_without_tables
```

---

### Step 3: 텍스트 정제 & 주석/비고 추출

#### 목적
테이블 외 텍스트에서 주석([주]), 조건/할증, 교차참조, 보완연도 등 구조화된 정보 추출

#### 구현 파일
`python_code/phase1_preprocessing/step3_text_cleaner.py`

#### 추출 대상

```python
# 1. 주석 추출: [주] ① ② ③... 패턴
#    → notes 배열로 분리

# 2. 조건/할증 추출: "~인 경우 X% 가산/감산/할증" 패턴
#    → conditions 배열: [{type, condition, rate}]

# 3. 교차참조 추출: "제X장", "X-X-X", "~항 참조" 패턴
#    → cross_references 배열: [{target_section_id, context}]

# 4. 보완연도 추출: ('24년 보완), ('02, '22년 보완) 패턴
#    → revision_year 필드

# 5. 단위 기준 추출: (일당), (m³당), (100m당) 패턴
#    → unit_basis 필드

# 6. 본문 정제:
#    - HTML 주석 태그 제거 (<!-- ... -->)
#    - 중복 텍스트 제거 (테이블 안팎 동일 주석)
#    - 빈 줄 정리
#    - ◦ 기호 → 불릿 포인트 정규화
```

#### 정규표현식 패턴 (핵심)

```python
PATTERNS = {
    # 섹션 마커
    "section_marker": r'<!-- SECTION: (\S+) \| (.+?) \| 부문:(.+?) \| 장:(.+?) -->',
    "page_marker": r'<!-- PAGE (\d+) \| (.+?) -->',

    # 주석
    "note_block": r'\[주\]\s*\n((?:①|②|③|④|⑤|⑥|⑦|⑧|⑨|⑩)[\s\S]*?)(?=\n\n|\n[^\s①②③]|\Z)',
    "note_item": r'(①|②|③|④|⑤|⑥|⑦|⑧|⑨|⑩)\s*(.+?)(?=(?:①|②|③|④|⑤|⑥|⑦|⑧|⑨|⑩)|\Z)',

    # 조건/할증
    "surcharge": r'(.+?(?:경우|때|시))\s*(?:본\s*)?(?:품|시공량).*?(\d+)%.*?(가산|감산|감|증|할증)',

    # 교차참조
    "cross_ref": r'(?:제(\d+)장\s+)?(\d+-\d+(?:-\d+)?)\s*(?:항?\s*)?(?:참조|준용|적용|따른다)',

    # 보완연도
    "revision": r"\('?(\d{2,4})(?:,\s*'?(\d{2,4}))?년\s*보완\)",

    # 단위 기준
    "unit_basis": r'\(([^)]*당)\)',
}
```

#### 입력/출력

```
입력: parsed_tables.json (테이블 파싱 결과 + 잔여 텍스트)
출력: cleaned_sections.json
      - 각 섹션: {
          section_id, title, department, chapter, page,
          clean_text,        ← 정제된 본문
          tables,            ← Step 2 결과
          notes,             ← 추출된 주석
          conditions,        ← 조건/할증
          cross_references,  ← 교차참조
          revision_year,     ← 보완연도
          unit_basis          ← 단위 기준
        }
```

---

### Step 4: 청크 생성 & 메타데이터 부착

#### 목적
정제된 섹션을 GraphRAG 및 벡터 검색에 최적화된 청크로 변환

#### 구현 파일
`python_code/phase1_preprocessing/step4_chunker.py`

#### 청킹 전략

```
[원칙]
1. 기본 단위: 항(Subsection, X-Y-Z) 1개 = 1개 청크
2. 테이블 + 관련 주석은 반드시 같은 청크에 유지
3. 1,500토큰 초과 시 의미 단위로 분할 (테이블 단위/문단 단위)
4. 500토큰 미만의 짧은 연속 섹션은 병합 고려

[청크 분할 기준]
                         ┌─────────────────┐
 항(X-Y-Z) 1개          │ 1,500토큰 이하?  │
                         └────┬────────┬───┘
                              │Yes     │No
                              ↓        ↓
                         1개 청크    의미 단위 분할
                                    ├── 테이블별 분할
                                    ├── 문단별 분할
                                    └── 최대 2개 청크로 제한

[청크 ID 규칙]
- 기본: C-{순번4자리}         (예: C-0001)
- 분할: C-{순번4자리}-{분할}  (예: C-0523-A, C-0523-B)
```

#### 토큰 카운트 방식

```python
# tiktoken의 cl100k_base 인코더 사용 (GPT-4/Claude 호환)
# 한국어 특성상 글자당 ~1.5토큰 가정
# 테이블은 텍스트화 후 토큰 카운트
```

#### 입력/출력

```
입력: cleaned_sections.json
출력: chunks.json (섹션 2.2의 최종 출력물 구조)
      - 예상 청크 수: ~1,300~1,800개
      - 각 청크에 전체 메타데이터 포함
```

---

### Step 5: 품질 검증 & 통계 리포트

#### 목적
생성된 청크의 품질을 자동 검증하고, 전체 파이프라인 결과를 요약

#### 구현 파일
`python_code/phase1_preprocessing/step5_validator.py`

#### 검증 항목

| 검증 | 기준 | 심각도 |
|------|------|--------|
| **섹션 커버리지** | toc_parsed.json 1,284개 섹션 대비 매핑률 ≥ 95% | CRITICAL |
| **테이블 파싱 성공률** | HTML table 태그 수 대비 파싱 성공 ≥ 90% | HIGH |
| **빈 청크 비율** | 텍스트+테이블 모두 비어있는 청크 ≤ 5% | MEDIUM |
| **토큰 분포** | 평균 300~800, 최대 2,000 이하 | MEDIUM |
| **메타데이터 완전성** | 필수 필드(section_id, department, chapter) 누락 = 0 | CRITICAL |
| **중복 청크** | 동일 section_id의 중복 없음 | HIGH |
| **주석 추출률** | [주] 패턴 대비 추출 성공률 ≥ 95% | MEDIUM |

#### 출력 리포트 예시

```json
{
  "summary": {
    "total_chunks": 1487,
    "total_sections_mapped": 1251,
    "coverage_rate": 0.974,
    "total_tables_parsed": 823,
    "table_parse_success_rate": 0.93,
    "avg_token_count": 512,
    "max_token_count": 1480
  },
  "by_department": {
    "공통부문": {"chunks": 412, "tables": 234, "sections": 354},
    "토목부문": {"chunks": 389, "tables": 198, "sections": 312},
    "건축부문": {"chunks": 201, "tables": 124, "sections": 187},
    "기계설비부문": {"chunks": 356, "tables": 201, "sections": 298},
    "유지관리부문": {"chunks": 129, "tables": 66, "sections": 133}
  },
  "issues": [
    {"severity": "WARN", "section_id": "8-3-2", "message": "테이블 파싱 실패: 비표준 구조"},
    {"severity": "INFO", "section_id": "3-2-1", "message": "토큰 수 1,423 (경계값 근접)"}
  ]
}
```

---

## 4. 프로젝트 구조

```
python_code/
├── phase1_preprocessing/
│   ├── __init__.py
│   ├── config.py                    ← 경로, 상수, 패턴 설정
│   ├── step1_section_splitter.py    ← MD 파일 로더 & 섹션 분할
│   ├── step2_table_parser.py        ← HTML 테이블 파서
│   ├── step3_text_cleaner.py        ← 텍스트 정제 & 정보 추출
│   ├── step4_chunker.py             ← 청크 생성
│   ├── step5_validator.py           ← 품질 검증
│   ├── run_pipeline.py              ← 전체 파이프라인 실행 스크립트
│   └── utils/
│       ├── __init__.py
│       ├── html_utils.py            ← HTML 파싱 유틸리티
│       └── token_counter.py         ← 토큰 카운트 유틸리티
│
├── phase1_output/                   ← 파이프라인 출력물
│   ├── raw_sections.json            ← Step 1 출력
│   ├── parsed_tables.json           ← Step 2 출력
│   ├── cleaned_sections.json        ← Step 3 출력
│   ├── chunks.json                  ← Step 4 최종 출력
│   └── quality_report.json          ← Step 5 검증 리포트
│
├── download_file/                   ← 기존 MD 파일 (41개)
│   └── *.md
│
└── toc_parsed.json                  ← 기존 목차 데이터
```

---

## 5. 기술 스택 & 의존성

| 라이브러리 | 용도 | 버전 |
|-----------|------|------|
| **Python** | 런타임 | 3.10+ |
| **beautifulsoup4** | HTML 테이블 파싱 | 4.12+ |
| **lxml** | BeautifulSoup 파서 백엔드 | 5.0+ |
| **tiktoken** | 토큰 카운트 | 0.7+ |
| **pandas** | 테이블 데이터 처리 (선택) | 2.2+ |
| **tqdm** | 진행률 표시 | 4.66+ |
| **rich** | 콘솔 출력 포맷팅 (선택) | 13.0+ |

```bash
pip install beautifulsoup4 lxml tiktoken tqdm
```

---

## 6. 구현 순서 & 예상 일정

```
[Week 1: 핵심 파이프라인]

Day 1-2: Step 1 (섹션 분할)
  ├── SECTION 마커 파서 구현
  ├── toc_parsed.json 매핑 로직
  ├── 엣지 케이스 처리 (연속 마커, 파일 간 연결)
  └── 공통부문 1개 파일로 단위 테스트

Day 3-4: Step 2 (테이블 파서)
  ├── rowspan/colspan 전개 로직
  ├── 테이블 유형 분류기
  ├── 테이블 내 주석 행 분리
  └── 다양한 테이블 구조에 대한 테스트

Day 5: Step 3 (텍스트 정제)
  ├── 정규표현식 패턴 구현 & 검증
  ├── 주석/조건/교차참조 추출
  └── 중복 제거 & 정제

[Week 2: 통합 & 검증]

Day 6: Step 4 (청크 생성)
  ├── 청킹 전략 구현
  ├── 토큰 카운트 연동
  └── 최종 JSON 출력 포맷

Day 7: Step 5 (품질 검증)
  ├── 검증 로직 구현
  ├── 통계 리포트 생성
  └── 이슈 자동 탐지

Day 8-9: 전체 데이터 적용 & 보정
  ├── 41개 파일 전체에 파이프라인 실행
  ├── 오류 케이스 수정
  └── 최종 품질 확인

Day 10: 문서화 & Phase 2 준비
  ├── 결과 리포트 작성
  └── Phase 2 엔티티 추출을 위한 데이터 준비 확인
```

---

## 7. 파일럿 테스트 전략

### 7.1 파일럿 대상 선정

전체 41개 파일에 앞서, **2개 파일**로 먼저 end-to-end 검증:

| 파일럿 파일 | 선정 이유 |
|------------|----------|
| `20260208_170-199 OKOK.md` (제6장 철근콘크리트공사) | 전형적인 품셈 테이블 + 시공량 + 주석 패턴, rowspan/colspan 빈번 |
| `20260207_84-113 OKOK.md` (제2장 가설공사) | 규모 기준 테이블 + 다양한 조건/할증 + 교차참조 |

### 7.2 파일럿 성공 기준

| 기준 | 목표 |
|------|------|
| 섹션 분할 정확도 | 100% (toc_parsed.json 대비) |
| 테이블 파싱 성공률 | ≥ 95% |
| 주석 추출 정확도 | ≥ 90% |
| 청크 토큰 범위 | 200~1,500 (95번째 백분위) |
| 전체 파이프라인 실행 시간 | < 30초 (2개 파일 기준) |

---

## 8. 리스크 & 대응 방안

| 리스크 | 가능성 | 영향 | 대응 |
|--------|--------|------|------|
| **복잡한 테이블 파싱 실패** | 높음 | 중간 | 실패 시 원본 HTML 유지 + 이슈 로깅, Phase 2에서 LLM으로 보완 |
| **SECTION 마커 누락/불일치** | 낮음 | 높음 | toc_parsed.json과 교차 검증, 제목 텍스트 기반 폴백 매핑 |
| **대형 파일 메모리 이슈** | 낮음 | 낮음 | 668KB 최대 파일도 메모리 문제 없음, 스트리밍 불필요 |
| **주석/조건 패턴 미탐지** | 중간 | 낮음 | 정규식 커버리지 리포트로 모니터링, 반복 보완 |
| **파일 인코딩 이슈** | 낮음 | 높음 | UTF-8 강제, 인코딩 감지 로직 추가 |

---

## 9. Phase 2 연계 포인트

Phase 1의 출력물(chunks.json)이 Phase 2(엔티티 & 관계 추출)에 어떻게 연결되는지:

```
[Phase 1 출력]                          [Phase 2 입력으로 활용]
─────────────────────────────────────────────────────────────
chunks.json
├── chunk.text          ──────────→     LLM 프롬프트에 텍스트 전달
├── chunk.tables        ──────────→     규칙 기반 엔티티 자동 추출
│   └── rows[].구분/수량/단위           (인력/장비/자재 노드 생성)
├── chunk.notes         ──────────→     LLM에 컨텍스트로 함께 전달
├── chunk.conditions    ──────────→     Surcharge 노드 직접 생성
├── chunk.cross_references ───────→    REFERENCES 엣지 직접 생성
└── chunk.metadata      ──────────→     노드 속성(부문/장/페이지) 부여
```

**핵심**: Phase 1에서 테이블을 잘 파싱하면, Phase 2에서 LLM 호출 없이 규칙 기반으로 인력/장비/자재 엔티티의 **~60%를 자동 추출**할 수 있다. 이것이 Phase 1을 충실히 구현해야 하는 가장 큰 이유다.

---

## 10. 실행 방법 (구현 완료 후)

```bash
# 전체 파이프라인 실행
python phase1_preprocessing/run_pipeline.py

# 개별 Step 실행
python phase1_preprocessing/step1_section_splitter.py
python phase1_preprocessing/step2_table_parser.py
python phase1_preprocessing/step3_text_cleaner.py
python phase1_preprocessing/step4_chunker.py
python phase1_preprocessing/step5_validator.py

# 파일럿 모드 (2개 파일만)
python phase1_preprocessing/run_pipeline.py --pilot

# 특정 부문만
python phase1_preprocessing/run_pipeline.py --department 공통부문
```

---

*본 계획서는 검토보고서(2026-02-08)의 Phase 1 설계를 기반으로 실제 MD 파일 구조 분석 결과를 반영하여 구체화한 것임.*

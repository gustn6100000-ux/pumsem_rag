# Step 2.6: Supabase 저장 & 임베딩 — 상세 구현 계획서

> **작성일**: 2026-02-11  
> **전제**: Step 2.5 CONDITIONAL_PASS (자동 검증 5/6 PASS)  
> **입력**: `normalized_entities.json` + `chunks.json`  
> **출력**: Supabase `pumsem` 프로젝트 (`bfomacoarwtqzjfxszdr`)에 3개 테이블 적재 완료  
> **구현 파일**: `phase2_extraction/step6_supabase_loader.py`

---

## 0. 현재 상태

### 0.1 입력 데이터 현황

| 데이터     |   건수 | 비고                              |
| ---------- | -----: | --------------------------------- |
| **엔티티** | 16,364 | 7개 타입                          |
| **관계**   | 23,586 | 6개 타입 (extractions 내 분산)    |
| **청크**   |  2,105 | chunks.json → metadata + chunks[] |
| **섹션**   |  1,364 | 고유 section_id                   |

**엔티티 타입별 분포**:

| 타입      |  건수 |  비율 |
| --------- | ----: | ----: |
| Note      | 6,249 | 38.2% |
| WorkType  | 4,531 | 27.7% |
| Equipment | 1,795 | 11.0% |
| Material  | 1,667 | 10.2% |
| Section   | 1,218 |  7.4% |
| Standard  |   569 |  3.5% |
| Labor     |   335 |  2.0% |

**관계 타입별 분포**:

| 타입               |  건수 | 설명        |
| ------------------ | ----: | ----------- |
| REQUIRES_LABOR     | 7,958 | 공종→인력   |
| HAS_NOTE           | 6,292 | 공종→비고   |
| BELONGS_TO         | 4,237 | 엔티티→섹션 |
| REQUIRES_EQUIPMENT | 2,315 | 공종→장비   |
| USES_MATERIAL      | 1,877 | 공종→자재   |
| APPLIES_STANDARD   |   907 | 공종→기준   |

**엔티티 필드 채움률**:

| 필드              | 채움률 | 비고                               |
| ----------------- | -----: | ---------------------------------- |
| source_method     |   100% | 필수                               |
| source_section_id |  98.6% | 거의 완전                          |
| spec              |  57.8% | WorkType/Equipment/Material에 집중 |
| unit              |  45.5% | 수량 관련 타입에 집중              |
| quantity          |  31.5% | 관계에 주로 저장                   |
| code              |   6.1% | 품셈 코드 보유 항목                |

### 0.2 Supabase `pumsem` 프로젝트 현황

- **Project ID**: `bfomacoarwtqzjfxszdr`
- **Region**: `ap-southeast-1` (싱가포르)
- **DB Version**: PostgreSQL 17.6
- **상태**: ACTIVE_HEALTHY

**설치된 주요 확장**:

| 확장         | 버전   | 용도                            |
| ------------ | ------ | ------------------------------- |
| `vector`     | 0.8.0  | ✅ pgvector (임베딩 검색)        |
| `pg_trgm`    | 1.6    | ✅ 트라이그램 (유사 문자열 검색) |
| `pg_graphql` | 1.5.11 | ✅ GraphQL 지원                  |
| `uuid-ossp`  | 1.1    | UUID 생성                       |

**기존 테이블** (Phase 1 챗봇용):

| 테이블           | 용도                                   | 관계  |
| ---------------- | -------------------------------------- | :---: |
| `unit_costs`     | 기존 벡터 검색 (Pinecone 마이그레이션) | 유지  |
| `synonyms`       | 유의어 사전                            | 유지  |
| `item_names`     | 항목명 사전                            | 유지  |
| `labor_costs`    | 노임단가표                             | 유지  |
| `pipe_materials` | 배관 자재 사전                         | 유지  |

> 기존 테이블은 유지하면서 `graph_*` prefix로 새 테이블 생성

### 0.3 입력 데이터 구조 (스키마)

**Entity 필드**:
```json
{
  "entity_id": "E-0001",
  "type": "Equipment",
  "name": "100m3",
  "normalized_name": "100m3",
  "code": null,
  "spec": "100",
  "unit": "대",
  "quantity": null,
  "properties": {},
  "confidence": 0.95,
  "source_chunk_id": "C-0301-J",
  "source_section_id": "8-3-10",
  "source_method": "llm",
  "source_chunk_ids": ["C-0301-J"]
}
```

**Relationship 필드** (extractions[n].relationships[m]):
```json
{
  "source": "조서작성",
  "source_type": "WorkType",
  "target": "지적산업기사",
  "target_type": "Labor",
  "type": "REQUIRES_LABOR",
  "quantity": 0.04,
  "unit": "인",
  "per_unit": null,
  "properties": {},
  "source_chunk_id": "C-0001",
  "source_entity_id": "W-3526",
  "target_entity_id": "L-0249"
}
```

**Chunk 필드** (chunks.json → chunks[]):
```json
{
  "chunk_id": "C-0001",
  "section_id": "9-17-5",
  "title": "조서작성",
  "department": "토목부문",
  "chapter": "제9장 측량",
  "section": "9-17-5 조서작성",
  "text": "...",
  "tables": [...],
  "notes": [],
  "conditions": [],
  "cross_references": [],
  "unit_basis": "...",
  "token_count": 1147,
  "source_file": "20260210_542 OKOK.md"
}
```

---

## 1. DB 스키마 설계

### 1.1 테이블 구조

#### 테이블 1: `graph_entities`

```sql
CREATE TABLE graph_entities (
    id          BIGINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
    entity_id   TEXT UNIQUE NOT NULL,           -- "W-0001", "L-0001" 등
    type        TEXT NOT NULL,                  -- WorkType, Labor, Equipment, ...
    name        TEXT NOT NULL,
    normalized_name TEXT NOT NULL,
    code        TEXT,                           -- 품셈 코드
    spec        TEXT,                           -- 규격/사양
    unit        TEXT,                           -- 단위
    quantity    FLOAT,                          -- 대표 수량
    properties  JSONB DEFAULT '{}',
    confidence  FLOAT DEFAULT 1.0,
    source_chunk_ids TEXT[] DEFAULT '{}',       -- 추출 원본 청크 목록
    source_section_id TEXT,
    department  TEXT,                           -- 부문 (토목/건축/기계설비 등)
    chapter     TEXT,                           -- 장 (제N장 xxx)
    source_method TEXT,                         -- table_rule, llm, merged
    embedding   VECTOR(768),                    -- text-embedding-004
    created_at  TIMESTAMPTZ DEFAULT NOW()
);
```

**설계 결정**:
- `entity_id`를 `UNIQUE TEXT`로 → 관계 테이블에서 FK 참조 용이
- `source_chunk_ids`를 `TEXT[]`로 → 다중 출처 청크 추적
- `department`, `chapter`는 별도 컬럼 → 필터링 성능 최적화
- `embedding VECTOR(768)` → Google text-embedding-004 차원 = 768

#### 테이블 2: `graph_relationships`

```sql
CREATE TABLE graph_relationships (
    id                 BIGINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
    source_entity_id   TEXT NOT NULL REFERENCES graph_entities(entity_id),
    target_entity_id   TEXT NOT NULL REFERENCES graph_entities(entity_id),
    type               TEXT NOT NULL,           -- REQUIRES_LABOR, BELONGS_TO, ...
    quantity           FLOAT,                   -- 투입 수량
    unit               TEXT,                    -- 투입 단위
    per_unit           TEXT,                    -- 기준 단위 (1m³당 등)
    properties         JSONB DEFAULT '{}',
    source_chunk_id    TEXT,                    -- 추출 원본 청크
    created_at         TIMESTAMPTZ DEFAULT NOW()
);
```

**설계 결정**:
- FK로 `graph_entities(entity_id)` 참조 → 적재 순서 강제 (엔티티 먼저)
- `quantity`, `unit`, `per_unit` 분리 → 수치 연산 및 필터링 가능

#### 테이블 3: `graph_chunks`

```sql
CREATE TABLE graph_chunks (
    id              BIGINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
    chunk_id        TEXT UNIQUE NOT NULL,
    section_id      TEXT NOT NULL,
    department      TEXT,
    chapter         TEXT,
    title           TEXT,
    content         TEXT,                       -- text + flattened tables
    text_raw        TEXT,                       -- 원본 text 필드
    tables_json     JSONB,                      -- 원본 tables 구조 보존
    notes           JSONB DEFAULT '[]',
    conditions      JSONB DEFAULT '[]',
    cross_references JSONB DEFAULT '[]',
    unit_basis      TEXT,
    metadata        JSONB DEFAULT '{}',         -- source_file, token_count 등
    entity_count    INT DEFAULT 0,
    relationship_count INT DEFAULT 0,
    embedding       VECTOR(768),                -- text-embedding-004
    created_at      TIMESTAMPTZ DEFAULT NOW()
);
```

**설계 결정**:
- `content` = `text + tables` 텍스트 결합 → 검색용
- `text_raw` + `tables_json` 분리 보관 → 원본 복원 가능
- `notes`, `conditions`, `cross_references`는 JSONB → 구조 보존

### 1.2 인덱스 설계

```sql
-- 엔티티 인덱스
CREATE INDEX idx_ge_type ON graph_entities(type);
CREATE INDEX idx_ge_dept ON graph_entities(department);
CREATE INDEX idx_ge_section ON graph_entities(source_section_id);
CREATE INDEX idx_ge_norm_name ON graph_entities(normalized_name);
CREATE INDEX idx_ge_method ON graph_entities(source_method);
CREATE INDEX idx_ge_name_trgm ON graph_entities 
    USING GIN (name gin_trgm_ops);             -- 트라이그램 유사 검색
CREATE INDEX idx_ge_embedding ON graph_entities 
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);

-- 관계 인덱스
CREATE INDEX idx_gr_type ON graph_relationships(type);
CREATE INDEX idx_gr_source ON graph_relationships(source_entity_id);
CREATE INDEX idx_gr_target ON graph_relationships(target_entity_id);
CREATE INDEX idx_gr_chunk ON graph_relationships(source_chunk_id);

-- 청크 인덱스
CREATE INDEX idx_gc_section ON graph_chunks(section_id);
CREATE INDEX idx_gc_dept ON graph_chunks(department);
CREATE INDEX idx_gc_content_fts ON graph_chunks 
    USING GIN (to_tsvector('simple', content));  -- FTS 검색
CREATE INDEX idx_gc_embedding ON graph_chunks 
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);
```

**인덱스 설계 근거**:
- `gin_trgm_ops`: 한국어 부분 문자열 검색 (`LIKE '%콘크리트%'`) 가속
- `hnsw`: 벡터 유사도 검색 — IVFFlat 대비 정확도 높고 인덱스 빌드 빠름
- `m=16, ef_construction=64`: 16K 레코드 규모에 적합한 파라미터
- FTS `'simple'`: 한국어에는 형태소 분석기 없이 simple이 적합

### 1.3 RLS 정책

```sql
ALTER TABLE graph_entities ENABLE ROW LEVEL SECURITY;
ALTER TABLE graph_relationships ENABLE ROW LEVEL SECURITY;
ALTER TABLE graph_chunks ENABLE ROW LEVEL SECURITY;

-- 공개 읽기 전용
CREATE POLICY "public_read_entities" ON graph_entities 
    FOR SELECT USING (true);
CREATE POLICY "public_read_relationships" ON graph_relationships 
    FOR SELECT USING (true);
CREATE POLICY "public_read_chunks" ON graph_chunks 
    FOR SELECT USING (true);

-- 쓰기는 service_role만
CREATE POLICY "service_write_entities" ON graph_entities 
    FOR ALL USING (auth.role() = 'service_role');
CREATE POLICY "service_write_relationships" ON graph_relationships 
    FOR ALL USING (auth.role() = 'service_role');
CREATE POLICY "service_write_chunks" ON graph_chunks 
    FOR ALL USING (auth.role() = 'service_role');
```

---

## 2. 적재 프로세스

### 2.1 전체 흐름

```
normalized_entities.json ─┐
                          ├─→ [Phase A] DDL 마이그레이션
chunks.json ──────────────┘         ↓
                            [Phase B] 엔티티 적재 (16,364건, batch 500)
                                    ↓
                            [Phase C] 관계 적재 (23,586건, batch 500)
                                    ↓
                            [Phase D] 청크 적재 (2,105건, batch 500)
                                    ↓
                            [Phase E] 임베딩 생성 & UPDATE
                                    ↓
                            [Phase F] 검증 쿼리
```

### 2.2 Phase A: DDL 마이그레이션

Supabase MCP `apply_migration` 도구로 실행.

**순서**:
1. `graph_entities` 테이블 생성
2. `graph_relationships` 테이블 생성 (FK 의존)
3. `graph_chunks` 테이블 생성
4. 인덱스 생성 (임베딩 인덱스는 Phase E 후)
5. RLS 정책 적용

> ⚠️ HNSW 임베딩 인덱스는 데이터 적재 후 생성 (빈 테이블에 생성하면 비효율)

### 2.3 Phase B: 엔티티 적재

```python
async def load_entities(entities: list[dict], batch_size: int = 500):
    """
    처리 로직:
    1. entities 리스트를 batch_size 단위로 분할
    2. 각 배치를 Supabase REST API로 INSERT
    3. department/chapter는 extraction에서 조회하여 매핑
    4. 중복 방지: ON CONFLICT (entity_id) DO NOTHING
    
    Why batch 500:
    - Supabase REST API 제한: 단일 요청 최대 ~1MB
    - 500건 × ~200 bytes ≈ 100KB → 안전 범위
    - 16,364 / 500 = 33 배치 → ~30초
    """
```

**department/chapter 매핑 전략**:

엔티티에는 `department`, `chapter` 필드가 없음. `extractions`에서 `source_chunk_id` 기준으로 조회:
```python
# extraction의 chunk_id → department, chapter 매핑 테이블 구축
chunk_meta = {}
for ext in data["extractions"]:
    chunk_meta[ext["chunk_id"]] = {
        "department": ext.get("department", ""),
        "chapter": ext.get("chapter", ""),
    }

# entity의 source_chunk_ids[0]로 department/chapter 결정
for entity in entities:
    first_chunk = entity.get("source_chunk_ids", [""])[0]
    meta = chunk_meta.get(first_chunk, {})
    entity["department"] = meta.get("department", "")
    entity["chapter"] = meta.get("chapter", "")
```

### 2.4 Phase C: 관계 적재

```python
async def load_relationships(extractions: list[dict], batch_size: int = 500):
    """
    처리 로직:
    1. extractions에서 모든 relationships 수집 (flatten)
    2. source_entity_id, target_entity_id 유효성 확인
       - 무효한 ID → skip + warnings 기록
    3. batch INSERT
    4. ON CONFLICT 없음 (관계는 복합키가 없으므로 중복 가능)
    
    Why 관계를 엔티티 후에:
    - FK 제약조건 (source_entity_id → graph_entities.entity_id)
    - 엔티티가 먼저 있어야 관계 INSERT 가능
    """
```

**관계 FK 검증**:
```python
# 메모리에서 유효 entity_id 집합 구축
valid_entity_ids = {e["entity_id"] for e in entities}

# 관계의 source/target 검증
for rel in all_relationships:
    if rel["source_entity_id"] not in valid_entity_ids:
        warnings.append(f"Invalid source: {rel['source_entity_id']}")
        continue
    if rel["target_entity_id"] not in valid_entity_ids:
        warnings.append(f"Invalid target: {rel['target_entity_id']}")
        continue
    valid_rels.append(rel)
```

### 2.5 Phase D: 청크 적재

```python
async def load_chunks(chunks_data: dict, extractions: list[dict], batch_size: int = 500):
    """
    처리 로직:
    1. chunks.json → chunks[] 리스트 추출
    2. content 필드 생성: text + flatten(tables)
    3. entity_count, relationship_count 집계 (extractions에서)
    4. batch INSERT
    """
```

**content 생성 전략**:
```python
def build_chunk_content(chunk: dict) -> str:
    """
    검색용 통합 텍스트:
    1. title (있으면)
    2. text
    3. tables → 재귀 평탄화
    4. notes → 텍스트 결합
    5. conditions → 텍스트 결합
    
    Why 통합:
    - 벡터 임베딩은 하나의 텍스트 필드에서 생성
    - FTS 검색도 단일 필드 대상이 효율적
    """
    parts = []
    if chunk.get("title"):
        parts.append(chunk["title"])
    if chunk.get("text"):
        parts.append(chunk["text"])
    if chunk.get("tables"):
        parts.append(flatten_tables(chunk["tables"]))
    if chunk.get("notes"):
        parts.extend(chunk["notes"])
    if chunk.get("conditions"):
        parts.extend(chunk["conditions"])
    return "\n".join(parts)
```

### 2.6 Phase E: 임베딩 생성

**모델**: Google `text-embedding-004` (768차원)

```python
async def generate_embeddings(batch_size: int = 100):
    """
    처리 로직:
    1. 엔티티 임베딩 (16,364건)
       - 임베딩 텍스트: build_entity_embedding_text(entity)
       - batch 100건씩 API 호출
       - UPDATE graph_entities SET embedding = ... WHERE entity_id = ...
    
    2. 청크 임베딩 (2,105건)
       - 임베딩 텍스트: content (이미 구축됨)
       - 동일 배치 처리
       - UPDATE graph_chunks SET embedding = ... WHERE chunk_id = ...
    
    3. HNSW 인덱스 생성 (데이터 적재 후)
    
    Rate Limit 관리:
    - text-embedding-004: 1,500 RPM
    - batch 100건씩 → 185 요청 → ~8초 간격이면 충분
    - asyncio.Semaphore(10) + sleep(0.1)
    """
```

**엔티티 임베딩 텍스트 구성**:
```python
def build_entity_embedding_text(entity: dict) -> str:
    """
    타입별 최적화된 임베딩 텍스트 생성.
    
    Why 타입별 차별화:
    - "보통인부"만으로는 벡터 공간에서 구분 어려움
    - 타입+부문 정보를 포함해야 의미적 구분 가능
    """
    t = entity["type"]
    name = entity["name"]
    spec = entity.get("spec", "") or ""
    dept = entity.get("department", "") or ""
    
    templates = {
        "WorkType":  f"{name} {spec} 공종 작업 {dept}",
        "Labor":     f"{name} 노무 인력 노동자",
        "Equipment": f"{name} {spec} 장비 기계",
        "Material":  f"{name} {spec} 자재 재료",
        "Section":   f"{entity.get('source_section_id','')} {name} 절 항 {dept}",
        "Note":      f"{name} 주석 조건 비고",
        "Standard":  f"{name} {entity.get('code','')} 기준 규격 표준",
    }
    return templates.get(t, f"{name} {spec}").strip()
```

**비용 추정**:

| 대상     |   건수 | 평균 토큰/건 |     총 토큰 | 비용 ($0.00625/1K) |
| -------- | -----: | :----------: | ----------: | -----------------: |
| 엔티티   | 16,364 |     ~30      |       ~491K |            ~$0.003 |
| 청크     |  2,105 |     ~760     |     ~1,600K |            ~$0.010 |
| **합계** |        |              | **~2,091K** |        **~$0.013** |

### 2.7 Phase F: 검증

```python
async def verify_loading():
    """
    검증 쿼리 6항목:
    
    S1. 적재 건수 일치
        SELECT COUNT(*) FROM graph_entities     → 16,364
        SELECT COUNT(*) FROM graph_relationships → 23,586 (± FK 탈락분)
        SELECT COUNT(*) FROM graph_chunks       → 2,105
    
    S2. 참조 무결성
        SELECT COUNT(*) FROM graph_relationships 
        WHERE source_entity_id NOT IN (SELECT entity_id FROM graph_entities)
        → 0건
    
    S3. 임베딩 완전성
        SELECT COUNT(*) FROM graph_entities WHERE embedding IS NULL → 0건
        SELECT COUNT(*) FROM graph_chunks WHERE embedding IS NULL → 0건
    
    S4. 타입별 건수 교차 검증
        SELECT type, COUNT(*) FROM graph_entities GROUP BY type
        → normalized_entities.json의 entity_type_counts와 일치
    
    S5. 벡터 검색 동작 확인
        "콘크리트 타설" 쿼리로 유사 엔티티 TOP 5 반환 확인
    
    S6. 그래프 탐색 동작 확인
        특정 WorkType의 REQUIRES_LABOR 관계 조회 확인
    """
```

---

## 3. Supabase 함수 (Phase 3 준비)

Step 2.6 완료 후 Phase 3에서 사용할 검색 함수를 미리 정의합니다.

### 3.1 벡터 유사도 검색

```sql
CREATE OR REPLACE FUNCTION search_entities_by_embedding(
    query_embedding VECTOR(768),
    match_type TEXT DEFAULT NULL,
    match_department TEXT DEFAULT NULL,
    match_count INT DEFAULT 10
)
RETURNS TABLE (
    entity_id TEXT,
    type TEXT,
    name TEXT,
    spec TEXT,
    similarity FLOAT
)
LANGUAGE plpgsql AS $$
BEGIN
    RETURN QUERY
    SELECT 
        ge.entity_id, ge.type, ge.name, ge.spec,
        1 - (ge.embedding <=> query_embedding) AS similarity
    FROM graph_entities ge
    WHERE (match_type IS NULL OR ge.type = match_type)
      AND (match_department IS NULL OR ge.department = match_department)
    ORDER BY ge.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

### 3.2 그래프 탐색 (공종 → 투입 자원)

```sql
CREATE OR REPLACE FUNCTION get_work_resources(
    work_entity_id TEXT
)
RETURNS TABLE (
    resource_type TEXT,
    resource_name TEXT,
    resource_spec TEXT,
    rel_type TEXT,
    quantity FLOAT,
    unit TEXT,
    per_unit TEXT
)
LANGUAGE plpgsql AS $$
BEGIN
    RETURN QUERY
    SELECT 
        e2.type AS resource_type,
        e2.name AS resource_name,
        e2.spec AS resource_spec,
        r.type AS rel_type,
        r.quantity,
        r.unit,
        r.per_unit
    FROM graph_relationships r
    JOIN graph_entities e2 ON r.target_entity_id = e2.entity_id
    WHERE r.source_entity_id = work_entity_id
      AND r.type IN ('REQUIRES_LABOR', 'REQUIRES_EQUIPMENT', 'USES_MATERIAL')
    ORDER BY r.type, e2.name;
END;
$$;
```

### 3.3 하이브리드 검색 (벡터 + 키워드 + 그래프)

```sql
CREATE OR REPLACE FUNCTION hybrid_search_graph(
    query_text TEXT,
    query_embedding VECTOR(768),
    keyword_weight FLOAT DEFAULT 0.4,
    vector_weight FLOAT DEFAULT 0.6,
    match_count INT DEFAULT 10
)
RETURNS TABLE (
    entity_id TEXT,
    type TEXT,
    name TEXT,
    spec TEXT,
    department TEXT,
    combined_score FLOAT
)
LANGUAGE plpgsql AS $$
BEGIN
    RETURN QUERY
    WITH vector_results AS (
        SELECT ge.entity_id, ge.type, ge.name, ge.spec, ge.department,
               1 - (ge.embedding <=> query_embedding) AS v_score
        FROM graph_entities ge
        WHERE ge.type = 'WorkType'
        ORDER BY ge.embedding <=> query_embedding
        LIMIT match_count * 3
    ),
    keyword_results AS (
        SELECT ge.entity_id, ge.type, ge.name, ge.spec, ge.department,
               similarity(ge.name, query_text) AS k_score
        FROM graph_entities ge
        WHERE ge.type = 'WorkType'
          AND ge.name % query_text
        LIMIT match_count * 3
    ),
    combined AS (
        SELECT 
            COALESCE(v.entity_id, k.entity_id) AS entity_id,
            COALESCE(v.type, k.type) AS type,
            COALESCE(v.name, k.name) AS name,
            COALESCE(v.spec, k.spec) AS spec,
            COALESCE(v.department, k.department) AS department,
            (COALESCE(v.v_score, 0) * vector_weight + 
             COALESCE(k.k_score, 0) * keyword_weight) AS combined_score
        FROM vector_results v
        FULL OUTER JOIN keyword_results k ON v.entity_id = k.entity_id
    )
    SELECT c.entity_id, c.type, c.name, c.spec, c.department, c.combined_score
    FROM combined c
    ORDER BY c.combined_score DESC
    LIMIT match_count;
END;
$$;
```

---

## 4. 기술 사양

### 4.1 의존성

```
supabase (Python client)  — REST API 기반 CRUD
google-generativeai       — text-embedding-004
asyncio                   — 배치 비동기 처리
```

### 4.2 환경 변수

| 변수                   | 용도                        | 소스   |
| ---------------------- | --------------------------- | ------ |
| `SUPABASE_URL`         | Supabase API URL            | `.env` |
| `SUPABASE_SERVICE_KEY` | Service Role Key (RLS 우회) | `.env` |
| `GEMINI_API_KEY`       | 임베딩 API 키               | `.env` |

### 4.3 에러 핸들링

| 상황              | 대응                             |
| ----------------- | -------------------------------- |
| 배치 INSERT 실패  | 해당 배치 개별 건 재시도 (1건씩) |
| FK 위반 (관계)    | 무효 관계 skip + warnings 기록   |
| 임베딩 API 실패   | 지수 백오프 재시도 (3회)         |
| 중복 entity_id    | ON CONFLICT DO NOTHING           |
| 네트워크 타임아웃 | 30초 타임아웃 + 재시도           |

### 4.4 실행 옵션

```bash
# 전체 실행
py -3 step6_supabase_loader.py

# DDL만 (테이블 생성)
py -3 step6_supabase_loader.py --ddl-only

# 데이터 적재만 (DDL 생략)
py -3 step6_supabase_loader.py --skip-ddl

# 임베딩만 (데이터 이미 적재됨)
py -3 step6_supabase_loader.py --embedding-only

# 검증만
py -3 step6_supabase_loader.py --verify-only

# 초기화 (테이블 DROP + 재생성)
py -3 step6_supabase_loader.py --reset
```

---

## 5. 검증 항목

|   #   | 검증             |      기준      | 방법                         |
| :---: | ---------------- | :------------: | ---------------------------- |
|  S1   | 적재 건수 일치   |      100%      | COUNT(*) == 입력 데이터 건수 |
|  S2   | FK 참조 무결성   |    0건 위반    | 고아 관계 조회               |
|  S3   | 임베딩 완전성    |    NULL 0건    | NULL 집계                    |
|  S4   | 타입별 교차 검증 |      일치      | GROUP BY 비교                |
|  S5   | 벡터 검색 동작   |   TOP 5 반환   | 샘플 쿼리                    |
|  S6   | 그래프 탐색 동작 | 자원 목록 반환 | 샘플 쿼리                    |

---

## 6. 일정 및 비용

### 6.1 작업 일정

|   단계   | 작업                        | 예상 시간  |
| :------: | --------------------------- | :--------: |
|    A     | DDL 마이그레이션 (MCP 도구) |    10분    |
|    B     | 엔티티 적재 로직 + 실행     |    25분    |
|    C     | 관계 적재 로직 + 실행       |    20분    |
|    D     | 청크 적재 로직 + 실행       |    15분    |
|    E     | 임베딩 생성 + UPDATE        |    30분    |
|    F     | 검증 쿼리 + 함수 생성       |    20분    |
| **합계** |                             | **~2시간** |

### 6.2 비용

| 항목                     | 모델               |        비용 |
| ------------------------ | ------------------ | ----------: |
| 임베딩 생성 (~2.1M 토큰) | text-embedding-004 |     ~$0.013 |
| Supabase (Free Plan)     | —                  |          $0 |
| **총 비용**              |                    | **~$0.013** |

---

## 7. 리스크 및 대응

| 리스크                       | 확률  | 영향  | 대응                               |
| ---------------------------- | :---: | :---: | ---------------------------------- |
| 임베딩 API Rate Limit        |  중   |  중   | Semaphore(10) + sleep(0.1)         |
| 대량 INSERT 타임아웃         |  하   |  중   | batch 500 → 200으로 축소           |
| FK 위반으로 관계 탈락        |  하   |  하   | warnings 기록, 탈락률 1% 이하 예상 |
| Supabase Free Plan 용량 초과 |  하   |  고   | 500MB 제한, 현재 ~50MB 예상 → 충분 |
| 기존 테이블과 이름 충돌      | 없음  |   —   | `graph_` prefix로 분리             |

---

## 8. 산출물 목록

| 파일                                         | 설명                        |
| -------------------------------------------- | --------------------------- |
| `phase2_extraction/step6_supabase_loader.py` | 적재 스크립트               |
| `phase2_output/loading_report.json`          | 적재 결과 리포트            |
| `phase2_output/loading_report.txt`           | 적재 결과 TXT               |
| Supabase `graph_entities`                    | 엔티티 테이블               |
| Supabase `graph_relationships`               | 관계 테이블                 |
| Supabase `graph_chunks`                      | 청크 테이블                 |
| Supabase 검색 함수 3개                       | 벡터/그래프/하이브리드 검색 |

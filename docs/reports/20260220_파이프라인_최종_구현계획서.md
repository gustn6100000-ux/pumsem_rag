# 🏛️ 파이프라인 최종 통합 구현 계획서 (Master Implementation Plan)

**작성일:** 2026-02-20
**문서 성격:** `20260220_파이프라인_현황분석_및_잔여과제.md`와 `20260220_파이프라인_품질전략_Gap분석.md`를 통합하여, 구조적 결함(Gap) 보정을 선행하고 잔여 과제(P0~P3)를 수행하기 위한 **수준 높은 상세 절차서**입니다.

---

## 1. 🚨 통합 아키텍처 및 로드맵 개요

두 보고서의 분석을 종합하면, 기존 잔여 과제(P0~P3)를 우선 수행할 경우 **5개의 숨겨진 구조적 결함(Gap)**으로 인해 품질 개선 효과가 상쇄됩니다. 이를 선 보정하는 단계(Phase 0.5)를 반드시 강제 주입하여 파이프라인 무결성을 담보해야 합니다.

### 📍 최종 실행 순서 (The Critical Path)
1. **[Phase 0.5] 선행 Gap 보정 & 기준 정립**: `per_unit` 보완, `_rel_key` 수정, E6/E4 임계값 중간치 타협, 토큰 초과 대비(Sub-batch).
2. **[Phase 1] 컨텍스트 주입 & 본 추출**: Context Bleeding을 방지하는 스마트 형제 텍스트 주입(P0) + 16384 토큰 기반 전수 추출(P1).
3. **[Phase 2] 교차 검증**: 후처리 독립 스크립트(P1.5)를 통한 `strict` 검증 + Dead Letter Queue 리뷰 (P2).
4. **[Phase 3] DB 적재**: 검증 최종 통과 데이터 한정 해시 병합 및 Supabase 무결성 적재 (P3).

---

## 2. 🛠️ 단계별 상세 구현 방안 및 코드 수정 지침

### 🧩 [Phase 0.5] 구조적 결함(Gap) 보정 및 기준 정립 (Day 1)

#### 1) `per_unit` (기준 단위) 스키마 및 프롬프트 추가 (Gap 2)
* **목적:** "1m³당", "100m당"과 같은 기준 단위의 정보 소실 방지.
* **수정 대상:** `phase2_extraction/step2_llm_extractor.py`
  * `LLMRelationship` 클래스에 `per_unit: Optional[str] = Field(description="기준 단위 (예: '1m3당', '100m당')")` 추가.
  * `SYSTEM_PROMPT` 규칙 5번에 "테이블 헤더나 컨텍스트에 표시된 기준 단위(per_unit)를 반드시 확인하여 추출 결과에 추가하라"는 명시적 규칙 추가.

#### 2) `max_tokens` 상향 및 Sub-batch 처리 (Gap 1)
* **목적:** 초대형 매트릭스(10cols 이상) 처리 시 발생하는 JSON 잘림(Truncation) 방지.
* **수정 대상:** `phase2_extraction/config.py`, `step2_llm_extractor.py`
  * `config.py`의 `LLM_MAX_TOKENS = 16384`로 분리/상향.
  * C-0270-C와 같은 10+ columns 초대형 매트릭스로 인한 Token Limit 회피를 위해, 테이블 규격(Columns) 크기가 10개를 초과할 경우, 프롬프트를 2~3회로 Sub-batch 분할 전송하는 로직을 `extract_single_chunk()`에 추가.

#### 3) `_rel_key` 구조 보완 (Gap 5)
* **목적:** Step 3 병합 시, 단위가 다른 동일 유형 관계가 무음 삭제(Silently dropped)되는 치명적 버그 수정.
* **수정 대상:** `phase2_extraction/step3_relation_builder.py`
  * 관계 복합키 `_rel_key(rel)` 생성 로직을 `(type, source, target, per_unit, source_spec)` 형태로 확장하여 충돌을 원천 차단.

#### 4) 임계값 기준 일원화 1단계 & E6 로직 개선 (Gap 4)
* **목적:** 검증 게이트의 이중 기준 제거 및 LLM 할루시네이션(E6) 맹점 극복.
* **수정 대상:** `phase2_extraction/config.py`, `step5_extraction_validator.py`
  * `config.py` 중간 목표: `orphan_node_max: 0.15`, `hallucination_max: 0.10`.
  * `step5_extraction_validator.py`의 하드코딩된 `0.30`, `0.20` 값을 지우고 `config.EXTRACTION_THRESHOLDS` 객체 연동.
  * E6 검증에서 `source_method=llm` 일괄 면제 로직 삭제. 테이블 헤더/셀 전체에 대해 향상된 `tokenize()`를 적용해 더 포괄적인 Set 매칭을 강제.

---

### 🚀 [Phase 1] 컨텍스트 주입 전략(P0) 및 추출(P1) (Day 1~2)

#### 1) P0: Context Injector & Bleeding 필터 반영 (Gap 3 + P0)
* **목적:** 빈 텍스트 청크(43.1%) 복원을 위해 형제 컨텍스트를 주입하되, 전혀 무관한 규격이 매핑되는 교차 오염 차단.
* **수정 대상:** `step2_llm_extractor.py`
  * `build_user_prompt(chunk, all_chunks)` 시그니처 추가, `text`가 비었을 때 동일 base_id 기준 `text`가 있는 형제 청크 탐색.
  * **(중요)** 무조건적인 주입 배제. 텍스트에 포함된 수치나 규격 키워드가 현재 렌더링될 테이블 헤더(Columns) 셋과 최소한의 유사도/정규식 매칭이 있을 때만 허용.
  * 프롬프트에 ⚠️ "위 맥락 수치는 타 청크 형제 주입 컨텍스트이므로, 테이블 헤더에 없는 규격을 임의 조합 금지" 안내문 송출.
  * 텍스트와 형제가 모두 없는 9개 고립 청크(C-0172 등)는 `confidence <= 0.7` 강제 세팅 백도어 코드 작성.

#### 2) P1-Sample & P1 전수 추출
* **상세 작업:** CLI 옵션(`--sample 20`) 테스트 진행. 고립 3건, 빈 텍스트 10건, 정상 5건, 대형 2건을 돌려 `Context Bleeding = 0건` 유지 확인.
* **전환:** 이상 무 판정 시 DeepSeek-V3 16384 Token 설정으로 2,105건 전수 재추출 수행 → `raw_llm_entities.json`.

---

### 🔍 [Phase 2] 독립 교차 검증 및 모니터링 (Day 3)

#### 1) P1.5: 독립 Post-Validator 구축 (`validate_outputs.py`)
* **목적:** 추출 직후 관계 수량/규격을 원본과 1:1로 즉각 대조하는 디커플링 아키텍처 지원 (P1 복잡도 오염 방지).
* **신규 스크립트:** `phase2_extraction/validate_outputs.py`
  * 향상된 `tokenize()` (공백/밑줄/괄호 등 복합 구분자 분리) 적극 채택.
  * `raw_llm_entities.json` 기반, `truth_numbers` 및 `truth_tokens` Subset 매칭 여부 판정.
  * `is_verified` 플래그가 입혀진 `validated_entities.json` 출력. 불일치는 `dead_letter_queue.json` 적재. `strict` 정책 기반 구동.

#### 2) P2: Quarantine Review (결함 격리 검토)
* **상세 작업:** DLQ(Dead Letter Queue)에 격리된 10%~20% 분량의 오차 데이터를 열어, 합산/비율로 인한 '파생값' 오류라면 해당 데이터에 한해 `relaxed` 정책으로 재수행 및 구제 판정. (목표 `is_verified=true` ≥ 85%)

---

### 🗄️ [Phase 3] Entity Resolution 및 DB 적재 (Day 4)

#### 1) 식별 키 기반 적재 및 최종 기준 일원화 (P3)
* **목적:** 깨끗한 데이터만 지식 그래프에 보내 무결성을 확보함.
* **수정 대상:** `config.py`, `step6_supabase_loader.py`
  * `config.py`의 E4=0.05, E6=0.02 극강 임계값 최종 설정.
  * `is_verified=true`를 받은 엔티티들에 한해서만 `(section_id, name, type)`을 Hash 복합키로 써서 Graph 평탄화 수행.
  * Supabase `graph_entities` / `graph_relationships`에 ON CONFLICT 병합 방식으로 최종 적재.

---

## 3. 실행 마일스톤 (Task Dependency)

```mermaid
graph TD
    subgraph Day 1 : Gap 보정 & P0 구현
        G2(Gap 2: per_unit 스키마 수정) --> P0(P0: Context Injector & Bleeding Filter)
        G1(Gap 1: max_tokens 16384 & Sub-batch) --> P0
        G5(Gap 5: _rel_key 중복 방지) --> P0
        G4(Gap 4: 임계값 일치화 & E6 보완) --> P0
    end

    subgraph Day 1~2 : Context 주입 & 재추출
        P0 --> P1S(P1-Sample 비교 테스트 20건)
        P1S -->|Pass| P1(P1 DeepSeek-V3 전수 재추출)
    end

    subgraph Day 3 : 교차 검증 & 격리 
        P1 --> P15(P1.5 validate_outputs.py 수량 교차검증)
        P15 --> P2(P2 DLQ 리뷰 & Relaxed 구제)
    end

    subgraph Day 4 : 최종 결과 생성 및 적재
        P2 --> P3(P3 Entity Resolution 기반 Supabase 최종 적재)
        P3 --> End(최종 임계값 목표치 달성)
    end
```

* **Check Point:** Day 1의 작업(Gap 보정 및 P0)은 즉각적인 효과를 모니터링할 핵심 구간입니다. 해당 구간을 마무리한 후 샘플 통과 시에만 P1으로 넘어감으로써 비용 통제와 시스템 품질을 동시에 담보합니다.

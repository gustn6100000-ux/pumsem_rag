# 🔬 파이프라인 품질 전략 Gap 분석 보고서

**결론:** 보고서대로 구현하면 **목표치(93%+) 미달 확률이 높음**. 보고서가 다루지 않는 **5개의 구조적 결함**이 존재하며, 이를 선 보정하지 않으면 P0~P1.5 전부 구현해도 품질 개선 효과가 상쇄됩니다.

---

## 📊 데이터 실측 기반 분석

| 지표 | 실측값 | 의미 |
|:---|:---|:---|
| 총 청크 | 2,105 | — |
| 빈 텍스트 | 908 (43.1%) | P0 대상 |
| 형제 복원 가능 | 899 (99%) | P0로 해결 가능 |
| 고립 (복원 불가) | 9 (1%) | confidence cap만 가능 |
| D_기타 10+cols 대형 매트릭스 | 429개 | LLM 부하 집중 |
| 대형 매트릭스 중 빈 텍스트 | 345/429 (80.4%) | P0 의존도 극대 |
| 규격 겹침 형제 그룹 | 121개 | Context Bleeding 위험 |
| max_tokens 초과 예상 청크 | 14개 | **데이터 손실 확정** |

---

## 🚨 보고서 미언급 구조적 결함 5건

### Gap 1. `max_tokens=8192` 예산 초과 — 무소음 데이터 절단

> [!CAUTION]
> **14개 청크의 LLM 출력이 max_tokens를 초과하여 JSON이 잘릴 위험**

```
C-0270-C: ~18,000 tokens (예산의 220%)  ← 360개 관계 전개 필요
C-0944-H: ~12,000 tokens (146%)
C-0944-N: ~12,000 tokens (146%)
C-0270-A-h: ~11,900 tokens (145%)
C-0973-B/D, C-0974-B: ~11,000 tokens (134%)
... + 7개 추가
```

**문제:** LLM이 중간에 잘린 JSON을 반환 → Pydantic 파싱 실패 → `failed` 리스트로 빠지며 해당 청크의 **모든 엔티티/관계가 소실**. 현재 `step2_llm_extractor.py`에는 잘린 JSON 복구 로직이 없음.

**보고서 대응:** `max_tokens=8192`를 `16384`로 올리면 대부분 커버되나, C-0270-C(360개 관계)는 여전히 위험. 보고서는 이 문제를 언급하지 않음.

**🔧 해법:** 대형 매트릭스 감지 시 **규격 그룹 분할(Sub-batch)** + JSON Streaming 파싱 필요.

---

### Gap 2. `per_unit` 필드 누락 — 기준 단위 정보 소실

> [!WARNING]
> **LLM 추출 스키마에 `per_unit` 필드가 완전히 빠져 있음**

```python
# step2_llm_extractor.py — LLMRelationship 스키마
class LLMRelationship(BaseModel):
    source: str
    target: str
    relation_type: str
    quantity: Optional[float]
    unit: Optional[str]          # ← "인", "m³" 등 투입 단위만 있음
    properties: Optional[dict]
    # per_unit: ???              # ← 🚨 "1m³당", "100m당" 등 기준 단위 없음!
```

**영향 범위:**
- `schemas.py:70` — `per_unit` 필드 정의됨
- `step1_table_extractor.py:684,718` — 테이블 추출은 `per_unit` 세팅함
- `step3_relation_builder.py:140-141` — 병합 시 `per_unit` 기대함
- `step4_normalizer.py:522` — 중복 제거 키에 `per_unit` 포함
- `step6_supabase_loader.py:94` — DB 적재 시 `per_unit` 참조

**결과:** LLM이 추출한 관계의 `per_unit`은 항상 `null` → 테이블 추출 결과와 병합 시 동일 관계가 별도 레코드로 중복 생성 OR 의미 소실 ("0.33인"이 "1m³당"인지 "100m당"인지 구분 불가).

**보고서 대응:** 보고서 §5 규칙 5에 "기준 단위도 추출한다"고 명시했지만, **실제 스키마/프롬프트에 `per_unit` 필드가 없어서 LLM이 어디에도 기록할 수 없음**.

**🔧 해법:** `LLMRelationship`에 `per_unit` 필드 추가 + 프롬프트/few-shot에 반영.

---

### Gap 3. Context Bleeding — P0가 해결하지 못하는 교차 오염

> [!WARNING]
> **121개 형제 청크 그룹에서 규격 겹침이 존재 → 형제 텍스트 주입 시 오히려 혼동 유발**

**예시 문제:**
```
C-0956-A (63mm, 75mm 데이터) ← 빈 텍스트
C-0956-B (100mm, 150mm 데이터) ← 빈 텍스트  
C-0956-C (200mm, 250mm 데이터) ← 텍스트 있음
```

P0 Context Injector가 -A에 형제 -C의 텍스트를 주입하면, LLM은 -A의 테이블(63/75mm)에 -C의 컨텍스트(200/250mm)를 적용하여 **잘못된 `source_spec`을 생성**할 위험이 있음.

보고서 §5는 "형제 청크 `text[:500]`을 참고"라고 제안하지만, **어떤 형제가 현재 테이블과 같은 맥락인지 판단하는 필터링 로직이 없음**.

**🔧 해법:** 형제 텍스트 주입 시 **section_id + headers 유사도** 기반 필터링 필요.

---

### Gap 4. E6 할루시네이션 검증기의 논리적 맹점

> [!IMPORTANT]
> **`source_method=llm`인 엔티티를 전부 판정 제외하면, LLM 추출의 진짜 할루시네이션도 면죄됨**

현재 step5 E6 로직 (line 456):
```python
llm_inferred = sum(1 for h in hallucinated if h["source_method"] == "llm")
truly_suspicious = len(hallucinated) - llm_inferred  # ← LLM 전부 제외!
```

**문제:** 이 로직은 "LLM이 추론한 것은 정당하다"고 **전제**하지만, 이는 순환 논증:
- P0(Context Injector)의 목적: LLM에 더 좋은 컨텍스트를 주어 **추출 품질 향상**
- E6의 목적: 추출 결과가 **원본에 근거하는지** 검증
- 그런데 E6가 LLM 결과를 **무조건 면제**하면, P0의 효과를 측정할 방법이 없음

**결과:** P0를 적용해도 E6 지표가 개선되지 않음 (이미 LLM은 면제). P0 없이도 E6가 PASS할 수 있으므로, **P0의 실제 효과를 검증할 수 없는 맹점 발생**.

**🔧 해법:** LLM 추출도 E6 판정 대상에 포함하되, **테이블 헤더/셀 값까지 확장된 매칭 로직**으로 정당한 추론을 구분. 현재처럼 `source_method`로 일괄 면제하지 않음.

---

### Gap 5. step3 `_rel_key` 중복 제거 시 `per_unit` 미포함 — 관계 병합 오류

```python
# step3_relation_builder.py:50-65
def _rel_key(rel: dict) -> str:
    src = rel['source'].replace(' ', '').lower()
    tgt = rel['target'].replace(' ', '').lower()
    return f"{rel['type']}::{src}::{tgt}"  # ← per_unit 없음!
```

**문제:** 같은 WorkType→Labor 관계라도 "1m³당 0.33인" vs "100m당 0.33인"은 **완전히 다른 관계**인데, 현재 키는 `(type, source, target)`만 비교하므로 **둘 중 하나가 silently 삭제**됨.

step4의 dedup은 `per_unit`을 키에 포함하지만, step3에서 이미 병합되었으므로 복구 불가.

**🔧 해법:** `_rel_key`에 `properties.get("source_spec", "")` 또는 `per_unit` 포함.

---

## 📉 구현 후 예상 품질 시뮬레이션

### 보고서대로 구현 시 (Gap 미보정)

| 지표 | 현재 | P0 후 예상 | 목표 |
|:---|:---:|:---:|:---:|
| E1 엔티티 커버리지 | ~88% | ~92% | ≥93% |
| E3 수량-단위 완전성 | ~91% | ~91% | ≥95% |
| E4 고아 노드 | ~25% | ~22% | ≤15% |
| E6 할루시네이션(실질) | 측정 불가 | 측정 불가 | ≤2% |
| per_unit 정확도 | ~0% (LLM) | ~0% (LLM) | 100% |
| 대형 매트릭스 손실율 | ~3.3% | ~3.3% | 0% |

### Gap 보정 후 구현 시

| 지표 | 보정 후 예상 | 목표 | 판정 |
|:---|:---:|:---:|:---:|
| E1 엔티티 커버리지 | ~94% | ≥93% | ✅ |
| E3 수량-단위 완전성 | ~95% | ≥95% | ✅ |
| E4 고아 노드 | ~15% | ≤15% | ✅ |
| E6 할루시네이션(실질) | ~3% | ≤2% | ⚠️ 추가 튜닝 필요 |
| per_unit 정확도 | ~90% | 100% | ⚠️ few-shot 의존 |
| 대형 매트릭스 손실율 | 0% | 0% | ✅ |

---

## ✅ 권장 보정 순서

```
[Gap 보정 0] per_unit 스키마/프롬프트 추가 (30분)
[Gap 보정 1] max_tokens 16384 + 대형 매트릭스 Sub-batch (1시간)
[Gap 보정 2] _rel_key에 source_spec 포함 (15분)
[Gap 보정 3] E6 검증 로직 개선 (1시간)
 ↓
[보고서 P0] Context Injector + Bleeding 필터 (3시간)
[보고서 P1] 전수 재추출
[보고서 P1.5] Post-Validator
```

> [!TIP]
> Gap 0~2는 **보고서 작업과 독립적으로 선행 가능**하며, 이들만 보정해도 기존 데이터의 품질이 즉시 개선됩니다.

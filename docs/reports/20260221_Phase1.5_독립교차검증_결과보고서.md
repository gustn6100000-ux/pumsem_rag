# Phase 1.5 독립 교차 검증(Strict Validation) 결과 및 DLQ 분석 보고서

**작성일**: 2026-02-21
**문서 내용**: Phase 1 전수 추출분(1,716건)에 대해 원본 문서 데이터를 기반으로 엄격한 토큰 매칭 알고리즘을 적용한 독립 교차 검증 파이프라인(`validate_outputs.py`)의 전개 방향 및 분석 내용 정리.

---

## 1. 개요 (Overview)

Phase 1에서 DeepSeek-V3 LLM을 통해 추출된 데이터(Entity 및 Relationship)가 상용 수준 DB 적재에 적합한 품질인지 판단하기 위해, 단순히 LLM의 `confidence` 점수에 의존하지 않고 원본 파싱 텍스트(`chunks.json`)와 1:1 토큰 매칭을 진행했습니다. 

검증 결과, 너무 엄격한 기준(Strict)으로 인한 과도한 실패(False-Negative) 현상을 개선하면서 총 4단계의 검증 룰(Rule) 완화 과정을 거쳤으며, **최종적으로 77.1%(1,323건)의 검증 통과(Pass) 데이터와 22.9%(393건)의 DLQ(격리) 데이터를 산출**했습니다.

---

## 2. 검증 로직 진화 및 완화(Relaxation) 전개

### Step 1. 초기 Strict Token Matching (통과율: 8.8%)
- **검증 규칙**: 추출된 `Entity.name`, `Entity.spec` 그리고 수량(Quantity) 등 모든 주요 속성이 원본 텍스트에 빈 공백 단위(어절)별로 완전히 포함(Subset)되어야 함.
- **결과**: **Pass 151건 (8.8%) / DLQ 1,565건**
- **실패 주요 원인**: 
  - **띄어쓰기 차이**: 파싱된 텍스트에는 "강판 전기아크용접"이나 추출물엔 "강판전기아크용접"과 같이 띄어쓰기 부재로 인해 어절 토큰이 끊겨 불일치로 처리됨.
  - **Context Bleeding (Title 누락)**: 원본 본문(Text)에 엔티티명이 없고 제목(Title)에만 존재하는 경우 매칭 실패.

### Step 2. 공백 제거 일치(Joined) 및 Title 병합 (통과율: 49.1%)
- **검증 규칙**: 
  - Token 분리 후에도 문자 사이의 공백을 모두 모아붙인 문자열 검색(Joined Token)을 별도로 허용하여 띄어쓰기 차이를 극복.
  - 청크의 `title` 속성을 원본 텍스트 매칭 검색 풀(Pool)에 추가.
- **결과**: **Pass 843건 (49.1%) / DLQ 873건**
- **실패 주요 원인**:
  - `chapter`, `department` 등 문서의 최상위 계층 정보로 추출된 Entity는 본문이나 소제목(title) 텍스트 풀에 존재하지 않아 Mismatch 발생. (예: "제13장 플랜트설비공사")

### Step 3. 상위 메타데이터 편입 및 Spec 유연화 (통과율: 51.0%)
- **검증 규칙**:
  - `department`, `chapter`, `subsection` 등 상위 메타데이터 필드를 모두 텍스트 스캔 풀에 포함.
  - LLM이 자의적으로 파생해서 축약/수정할 가능성이 높은 `spec`(규격) 항목은 토큰 Mismatch가 검출되어도 타 속성이 맞으면 통과(Warning)시킴. (예: "하향한면" -> "V형")
- **결과**: **Pass 875건 (51.0%) / DLQ 841건**
- **실패 주요 원인**:
  - `Note` (비고, 주석) 및 `Condition` 등 자연어 문장(Sentence) 형태의 Entity에서 대거 실패. 사람이 읽기 좋게 문장을 요약/재구성하는 LLM 특성상 원본 글자 그대로 남아있기 불가능.

### Step 4. 문장형(Note) Entity 검증 제외 결정 (최종 통과율: 77.1%)
- **검증 규칙**: Entity `type`이 "Note" 또는 "Condition"일 경우 토큰 부분 일치가 없더라도 Strict Rule 적용 타겟에서 예외적으로 제외시킴.
- **최종 결과**: **Pass 1,323건 (77.1%) / DLQ 393건 (22.9%)**

---

## 3. 남은 22.9% (DLQ 393건) 에러 유형 및 판단

파이프라인 적용 이후 마지막까지 살아남은 DLQ 원인을 분석한 결과, 아래와 같은 데이터 유실이나 LLM 환각(Hallucination)의 전형적인 증상으로 확인되었습니다. 결론적으로 이는 Strict Mode에서 반드시 걸러내야 하는 **정상적이고 유의미한 격리(Quarantine)** 입니다.

1. **테이블 구조적 유실 및 재추론 (`False-Negative`)**: 
   - 다단형 하위 컬럼 혹은 수직/수평 병합(Merge)된 셀 구조가 PDF 파싱 단계에서 일반 문장 집합으로 붕괴됨.
   - LLM은 파편화된 데이터 문맥을 읽어 "조경기능공", "배관공" 이라는 명사를 정답에 맞게 추론해 냈으나, 문자 그 자체가 없었기 때문에 토큰 매칭에는 실패.
2. **언어 생성 편향 및 환각 (`True-Positive DLQ`)**: 
   - "측량용역대가기준", "국토교통부장관 고시" 처럼 원본에 파편화되어 떨어져 있는 단어들을 조합해 새로운 형태의 명사를 창조(Fabrication)해 냄. 이 데이터들이 그대로 DB에 적재될 경우 수백 개의 Fragmented Node(오염된 불필요 노드) 트리거 역할로 작용하게 됨.

---

## 4. 결론 및 다음 단계 전략

### 4.1. Phase 3: 신뢰도 100% 구간 DB 적재 개시
- 통과된 1,323건의 데이터 풀(`validated_entities.json`)은 토큰 및 수량 매칭에서 오차율이 없는 고순도 기반 데이터입니다.
- 이를 바탕으로 수량과 가격이 결합된 Entity Resolution 및 복합키 병합 과정을 진행 후 (Phase 3: Supabase Graph 적재) 실사용 검증을 수행할 수 있습니다.

### 4.2. Phase 2 Continued: Quarantine Review 및 인간-AI 결합 리뷰
- `DLQ_entities.json` 에 격리된 393건의 모호한 데이터는 버리지 않고, **강화된 Relaxed Validation 모델(Vector Embedding 유사도 측정 혹은 별도의 LLM Evaluator 프롬프트)** 로 2차 판별(LLM-as-a-judge)을 진행합니다.
- 복구가 유효하여 승인 처리된 데이터는 추가 적재하며, 치명적인 환각 현상을 겪은 추출 결과는 영구 폐기 절차(Discard)를 거칠 예정입니다.

# 🏛️ Phase 1.5 ~ Phase 3 Master System Architecture & Refactoring 명세서

**작성일**: 2026-02-21
**문서 내용**: 클로드 및 제미나이 3.1 PRO DEEP THINK 모델의 시스템 감사(System Audit) 결과를 전면 수용하여, 기존 오버래핑 파이프라인의 구조적 결함을 치유하고 무결점 데이터 DB 적재를 위해 파이프라인(Phase 1.5/2/3) 실행 순서 및 모듈 리팩토링 상세 구현 방안을 정의함.

---

## 0. 핵심 변경 사항 (Critical Routing Modification)

기존 파이프라인은 1차 검증(validate_outputs.py)을 임시로 통과한 오염된 1,323건(False-Positive 혼재)을 트랙 A(DB 선적재)로 넘기려 한 치명적 안티 패턴이 있었습니다.
이를 방지하기 위해 **파이프라인 실행 방식을 아래의 3단계 [트랙 C ➔ B ➔ A] 강제 순차 처리로 전면 재조정**합니다.

---

## 🅲 Phase 1 [진단]: 트랙 C (Validator 전면 재작업 및 전수 재검증)

파이프라인의 핵심 코어인 `pipeline/phase2_extraction/validate_outputs.py`의 심각한 구조적 결함을 아래와 같이 치유합니다.

### 1.1. 현재 스크립트의 치명적 결함(Root Cause)
- **결함 1 (연좌제 폐기)**: Entity 루프 내에서 하나라도 `validate_entity`가 False면 `break` 하여 해당 청크에 포함된 정상 엔티티 9개까지 모조리 DLQ로 강등시킵니다.
- **결함 2 (검증 무력화)**: `validate_relationship` 함수 내부에서 수량 및 규격 검증 실패 시 `return False` 처리가 아닌 하드코딩된 `pass`와 최종 `return True`가 적용되어 있어 1,323건 내에 수량/규격 불일치 포맷이 섞여 있을 확률이 90% 이상입니다.

### 1.2. 구현 상세 명세 (Action Plan)
- **Entity & Relationship의 독립 격리**: 청크 전체 통과/실패 구조(`is_valid=False` 후 `break`)를 폐기하고, **엔티티와 관계 리스트를 각각 순회하여 개별적으로 필터링**합니다.
- **구조 분리 출력**: `validated_entities.json` 역시 청크 구조는 유지하되 내부 배열(`entities` / `relationships`)에 **통과한(Valid) 데이터만** 담습니다. **실패한(Invalid) 항목들**만 따로 모아 `dlq_entities.json`에 `dlq_reason`과 함께 저장합니다. (이렇게 해야 전체 1,716 청크 중 일부만 살고 일부만 버려지는 미세 타격이 가능해집니다.)
- **Relationship 검증 실질화**: 수치형 `quantity`가 원본 Text 혹은 표 데이터에 문자형태로 존재하지 않을 시 무조건 `False`로 드롭(Drop) 시킵니다.

### 1.3. 실행 결과 기대값
- 리팩토링 후 1,716건 전수 재구동을 진행합니다.
- (1,323건의 위양성 데이터 중 일부가 DLQ로 강등) + (393건의 위음성 DLQ 중 상당수 연좌제 정상 데이터가 Pass로 구제) ➔ **순수한 New Pass / True DLQ 모수 집합이 완성**됩니다.

---

## 🅰️ Phase 2 [설계]: 트랙 B (Quarantine Review 기획 & 개발)

순수한 에러 집합으로 추려진 **New DLQ 데이터**만을 타겟 대상으로 하여 LLM-as-a-judge 평가 프롬프트를 작동시킵니다. 정상 데이터에 대한 API 비용을 원천 차단합니다.

### 2.1. 구현 상세 명세 (`step2_5_quarantine_review.py`)
- **컴포넌트 역할**: 비동기(Async) 기반 이진 분류 제어 브릿지 모듈.
- **동시성 제어 (Rate Limit)**: 수백 건의 동기적 API 호출에 따른 429 Too Many Requests 에러 방지를 위해 Python `asyncio`와 `asyncio.Semaphore(10)`로 병목 현상을 방어합니다.
- **프롬프트 엔지니어링 통제**:
  - LLM의 지나친 환각 수용성을 억제합니다.
  - *제한적 유효 명시*: "표 구조상 파편화되었으나 도메인 상식상 필연적으로 도출 가능한 값(예: 장비명/직무명)인 경우에만 True로 판정하라."
  - *환각 배제 명시*: "텍스트 곳곳에 흩어진 여러 개의 단어를 무작위 결합하여 새로운 명사를 만들어 냈다면(예: 국토교통부장관 고시 등) 철저히 False(0.0) 판정하라."
- **Output Schema**: Pydantic 베이스 클래서 혹은 JSON 포맷터 딕셔너리로 `{"is_valid": bool, "confidence": float, "reason": str}` 규격을 강제화합니다.

### 2.2. 실행 결과 기대값
- 출력물 분리:
  1. `recovered_entities.json` (이유가 있어 누락되었으나 합격 판정받은 데이터 - 도메인 내 구제됨)
  2. `discarded_entities.json` (LLM 환각 및 완전 오염 데이터 - 영구 폐기)

---

## 🅱️ Phase 3 [구현]: 트랙 A (통합 적재 및 무결성 주입)

### 3.1. 통합 마스터 세트 구축 (Data Merge)
- 이전 단계에서 100% 매칭된 `New Pass` (validated_entities.json) + LLM 심사 구제를 받은 `recovered_entities.json`을 단일 배열(List extend)로 병합하는 전처리 컴포넌트를 동작시킵니다.
- 병합된 마스터 JSON은 오염 노드가 없는 무결점(100%) 데이터 그 자체입니다.

### 3.2. TRUNCATE 적재 방식 채택
- **왜 TRUNCATE 인가?**:
  - 이전 개발 세션에서 이미 Supabase DB에 적재된 구 버전 데이터의 상태(`id` 또는 복합키 구조 등)가 불분명합니다.
  - 여기에 마스터 데이터를 *증분(Incremental)*으로 적재하게 될 경우, `step4_normalizer.py` 가 찍어내는 새로운 Hash ID와 기존 ID가 충돌하며 어마어마한 고아 노드(Orphan Node)와 엣지 파편화를 초래합니다.
  - 즉, RAG 검색을 오염시키는 원흉이 됩니다.
- **구현 상세 (`step6_supabase_loader.py`)**:
  - `TRUNCATE TABLE entities, relationships CASCADE;` (또는 Supabase Client RPC Delete 방식) 쿼리를 최우선적으로 실행해 DB를 텅 빈 백지 상태로 초기화(Flush)합니다.
  - 그 직후 무결점 마스터 데이터를 `insert` (일괄 Batch 적재)하여 완전한 Graph Relation 구조를 신규 맵핑합니다.

### 3.3. RAG 텍스트 임베딩 재생성
- `step7_embedding_generator.py` 작동을 통해, 새로 적재된 Entity들의 Name 등 주요 Property 기준 Vector 생성 및 저장을 동시에 수행하며 Phase 3 파이프라인 여정을 갈무리합니다.

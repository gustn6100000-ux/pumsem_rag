# RAG 답변 품질 개선 — 구현 결과

> 작성일: 2026-02-13  
> 대상 파일: `rag-chat/index.ts`, `step5_extraction_validator.py`

---

## 문제 진단

E5 LLM 감사 점수 0.568 (기준 ≥0.85) FAIL → RAG 답변 LLM도 품셈 데이터를 이해 못할 가능성 진단.

Edge Function `index.ts` 전체 분석 결과 5개 구조적 문제 발견:

| # | 문제 | 심각도 |
|---|---|---|
| P1 | 시스템 프롬프트에 도메인 지식 없음 | 🔴 HIGH |
| P2 | 원문 청크 500자 절삭 | 🔴 HIGH |
| P3 | E5 감사 프롬프트에 품셈 도메인 지식 없음 | 🟡 MED |
| P4 | 엔티티 properties가 context에 미포함 | 🟡 MED |
| P5 | E5가 전체 판정(verdict)에 영향 | 🟢 LOW |

---

## 적용된 Fix (5건)

### Fix 1. 시스템 프롬프트에 도메인 지식 주입 [P1]
- **파일**: `rag-chat/index.ts` — `SYSTEM_PROMPT`
- **변경**: 품셈 도메인 지식 섹션 17줄 추가
  - 품셈서 구조 (부문>장>절>표번호)
  - 코드 체계 (7205-0540 = 건설기계 분류코드)
  - 계수/보정값 (계수 A~E)
  - 단위 체계 ("인" = 1인 1일 노동량 8시간)
  - 속성 필드 활용 안내

### Fix 2. 원문 청크 500자 → 2000자 확장 [P2]
- **파일**: `rag-chat/index.ts` — `retrieveChunks`
- **변경**: `text?.substring(0, 500)` → `text?.substring(0, 2000)`
- **이유**: 품셈 테이블은 규격별 행이 많아 500자면 앞 3개 규격만 전달

### Fix 3. E5 감사 프롬프트에 품셈 도메인 가이드 [P3]
- **파일**: `step5_extraction_validator.py` — `check_E5`의 `AUDIT_PROMPT`
- **변경**: 도메인 이해 가이드 10줄 추가
  - 테이블 코드→장비명 추론은 정당한 추출
  - source_method="llm"인 엔티티는 코드 기반 추론
  - 각 평가 항목에 "주의" 보충 설명

### Fix 4. 엔티티 properties를 context에 포함 [P4]
- **파일**: `rag-chat/index.ts` — `buildContext`
- **변경**: 엔티티별 속성(규격, 수량, 단위) 출력 추가
- **필터**: embedding, source_chunk_ids, chunk_id 제외

### Fix 5. E5를 참고 지표로 변경 [P5]
- **파일**: `step5_extraction_validator.py` — `_judge`
- **변경**: E5를 판정(PASS/FAIL)에서 완전 제외, 리포트에만 기록
- **이유**: LLM 자체 감사의 도메인 한계로 정확한 데이터도 낮은 점수

---

## 검증 결과

### E5 점수 비교

| 항목 | Before | After | 변화 |
|---|---|---|---|
| completeness | 0.49 | 0.42 | -14% ※ |
| accuracy | 0.57 | **0.67** | **+18%** ✅ |
| no_hallucination | 0.72 | 0.69 | -4% |
| relationship_quality | 0.47 | **0.53** | **+13%** ✅ |
| **가중평균** | 0.568 | **0.586** | **+3%** |

※ completeness는 랜덤 샘플링 변동 + LLM 감사 자체 한계

### 전체 검증 Verdict

| 항목 | Before | After |
|---|---|---|
| E1 커버리지 | ✅ 95.9% | ✅ 95.9% |
| E2 참조 무결성 | ✅ 100% | ✅ 100% |
| E3 수량-단위 일관성 | ✅ 98.7% | ✅ 98.7% |
| E4 고아 엔티티 | ✅ 21.5% | ✅ 21.5% |
| E5 LLM 감사 | ❌ 0.568 | ❌ 0.586 (참고) |
| E6 할루시네이션 | ✅ 12.9% | ✅ 12.9% |
| **Verdict** | **CONDITIONAL_PASS** | **PASS** ✅ |

---

## 다음 단계

- [ ] Edge Function 재배포: `supabase functions deploy rag-chat`
- [ ] RAG 챗봇 실제 답변 테스트 (강관용접, 크러셔 등)

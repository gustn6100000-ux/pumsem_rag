[{"name": "index.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// RAG ì±—ë´‡ Edge Function â€” rag-chat/index.ts\n// Phase 2: ëª¨ë“ˆ Import êµ¬ì¡° (ë¦¬íŒ©í† ë§ ì™„ë£Œ)\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport \"jsr:@supabase/functions-js/edge-runtime.d.ts\";\n\n// â”â”â” [A] ëª¨ë“ˆ Import â”â”â”\nimport {\n    supabase,\n    RAG_API_KEY,\n    getCorsHeaders,\n    checkRateLimit,\n} from \"./config.ts\";\nimport { generateEmbedding } from \"./embedding.ts\";\nimport type {\n    ChatMessage,\n    ChatRequest,\n    SessionContext,\n    SourceInfo,\n    ClarifyOption,\n    ChatResponse,\n    IntentAnalysis,\n    EntityResult,\n    RelatedResource,\n    IlwiItem,\n    ChunkResult,\n    AnswerOptions,\n} from \"./types.ts\";\nimport { targetSearch } from \"./search.ts\";\nimport {\n    expandGraph,\n    searchIlwi,\n    retrieveChunks,\n    fetchLaborCosts,\n} from \"./graph.ts\";\nimport {\n    analyzeIntent,\n    detectCostIntent,\n    extractSpec,\n    graphClarify,\n    normalizeSpec,\n} from \"./clarify.ts\";\nimport { generateAnswer } from \"./llm.ts\";\nimport {\n    makeAnswerResponse,\n    makeClarifyResponse,\n} from \"./context.ts\";\nimport { buildSelectorPanel } from \"./resolve.ts\";\n\n// â”â”â” [D] ì»¨í…ìŠ¤íŠ¸ ì¡°í•© â”â”â”\n\n// â”€â”€â”€ ë§¤íŠ¸ë¦­ìŠ¤(êµì°¨í‘œ) ë Œë”ë§ â”€â”€â”€\n// Why: ë™ì¼ ì§ì¢…ì´ ì—¬ëŸ¬ ê¸°ì¤€(SCH, ê·œê²©, ì‘ì—…ì¡°ê±´ ë“±)ì— ê±¸ì³ ë°˜ë³µë  ë•Œ\n//      í”Œë« 4ì—´ í…Œì´ë¸” ëŒ€ì‹  í–‰=ì§ì¢…, ì—´=ê¸°ì¤€ì˜ êµì°¨í‘œë¡œ ì¶œë ¥í•˜ë©´\n//      ì‹¤ë¬´ìê°€ í•œëˆˆì— ì¡°ê±´ ê°„ ìˆ˜ì¹˜ë¥¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤.\nfunction renderMatrixTable(\n    items: RelatedResource[],\n    sectionId: string,\n    categoryLabel: string,  // \"íˆ¬ì… ì¸ë ¥\" | \"íˆ¬ì… ì¥ë¹„\" | \"ì‚¬ìš© ìì¬\"\n    nameLabel: string,      // \"ì§ì¢…\" | \"ì¥ë¹„ëª…\" | \"ìì¬ëª…\"\n): string {\n    if (items.length === 0) return \"\";\n\n    // 1) ê° í•­ëª©ì—ì„œ ì´ë¦„ê³¼ ê¸°ì¤€(spec) ì¶”ì¶œ\n    type Row = { name: string; spec: string; quantity: string; unit: string };\n    const rows: Row[] = items.map((item) => {\n        const props = (item.properties || {}) as any;\n        let specFallback = \"-\";\n        if (item.related_name.includes('_')) specFallback = item.related_name.split('_')[0];\n        const spec = props.source_spec || props.spec || props.per_unit || props.work_type_name || specFallback;\n        const itemName = item.related_name.includes('_') ? item.related_name.split('_')[1] : item.related_name;\n        return {\n            name: itemName,\n            spec: String(spec || \"-\"),\n            quantity: String(props.quantity ?? \"-\"),\n            unit: String(props.unit ?? (nameLabel === \"ì§ì¢…\" ? \"ì¸\" : \"-\")),\n        };\n    });\n\n    // 2) ê³ ìœ  ê¸°ì¤€(spec) ëª¨ìœ¼ê¸° â€” ë“±ì¥ ìˆœì„œ ìœ ì§€\n    const specSet = new Set<string>();\n    rows.forEach(r => specSet.add(r.spec));\n    const specs = Array.from(specSet);\n\n    // 3) ê¸°ì¤€ì´ 1ê°œ ì´í•˜ë©´ ì‹¬í”Œ(í”Œë«) í…Œì´ë¸”ë¡œ í´ë°±\n    if (specs.length <= 1) {\n        const lines: string[] = [];\n        lines.push(`**[í‘œ ${sectionId}] ${categoryLabel}**\\n`);\n        lines.push(`| ${nameLabel} | ìˆ˜ëŸ‰ | ë‹¨ìœ„ | ê¸°ì¤€ |`);\n        lines.push(\"| --- | ---: | --- | --- |\");\n        rows.forEach(r => {\n            lines.push(`| ${r.name} | ${r.quantity} | ${r.unit} | ${r.spec} |`);\n        });\n        lines.push(\"\");\n        return lines.join(\"\\n\");\n    }\n\n    // 4) ê³ ìœ  ì´ë¦„(ì§ì¢…) ëª¨ìœ¼ê¸° â€” ë“±ì¥ ìˆœì„œ ìœ ì§€\n    const nameSet = new Set<string>();\n    rows.forEach(r => nameSet.add(r.name));\n    const names = Array.from(nameSet);\n\n    // 5) (ì´ë¦„, ê¸°ì¤€) â†’ ìˆ˜ëŸ‰ ë§¤í•‘\n    const matrix = new Map<string, string>();\n    rows.forEach(r => {\n        matrix.set(`${r.name}||${r.spec}`, r.quantity);\n    });\n\n    // 6) ë‹¨ìœ„ ì •ë³´ (ì²« ë²ˆì§¸ í•­ëª©ì—ì„œ)\n    const unitInfo = rows[0]?.unit || \"\";\n\n    // 7) ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±\n    const lines: string[] = [];\n    lines.push(`**[í‘œ ${sectionId}] ${categoryLabel}** (ë‹¨ìœ„: ${unitInfo})\\n`);\n\n    // í—¤ë”í–‰\n    const header = `| ${nameLabel} | ` + specs.join(\" | \") + \" |\";\n    const sep = \"| --- | \" + specs.map(() => \"---:\").join(\" | \") + \" |\";\n    lines.push(header);\n    lines.push(sep);\n\n    // ë°ì´í„°í–‰\n    names.forEach(name => {\n        const cells = specs.map(spec => {\n            return matrix.get(`${name}||${spec}`) ?? \"â€”\";\n        });\n        lines.push(`| ${name} | ` + cells.join(\" | \") + \" |\");\n    });\n    lines.push(\"\");\n    return lines.join(\"\\n\");\n}\n\n// â”€â”€â”€ tables JSON â†’ Markdown í…Œì´ë¸” ë³€í™˜ â”€â”€â”€\n// Why: graph_chunks.tablesëŠ” JSONì´ë¯€ë¡œ LLMì´ ì´í•´í•˜ë ¤ë©´ Markdown ë³€í™˜ í•„ìš”\nfunction tablesToMarkdown(tables: any[]): string {\n    return tables.map(t => {\n        if (!t.rows || t.rows.length === 0) return \"\";\n        const headers: string[] = t.headers || Object.keys(t.rows[0]);\n        const headerRow = \"| \" + headers.join(\" | \") + \" |\";\n        const sepRow = \"| \" + headers.map(() => \"---\").join(\" | \") + \" |\";\n        const dataRows = t.rows.map((r: any) =>\n            \"| \" + headers.map((h: string) => r[h] ?? \"\").join(\" | \") + \" |\"\n        );\n        // í‘œ í•˜ë‹¨ ì£¼ì„ (ì²« ë²ˆì§¸ ê²ƒë§Œ, 200ì ì œí•œ)\n        const noteText = (t.notes_in_table && t.notes_in_table.length > 0)\n            ? `\\n> ${t.notes_in_table[0].substring(0, 300)}`\n            : \"\";\n        return [headerRow, sepRow, ...dataRows, noteText].filter(Boolean).join(\"\\n\");\n    }).filter(Boolean).join(\"\\n\\n\");\n}\n\nfunction buildContext(\n    entities: EntityResult[],\n    relationsAll: RelatedResource[][],\n    ilwiResults: IlwiItem[],\n    chunks: ChunkResult[],\n    specFilter?: string   // entity ì§ì ‘ ì¡°íšŒ ì‹œ ë‘ê»˜/í˜¸ì¹­ê²½ ë“± spec ê¸°ì¤€ í•„í„°\n): string {\n    const parts: string[] = [];\n\n    // í’ˆì…ˆ ê²€ìƒ‰ ê²°ê³¼\n    parts.push(\"## í’ˆì…ˆ ê²€ìƒ‰ ê²°ê³¼\\n\");\n\n    entities.forEach((entity, idx) => {\n        const relations = relationsAll[idx] || [];\n        const chunk = chunks.find((c) => c.section_id === entity.source_section);\n\n        // ì¶œì²˜ ë¼ë²¨ êµ¬ì„± (Codex F4)\n        const sectionLabel = chunk\n            ? `${chunk.department} > ${chunk.chapter} > ${chunk.title}`\n            : entity.source_section || \"ì¶œì²˜ ë¯¸í™•ì¸\";\n\n        // í‘œë²ˆí˜¸ ëª…ì‹œ (ì˜ˆ: [í‘œ 13-5-1])\n        const sectionId = entity.source_section || \"\";\n\n        parts.push(\n            `### ${idx + 1}. [í‘œ ${sectionId}] ${entity.name} (${entity.type}, ìœ ì‚¬ë„: ${entity.similarity?.toFixed(3)})`\n        );\n        parts.push(`**í‘œë²ˆí˜¸**: ${sectionId}`);\n        parts.push(`**ì¶œì²˜**: ${sectionLabel}\\n`);\n\n        // Fix 4: ì—”í‹°í‹° ì†ì„± í‘œì‹œ (ê·œê²©, ìˆ˜ëŸ‰, ë‹¨ìœ„ ë“±)\n        // Why: LLMì´ ì—”í‹°í‹°ì˜ ì„¸ë¶€ ì†ì„±(spec, quantity ë“±)ì„ ì•Œì•„ì•¼ ì •í™•í•œ ë‹µë³€ ê°€ëŠ¥\n        const entityProps = entity.properties || {};\n        const propEntries = Object.entries(entityProps)\n            .filter(([k]) => !['embedding', 'source_chunk_ids', 'chunk_id'].includes(k))\n            .filter(([, v]) => v !== null && v !== undefined && v !== '');\n        if (propEntries.length > 0) {\n            parts.push(`**ì†ì„±**: ${propEntries.map(([k, v]) => `${k}=${v}`).join(', ')}\\n`);\n        }\n\n        // ê´€ê³„ë³„ ê·¸ë£¹í™”\n        const grouped = new Map<string, RelatedResource[]>();\n        relations.forEach((r) => {\n            const key = r.relation;\n            if (!grouped.has(key)) grouped.set(key, []);\n            grouped.get(key)!.push(r);\n        });\n\n        // â”€â”€â”€ íˆ¬ì… ì¸ë ¥ (ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§) â”€â”€â”€\n        const labor = grouped.get(\"REQUIRES_LABOR\") || [];\n        if (labor.length > 0) {\n            parts.push(renderMatrixTable(labor, sectionId, \"íˆ¬ì… ì¸ë ¥\", \"ì§ì¢…\"));\n        }\n\n        // íˆ¬ì… ì¥ë¹„ (ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§)\n        const equipment = grouped.get(\"REQUIRES_EQUIPMENT\") || [];\n        if (equipment.length > 0) {\n            parts.push(renderMatrixTable(equipment, sectionId, \"íˆ¬ì… ì¥ë¹„\", \"ì¥ë¹„ëª…\"));\n        }\n\n        // ì‚¬ìš© ìì¬ (ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§)\n        const material = grouped.get(\"USES_MATERIAL\") || [];\n        if (material.length > 0) {\n            parts.push(renderMatrixTable(material, sectionId, \"ì‚¬ìš© ìì¬\", \"ìì¬ëª…\"));\n        }\n\n        // ì£¼ì˜ì‚¬í•­ â€” Note ì—”í‹°í‹°ì˜ ì›ë¬¸ ìš°ì„  í‘œì‹œ\n        // ë°ì´í„° êµ¬ì¡°: note_13-2-3_* â†’ properties.contentì— ì›ë¬¸ ì €ì¥ (expandGraphì—ì„œ note_contentë¡œ ë§¤í•‘)\n        //              Back Mirror ë“± â†’ properties.spec(ì¡°ê±´)/quantity(ê³„ìˆ˜) ì €ì¥\n        // Why: quantityëŠ” ê³„ìˆ˜(0.3)ì´ì§€ë§Œ ì›ë¬¸ì€ %(30%) í‘œê¸° â†’ ë³€í™˜ í•„ìš”\n        const notes = grouped.get(\"HAS_NOTE\") || [];\n        if (notes.length > 0) {\n            // ì¤‘ë³µ ì œê±°: note_content(ì›ë¬¸)ê°€ ìˆëŠ” í•­ëª©ê³¼ ê°œë³„ Noteê°€ ê²¹ì¹  ìˆ˜ ìˆìŒ\n            const seen = new Set<string>();\n            parts.push(`**[í‘œ ${sectionId}] ì£¼ì˜ì‚¬í•­**\\n`);\n            notes.forEach((n) => {\n                const props = (n.properties || {}) as any;\n                const content = props.note_content;  // expandGraphì—ì„œ ì£¼ì…ëœ ì›ë¬¸\n                const spec = props.spec;\n                const quantity = props.quantity;\n\n                if (content) {\n                    // ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶œë ¥ (note_13-2-3_* ì—”í‹°í‹°)\n                    const key = content.substring(0, 30);\n                    if (!seen.has(key)) {\n                        seen.add(key);\n                        parts.push(`- ${content}`);\n                    }\n                } else {\n                    // ê°œë³„ Note (Back Mirror ë“±): quantityë¥¼ %ë¡œ ë³€í™˜\n                    const key = n.related_name;\n                    if (seen.has(key)) return;\n                    seen.add(key);\n\n                    let detail = n.related_name;\n                    if (quantity) {\n                        const pct = Math.round(Number(quantity) * 100);\n                        const action = n.related_name.includes('ê°') ? 'ê°' : 'ê°€ì‚°';\n                        if (spec) {\n                            detail += `(${spec}): ${pct}%ê¹Œì§€ ${action}`;\n                        } else {\n                            detail += `: ${pct}%ê¹Œì§€ ${action}`;\n                        }\n                    } else if (spec) {\n                        detail += ` â€” ${spec}`;\n                    }\n                    parts.push(`- ${detail}`);\n                }\n            });\n            parts.push(\"\");\n        }\n\n        parts.push(\"---\\n\");\n    });\n\n    // ì¼ìœ„ëŒ€ê°€ ë¹„ìš© ì •ë³´\n    if (ilwiResults.length > 0) {\n        parts.push(\"## ì¼ìœ„ëŒ€ê°€ ë¹„ìš© ì •ë³´\\n\");\n        parts.push(\"| í•­ëª© | ê·œê²© | ë…¸ë¬´ë¹„ | ì¬ë£Œë¹„ | ê²½ë¹„ | í•©ê³„ |\");\n        parts.push(\"| --- | --- | --- | --- | --- | --- |\");\n        ilwiResults.slice(0, 5).forEach((item) => {\n            parts.push(\n                `| ${item.name} | ${item.spec || \"-\"} | ${item.labor_cost?.toLocaleString() ?? \"-\"} | ${item.material_cost?.toLocaleString() ?? \"-\"} | ${item.expense_cost?.toLocaleString() ?? \"-\"} | ${item.total_cost?.toLocaleString() ?? \"-\"} |`\n            );\n        });\n        parts.push(\"\");\n    }\n\n    // ì›ë¬¸ ì°¸ê³ \n    // specFilterê°€ ìˆìœ¼ë©´ ì›ë¬¸ ì°¸ê³  ìƒëµ: ê·¸ë˜í”„ ê´€ê³„(REQUIRES_LABOR ë“±)ì—ì„œ ì •í™•í•œ ìˆ˜ì¹˜ ì œê³µ\n    // Why: chunk.textì— ì „ ë²”ìœ„ ë°ì´í„°(ë‘ê»˜=3~50)ê°€ í¬í•¨ â†’ LLMì´ ê·¸ë˜í”„ ë¬´ì‹œí•˜ê³  ì›ë¬¸ ê¸°ì¤€ ì „ì²´ ì¶œë ¥í•˜ëŠ” ë¬¸ì œ\n    if (chunks.length > 0 && !specFilter) {\n        parts.push(\"## ì›ë¬¸ ì°¸ê³  (í’ˆì…ˆ ì›ë¬¸)\\n\");\n        chunks.forEach((chunk) => {\n            parts.push(`> **${chunk.section_id} ${chunk.title}**`);\n            parts.push(`> ${chunk.text}`);\n            parts.push(\"\");\n        });\n    } else if (chunks.length > 0 && specFilter) {\n        // spec í•„í„° ì ìš© ì‹œ: ì¶œì²˜ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ì œê³µ\n        parts.push(\"## ì›ë¬¸ ì¶œì²˜\\n\");\n        chunks.forEach((chunk) => {\n            parts.push(`> **[í‘œ ${chunk.section_id}] ${chunk.title}** (${chunk.department} > ${chunk.chapter})`);\n            parts.push(\"\");\n        });\n    }\n\n    return parts.join(\"\\n\");\n}\n\n// â”â”â” [G] íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ â”â”â”\n\n// â”€â”€â”€ answerPipeline: entity â†’ graph í™•ì¥ â†’ context â†’ LLM â†’ ì‘ë‹µ â”€â”€â”€\n// Why: Phase -1(entity_id ì§ì ‘ì¡°íšŒ)ê³¼ Phase 1b(search ê²°ê³¼ ë‹µë³€)ì˜ ì¤‘ë³µ ë¡œì§ì„ í†µí•©\nasync function answerPipeline(\n    entities: EntityResult[],\n    question: string,\n    history: ChatMessage[],\n    startTime: number,\n    opts?: {\n        skipSiblings?: boolean;   // entity_id ì§ì ‘ì¡°íšŒ ì‹œ í˜•ì œ WT ìŠ¤í‚µ\n        specFilter?: string;      // ë‘ê»˜/ê·œê²© í•„í„°\n        answerOptions?: AnswerOptions;\n        analysis?: IntentAnalysis;\n    }\n): Promise<ChatResponse> {\n    const embeddingTokens = Math.ceil(question.length / 2);\n    const skipSiblings = opts?.skipSiblings ?? false;\n    const specFilter = opts?.specFilter;\n\n    // ğŸ’¡ [í•µì‹¬ íŒ¨ì¹˜] OOM ë°©ì§€ ë° í•˜ìœ„ ë¡œì§ ì¸ë±ìŠ¤ ë¶ˆì¼ì¹˜ ë°©ì§€ë¥¼ ìœ„í•´ ìƒìœ„ 10ê±´ í™•ì •\n    const targetEntities = entities.slice(0, 10);\n\n    // [1] ê·¸ë˜í”„ í™•ì¥ (ë³‘ë ¬)\n    // ğŸ’¡ [í•µì‹¬ íŒ¨ì¹˜] Caller ë ˆë²¨ì—ì„œ source_section ì¤‘ë³µ ë°©ë¬¸ ì°¨ë‹¨ (ì—°ì‡„ íŒ½ì°½ ë°©ì§€)\n    const visitedSections = new Set<string>();\n    const relationsPromises = targetEntities.map(async (e) => {\n        // source_section ì¤‘ë³µ ë°©ë¬¸ ì°¨ë‹¨\n        if (e.source_section && visitedSections.has(e.source_section)) {\n            // ë™ì¼ sectionì€ skipSectionExpansion=trueë¡œ 1-hopë§Œ ì¡°íšŒ\n            return expandGraph(e.id, e.type, true);\n        }\n        if (e.source_section) visitedSections.add(e.source_section);\n\n        return expandGraph(e.id, e.type, skipSiblings);\n    });\n    const relationsAll = await Promise.all(relationsPromises);\n\n    // [2] ë¹„ìš© ì˜ë„ â†’ ì¼ìœ„ëŒ€ê°€ ê²€ìƒ‰\n    let ilwiResults: IlwiItem[] = [];\n    if (detectCostIntent(question)) {\n        for (const e of targetEntities.filter(e => e.type === \"WorkType\")) {\n            const spec = extractSpec(question);\n            const items = await searchIlwi(e.name, spec);\n            if (items.length > 0) { ilwiResults.push(...items); break; }\n        }\n    }\n\n    // [3] ì›ë¬¸ ì²­í¬ ë³´ê°•\n    const chunks = await retrieveChunks(targetEntities, specFilter);\n    if (specFilter) console.log(`[answerPipeline] specFilter=\"${specFilter}\" ì ìš©`);\n\n    // [4] ì»¨í…ìŠ¤íŠ¸ ì¡°í•©\n    let context = buildContext(targetEntities, relationsAll, ilwiResults, chunks, specFilter);\n\n    // [4-1] cost_calculate/report_request ì‹œ ë…¸ì„ë‹¨ê°€ ì£¼ì…\n    const effectiveIntent = opts?.answerOptions?.intent || opts?.analysis?.intent;\n    if (effectiveIntent === \"cost_calculate\" || effectiveIntent === \"report_request\") {\n        const laborNames = relationsAll.flat()\n            .filter(r => r.relation === \"REQUIRES_LABOR\")\n            .map(r => r.related_name)\n            .filter(Boolean);\n        if (laborNames.length > 0) {\n            const laborCosts = await fetchLaborCosts(laborNames);\n            if (laborCosts.length > 0) {\n                context += \"\\n\\n## [2026ë…„ ë…¸ì„ë‹¨ê°€]\\n\";\n                context += \"| ì§ì¢… | ë…¸ì„ë‹¨ê°€(ì›/ì¼) |\\n|---|---:|\\n\";\n                laborCosts.forEach(lc => {\n                    context += `| ${lc.job_name} | ${lc.cost_2026.toLocaleString()} |\\n`;\n                });\n            }\n        }\n    }\n\n    // [5] LLM ë‹µë³€ ìƒì„±\n    const llmResult = await generateAnswer(question, context, history, {\n        intent: effectiveIntent,\n        quantity: opts?.answerOptions?.quantity || opts?.analysis?.quantity || undefined,\n    });\n\n    // [6] ì‘ë‹µ ì¡°ë¦½\n    const sourcesWithSection: SourceInfo[] = targetEntities.map(e => {\n        const chunk = chunks.find(c => c.section_id === e.source_section);\n        return {\n            entity_id: e.id,\n            entity_name: e.name,\n            entity_type: e.type,\n            source_section: e.source_section,\n            section_label: chunk\n                ? `${chunk.department} > ${chunk.chapter} > ${chunk.title}`\n                : e.source_section || undefined,\n            similarity: e.similarity,\n        };\n    });\n\n    return makeAnswerResponse(llmResult.answer, startTime, {\n        sources: sourcesWithSection,\n        entities: targetEntities, relations: relationsAll,\n        ilwi: ilwiResults, chunks,\n        embeddingTokens, llmResult,\n    });\n}\n\n// â”€â”€â”€ fullViewPipeline: section ì „ì²´ ì›ë¬¸ â†’ WorkType íƒìƒ‰ â†’ context â†’ LLM â”€â”€â”€\n// Why: full_view 4ë‹¨ê³„ í´ë°±(ì§ì ‘â†’cross-refâ†’í•˜ìœ„ì ˆâ†’Section) ë¡œì§ì„ handleChatì—ì„œ ë¶„ë¦¬\nasync function fullViewPipeline(\n    sectionId: string,\n    question: string,\n    history: ChatMessage[],\n    startTime: number\n): Promise<ChatResponse> {\n    const embeddingTokens = Math.ceil(question.length / 2);\n\n    // â”€â”€ sub_section íŒŒì‹±: \"13-2-4:sub=1. ì „ê¸°ì•„í¬ìš©ì ‘(Ví˜•)\" â†’ base + sub í‚¤ì›Œë“œ\n    const decodedSectionId = decodeURIComponent(sectionId);\n    const subMatch = decodedSectionId.match(/^(.+?):sub=(.+)$/);\n    const baseSectionId = subMatch ? subMatch[1] : decodedSectionId;\n    const subKeyword = subMatch ? subMatch[2].replace(/^\\d+\\.\\s*/, '') : null;\n\n    console.log(`[fullViewPipeline] base=${baseSectionId}, sub=${subKeyword || 'none'} ì „ì²´ ì›ë¬¸ ì¡°íšŒ`);\n\n    // [1] ì „ì²´ chunk ë¡œë”©\n    const { data: chunkData } = await supabase\n        .from(\"graph_chunks\")\n        .select(\"id, section_id, title, department, chapter, section, text, tables\")\n        .eq(\"section_id\", baseSectionId)\n        .limit(20);\n\n    let allChunks = (chunkData || []) as any[];\n\n    // [1-1] sub_section í•„í„°\n    if (subKeyword && allChunks.length > 1) {\n        const filtered = allChunks.filter(c =>\n            (c.text && c.text.includes(subKeyword)) ||\n            (c.tables && JSON.stringify(c.tables).includes(subKeyword))\n        );\n        if (filtered.length > 0) {\n            console.log(`[fullViewPipeline] sub \"${subKeyword}\" í•„í„°: ${allChunks.length}ê±´ â†’ ${filtered.length}ê±´`);\n            allChunks = filtered;\n        }\n    }\n\n    // [2] chunk ë³‘í•© (text + tables â†’ í•˜ë‚˜ì˜ ë©”íƒ€ chunk)\n    const chunk = allChunks[0] ? { ...allChunks[0] } : null;\n    if (chunk && allChunks.length >= 1) {\n        chunk.text = allChunks\n            .map(c => {\n                let t = c.text || \"\";\n                if (c.tables && Array.isArray(c.tables) && c.tables.length > 0) {\n                    t += (t ? \"\\n\" : \"\") + tablesToMarkdown(c.tables);\n                }\n                return t;\n            })\n            .filter(t => t.length > 0)\n            .join(\"\\n\\n\");\n        console.log(`[fullViewPipeline] ${allChunks.length}ê±´ chunk ë³‘í•©, text_len=${chunk.text.length}`);\n    }\n\n    if (!chunk) {\n        console.warn(`[fullViewPipeline] section_id=${baseSectionId} ì›ë¬¸ ì—†ìŒ â†’ ì•ˆë‚´`);\n        return makeAnswerResponse(\n            `í•´ë‹¹ ì ˆ(${baseSectionId})ì˜ ì›ë¬¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\në‹¤ë¥¸ ì‘ì—…ì„ ì„ íƒí•˜ê±°ë‚˜, ë‹¤ì‹œ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.`,\n            startTime\n        );\n    }\n\n    // [3] WorkType 4ë‹¨ê³„ í´ë°± íƒìƒ‰\n    let wtEntities: EntityResult[] = [];\n    let relationsAll: any[][] = [];\n\n    // 3-1: ì§ì ‘ ë§¤ì¹­\n    const { data: sectionWTData } = await supabase\n        .from(\"graph_entities\")\n        .select(\"id, name, type, properties, source_section\")\n        .eq(\"type\", \"WorkType\")\n        .eq(\"source_section\", baseSectionId)\n        .limit(20);\n\n    const sectionWTs = (sectionWTData || []) as any[];\n    console.log(`[fullViewPipeline] WorkType ${sectionWTs.length}ê±´ (baseSectionId=${baseSectionId})`);\n\n    if (sectionWTs.length > 0) {\n        wtEntities = sectionWTs.map(wt => ({\n            id: wt.id, name: wt.name, type: wt.type,\n            properties: wt.properties || {},\n            source_section: wt.source_section,\n            similarity: 1.0,\n        }));\n        const rp = wtEntities.map(e => expandGraph(e.id, e.type));\n        relationsAll = await Promise.all(rp);\n    } else {\n        // 3-2: cross-reference (ë™ì¼ titleì˜ ë‹¤ë¥¸ section)\n        console.log(`[fullViewPipeline] baseSectionId=${baseSectionId} WorkType 0ê±´ â†’ cross-reference íƒìƒ‰`);\n        const { data: siblings } = await supabase\n            .from(\"graph_chunks\")\n            .select(\"section_id\")\n            .eq(\"title\", chunk.title)\n            // ğŸ’¡ [í•µì‹¬ íŒ¨ì¹˜] ë„ë©”ì¸ ê²©ë¦¬: ë™ì¼ ë¶€ë¬¸(department)ê³¼ ì¥(chapter)ì´ ì¼ì¹˜í•  ë•Œë§Œ ë³‘í•©\n            .eq(\"department\", chunk.department)\n            .eq(\"chapter\", chunk.chapter);\n        const siblingIds = [...new Set(\n            (siblings || []).map((s: any) => s.section_id).filter((sid: string) => sid !== baseSectionId)\n        )];\n\n        if (siblingIds.length > 0) {\n            const { data: siblingWTs } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .eq(\"type\", \"WorkType\")\n                .in(\"source_section\", siblingIds)\n                .limit(30);\n\n            if (siblingWTs && siblingWTs.length > 0) {\n                console.log(`[fullViewPipeline] cross-refì—ì„œ ${siblingWTs.length}ê±´ WorkType ë°œê²¬`);\n                wtEntities = (siblingWTs as any[]).map(wt => ({\n                    id: wt.id, name: wt.name, type: wt.type,\n                    properties: wt.properties || {},\n                    source_section: wt.source_section,\n                    similarity: 0.95,\n                }));\n                const rp = wtEntities.map(e => expandGraph(e.id, e.type));\n                relationsAll = await Promise.all(rp);\n            }\n        }\n\n        if (wtEntities.length === 0) {\n            // 3-3: í•˜ìœ„ ì ˆ(children) WorkType íƒìƒ‰\n            const childBaseSectionId = baseSectionId.includes('#') ? baseSectionId.split('#')[0] : baseSectionId;\n            const childPrefix = childBaseSectionId + '-';\n            console.log(`[fullViewPipeline] cross-ref ì‹¤íŒ¨ â†’ í•˜ìœ„ ì ˆ íƒìƒ‰ (prefix=${childPrefix})`);\n\n            const { data: childWTs } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .eq(\"type\", \"WorkType\")\n                .ilike(\"source_section\", `${childPrefix}%`)\n                .limit(50);\n\n            if (childWTs && childWTs.length > 0) {\n                console.log(`[fullViewPipeline] í•˜ìœ„ ì ˆì—ì„œ ${childWTs.length}ê±´ WorkType ë°œê²¬`);\n                wtEntities = (childWTs as any[]).map(wt => ({\n                    id: wt.id, name: wt.name, type: wt.type,\n                    properties: wt.properties || {},\n                    source_section: wt.source_section,\n                    similarity: 0.98,\n                }));\n                const rp = wtEntities.map(e => expandGraph(e.id, e.type));\n                relationsAll = await Promise.all(rp);\n\n                // í•˜ìœ„ ì ˆ chunk í…ìŠ¤íŠ¸ ë³´ê°•\n                const childSectionIds = [...new Set(childWTs.map((w: any) => w.source_section))];\n                const { data: childChunks } = await supabase\n                    .from(\"graph_chunks\")\n                    .select(\"id, section_id, title, department, chapter, section, text\")\n                    .in(\"section_id\", childSectionIds)\n                    .limit(10);\n\n                if (childChunks && childChunks.length > 0) {\n                    const childTexts = (childChunks as any[])\n                        .filter(c => c.text && c.text.length > 10)\n                        .map(c => `### ${c.section_id} ${c.title}\\n${c.text}`)\n                        .join('\\n\\n');\n                    if (childTexts) chunk.text = (chunk.text || '') + '\\n\\n' + childTexts;\n                }\n            } else {\n                // 3-4: Section ìì²´ í™•ì¥ (ìµœí›„ ìˆ˜ë‹¨)\n                const { data: sectionEntity } = await supabase\n                    .from(\"graph_entities\")\n                    .select(\"id, name, type, properties, source_section\")\n                    .eq(\"type\", \"Section\")\n                    .eq(\"source_section\", baseSectionId)\n                    .limit(1);\n\n                if (sectionEntity && sectionEntity.length > 0) {\n                    const se = sectionEntity[0] as any;\n                    wtEntities = [{\n                        id: se.id, name: se.name, type: se.type,\n                        properties: se.properties || {},\n                        source_section: se.source_section,\n                        similarity: 1.0,\n                    }];\n                    const sectionRels = await expandGraph(se.id, \"Section\");\n                    relationsAll = [sectionRels];\n                }\n            }\n        }\n    }\n\n    // [4] ì›ë¬¸ + ê·¸ë˜í”„ ê´€ê³„ ì»¨í…ìŠ¤íŠ¸ â†’ LLM â†’ ì‘ë‹µ\n    const context = [\n        `## í’ˆì…ˆ ì›ë¬¸: ${chunk.title}`,\n        `**ì¶œì²˜**: ${chunk.department} > ${chunk.chapter} > ${chunk.title}`,\n        `**í‘œë²ˆí˜¸**: ${chunk.section_id}`,\n        `\\n${chunk.text}`,\n        `\\n---\\n`,\n        buildContext(wtEntities, relationsAll, [], [chunk as ChunkResult]),\n    ].join(\"\\n\");\n\n    const llmResult = await generateAnswer(question, context, history);\n\n    return makeAnswerResponse(llmResult.answer, startTime, {\n        sources: [{\n            entity_name: chunk.title,\n            entity_type: \"Section\",\n            source_section: chunk.section_id,\n            section_label: `${chunk.department} > ${chunk.chapter} > ${chunk.title}`,\n            similarity: 1.0,\n        }],\n        entities: wtEntities, relations: relationsAll,\n        chunks: [chunk as any],\n        embeddingTokens, llmResult,\n    });\n}\n\n// â”€â”€â”€ searchPipeline: embedding â†’ targetSearch â†’ Section-Only ë¶„ê¸° â†’ answer â”€â”€â”€\n// Why: ê²€ìƒ‰ + ê²°ê³¼ í‰ê°€ + ë‹µë³€/clarify ë¶„ê¸°ë¥¼ handleChatì—ì„œ ë¶„ë¦¬\nasync function searchPipeline(\n    analysis: IntentAnalysis,\n    question: string,\n    history: ChatMessage[],\n    startTime: number,\n    answerOptions?: AnswerOptions\n): Promise<ChatResponse> {\n    const embeddingTokens = Math.ceil(question.length / 2);\n\n    // [1] ì§ˆë¬¸ ì„ë² ë”©\n    const embedding = await generateEmbedding(question);\n\n    // [1-1] ğŸ’¡ [Track B-1 ìµœì í™”] ë™ì˜ì–´ ì¬ë£Œ ì¦‰ì‹œ ì¶”ì¶œ (targetSearch ëŒ€ê¸° ë¶ˆí•„ìš”)\n    // Why: domainExpëŠ” analysis(LLM ë¶„ì„ ê²°ê³¼)ì—ì„œë§Œ ì‚°ì¶œ. targetSearch ê²°ê³¼ ì˜ì¡´ ì—†ìŒ.\n    //      ë”°ë¼ì„œ targetSearchì™€ ë™ì˜ì–´ WorkType ì¿¼ë¦¬ë¥¼ Promise.allë¡œ ë³‘ë ¬ ì‹¤í–‰í•˜ì—¬\n    //      ìˆœì°¨ I/O ëŒ€ê¸°ì‹œê°„(+1.4s)ì„ targetSearchì˜ ëŒ€ê¸°ì‹œê°„ì— ì™„ì „íˆ ê°€ë ¤(Shadowing) ì œê±°.\n    const { expandDomainSynonyms } = await import(\"./search.ts\");\n    const domainTerms = analysis.work_name\n        ? [analysis.work_name, ...(analysis.keywords || [])]\n        : analysis.keywords || [];\n    const domainExp = expandDomainSynonyms(domainTerms);\n    const synOrClauses = domainExp.length > 0\n        ? domainExp.map(s => `name.ilike.%${s}%`).join(\",\")\n        : null;\n\n    // [1-2] ğŸ’¡ ë©”ì¸ ê²€ìƒ‰ + ë™ì˜ì–´ ì„œë¸Œ ê²€ìƒ‰ì„ Promise.allë¡œ ë³‘ë ¬ ì¶œë°œ\n    const [entities, synWTsResponse] = await Promise.all([\n        targetSearch(analysis, embedding, question),\n        synOrClauses\n            ? supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, source_section, properties\")\n                .eq(\"type\", \"WorkType\")\n                .or(synOrClauses)\n                .limit(50)\n            : Promise.resolve({ data: [] as any[], error: null }),\n    ]);\n    const synonymWorkTypes = synWTsResponse.data || [];\n    if (synonymWorkTypes.length > 0) {\n        console.log(`[searchPipeline] ë„ë©”ì¸ ë™ì˜ì–´ WorkType: ${synonymWorkTypes.length}ê±´ (${domainExp.join(\",\")})`);\n    }\n\n    // [2] Sectionë§Œ ë§¤ì¹­ â†’ clarify ë¶„ê¸°\n    const sectionOnly = entities.length > 0 && entities.every(e => e.type === \"Section\");\n    if (sectionOnly) {\n        const sectionSourceIds = [...new Set(entities.map(e => e.source_section).filter(Boolean))] as string[];\n\n        // Section source_section + ë™ì˜ì–´ WorkType source_section ë³‘í•©\n        const synSectionIds = [...new Set(synonymWorkTypes.map(w => w.source_section).filter(Boolean))] as string[];\n        const allSectionIds = [...new Set([...sectionSourceIds, ...synSectionIds])];\n\n        if (allSectionIds.length > 1) {\n            // ë³µìˆ˜ ë¶„ì•¼: ì„¹ì…˜ ì„ íƒ ì¹© ì§ì ‘ ìƒì„±\n            console.log(`[searchPipeline] Section ${sectionSourceIds.length}ê°œ + ë™ì˜ì–´ ${synSectionIds.length}ê°œ = ì´ ${allSectionIds.length}ê°œ ë¶„ì•¼ â†’ ì„¹ì…˜ ì„ íƒ`);\n            const { data: chunkMetas } = await supabase\n                .from(\"graph_chunks\")\n                .select(\"section_id, department, chapter, title\")\n                .in(\"section_id\", allSectionIds);\n\n            const metaMap = new Map<string, any>();\n            for (const cm of (chunkMetas || [])) {\n                if (!metaMap.has(cm.section_id)) metaMap.set(cm.section_id, cm);\n            }\n\n            // Section ì—”í‹°í‹° ê¸°ë°˜ ì˜µì…˜\n            const options: ClarifyOption[] = entities.slice(0, 10).map(s => {\n                const meta = metaMap.get(s.source_section || \"\");\n                const label = meta\n                    ? `${meta.department} > ${meta.chapter} > ${meta.title}`\n                    : `[${s.source_section || \"\"}] ${s.name}`;\n                return {\n                    label,\n                    query: `${s.name} í’ˆì…ˆ`,\n                    source_section: s.source_section,\n                    section_id: s.source_section,\n                    option_type: 'section' as const,\n                };\n            });\n\n            // ë™ì˜ì–´ WorkTypeì˜ source_section ì¤‘ Sectionì— ì—†ëŠ” ê²ƒ ì¶”ê°€\n            const existingSrcSet = new Set(sectionSourceIds);\n            const addedSynSrcSet = new Set<string>();\n            for (const wt of synonymWorkTypes) {\n                if (wt.source_section && !existingSrcSet.has(wt.source_section) && !addedSynSrcSet.has(wt.source_section)) {\n                    addedSynSrcSet.add(wt.source_section);\n                    const meta = metaMap.get(wt.source_section);\n                    const label = meta\n                        ? `${meta.department} > ${meta.chapter} > ${meta.title}`\n                        : `[${wt.source_section}] ${wt.name}`;\n                    options.push({\n                        label,\n                        query: `${meta?.title || wt.name} í’ˆì…ˆ`,\n                        source_section: wt.source_section,\n                        section_id: wt.source_section,\n                        option_type: 'section' as const,\n                    });\n                }\n            }\n\n            return makeClarifyResponse(\n                `\"${question}\" ê´€ë ¨ í’ˆì…ˆì´ **${allSectionIds.length}ê°œ ë¶„ì•¼**ì— ìˆìŠµë‹ˆë‹¤.\\nì–´ë–¤ ë¶„ì•¼ì˜ í’ˆì…ˆì„ ì°¾ìœ¼ì‹œë‚˜ìš”?`,\n                startTime,\n                {\n                    options,\n                    reason: `'${entities[0].name}' ê´€ë ¨ í’ˆì…ˆì´ ì—¬ëŸ¬ ë¶„ì•¼ì— ì¡´ì¬í•˜ì—¬ ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.`,\n                    original_query: question,\n                },\n                { entities }\n            );\n        }\n\n        // ë‹¨ì¼ ì„¹ì…˜: í•˜ìœ„ WorkType í™•ì¸\n        const singleSectionId = sectionSourceIds[0];\n        const { data: childWorkTypes } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties, source_section\")\n            .eq(\"type\", \"WorkType\")\n            .eq(\"source_section\", singleSectionId)\n            .limit(200);\n\n        if (childWorkTypes && childWorkTypes.length > 3) {\n            console.log(`[searchPipeline] Section 1ê°œ + WorkType ${childWorkTypes.length}ê°œ â†’ Step 2`);\n            const clarifyResult = await graphClarify(\n                { ...analysis, intent: \"clarify_needed\" as const, work_name: analysis.work_name || entities[0].name },\n                singleSectionId\n            );\n            return makeClarifyResponse(clarifyResult.message, startTime, {\n                options: clarifyResult.options,\n                reason: `'${entities[0].name}' í•˜ìœ„ì— ${childWorkTypes.length}ê°œ ì‘ì—…ì´ ìˆì–´ ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.`,\n                original_query: question,\n                selector: clarifyResult.selector,\n            }, { entities });\n        }\n        // WT â‰¤ 3 â†’ answerPipelineìœ¼ë¡œ ì§„í–‰\n    }\n\n    // [3] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n    if (entities.length === 0) {\n        const llmResult = await generateAnswer(\n            question,\n            \"ì œê³µëœ í’ˆì…ˆ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\",\n            history\n        );\n        return makeAnswerResponse(llmResult.answer, startTime, {\n            embeddingTokens, llmResult,\n        });\n    }\n\n    // [4] WorkType ë§¤ì¹­ â†’ answerPipeline\n    return answerPipeline(entities, question, history, startTime, {\n        answerOptions, analysis,\n    });\n}\n\n// â”â”â” [H] ë©”ì¸ í•¸ë“¤ëŸ¬ (ë¼ìš°í„°) â”â”â”\n\n// â”€â”€â”€ íŠ¹ìˆ˜ í…Œì´ë¸” ì „ìš© ê°ì§€ê¸° ë° íŒŒì´í”„ë¼ì¸ (Phase 1.5) â”€â”€â”€\ninterface ComplexTableQuery {\n    section_code: string;       // '13-1-1'\n    material?: string;          // 'ë°°ê´€ìš© íƒ„ì†Œê°•ê´€'\n    spec_mm?: number;           // 200\n    pipe_location?: string;     // 'ì˜¥ë‚´' | 'ì˜¥ì™¸'\n    joint_type?: string;        // 'ìš©ì ‘ì‹' | 'ë‚˜ì‚¬ì‹'\n    quantity_value?: number;    // 10 (m)\n}\n\nconst COMPLEX_TABLE_TRIGGERS: Record<string, {\n    section_code: string;\n    materials: string[];\n}> = {\n    \"í”ŒëœíŠ¸ ë°°ê´€\": {\n        section_code: \"13-1-1\",\n        materials: [\"íƒ„ì†Œê°•ê´€\", \"í•©ê¸ˆê°•\", \"ìŠ¤í…ë ˆìŠ¤\", \"ìŠ¤í…Œì¸ë¦¬ìŠ¤\", \"ì•Œë£¨ë¯¸ëŠ„\",\n            \"ë™ê´€\", \"í™©ë™\", \"KSD3507\", \"A335\", \"Type304\", \"Monel\", \"ë°±ê´€\", \"í‘ê´€\"]\n    }\n};\n\nfunction detectComplexTable(question: string): ComplexTableQuery | null {\n    for (const [trigger, config] of Object.entries(COMPLEX_TABLE_TRIGGERS)) {\n        const triggerWords = trigger.split(\" \");\n        const allTriggerMatch = triggerWords.every(w => question.includes(w));\n        if (!allTriggerMatch) continue;\n\n        const matchedMaterial = config.materials.find(m => question.includes(m));\n\n        const specMatch = question.match(/(\\d{2,4})\\s*(mm|A|a|ãœ)/);\n        const spec_mm = specMatch ? parseInt(specMatch[1]) : undefined;\n\n        const pipe_location = question.includes(\"ì˜¥ì™¸\") ? \"ì˜¥ì™¸\" : (question.includes(\"ì˜¥ë‚´\") ? \"ì˜¥ë‚´\" : undefined);\n        const joint_type = question.includes(\"ë‚˜ì‚¬\") ? \"ë‚˜ì‚¬ì‹\" : (question.includes(\"ìš©ì ‘\") ? \"ìš©ì ‘ì‹\" : undefined);\n\n        const qtyMatch = question.match(/(\\d+(?:\\.\\d+)?)\\s*(m|ë¯¸í„°|M|ton|í†¤)\\b/);\n        const quantity_value = qtyMatch ? parseFloat(qtyMatch[1]) : undefined;\n\n        return {\n            section_code: config.section_code,\n            material: matchedMaterial,\n            spec_mm,\n            pipe_location,\n            joint_type,\n            quantity_value,\n        };\n    }\n    return null;\n}\n\nfunction findBestCostMatch(\n    jobName: string,\n    costMap: Map<string, number>\n): { name: string; cost: number } | null {\n    if (costMap.has(jobName)) return { name: jobName, cost: costMap.get(jobName)! };\n    const normalized = jobName.replace(/\\s+/g, '');\n    for (const [key, cost] of costMap) {\n        if (key.replace(/\\s+/g, '') === normalized) return { name: key, cost };\n    }\n    let bestMatch: { name: string; cost: number } | null = null;\n    for (const [key, cost] of costMap) {\n        const keyNorm = key.replace(/\\s+/g, '');\n        if (keyNorm.includes(normalized) || normalized.includes(keyNorm)) {\n            if (!bestMatch || key.length < bestMatch.name.length) {\n                bestMatch = { name: key, cost };\n            }\n        }\n    }\n    return bestMatch;\n}\n\nasync function complexTablePipeline(\n    query: ComplexTableQuery,\n    question: string,\n    history: ChatMessage[],\n    startTime: number\n): Promise<ChatResponse> {\n    console.log(`[complexTablePipeline] section=${query.section_code}, ` +\n        `material=${query.material}, spec=${query.spec_mm}, ` +\n        `location=${query.pipe_location}, joint=${query.joint_type}`);\n\n    let dbQuery = supabase\n        .from(\"complex_table_specs\")\n        .select(\"*\")\n        .eq(\"section_code\", query.section_code);\n\n    if (query.material) dbQuery = dbQuery.ilike(\"material\", `%${query.material}%`);\n    if (query.pipe_location) dbQuery = dbQuery.eq(\"pipe_location\", query.pipe_location);\n    if (query.joint_type) dbQuery = dbQuery.eq(\"joint_type\", query.joint_type);\n\n    const { data: specs, error } = await dbQuery;\n\n    let filteredSpecs: any[] = specs || [];\n    if (query.spec_mm) {\n        filteredSpecs = filteredSpecs.filter((s: any) => s.spec_mm === query.spec_mm);\n    }\n\n    if (query.material && filteredSpecs.length > 0) {\n        const uniqueMaterials = [...new Set(filteredSpecs.map(s => s.material))];\n        let bestMaterial = uniqueMaterials[0];\n        for (const mat of uniqueMaterials) {\n            const matPrefix = mat.split('(')[0];\n            if (question.replace(/\\s+/g, '').includes(matPrefix.replace(/\\s+/g, ''))) {\n                bestMaterial = mat;\n                break;\n            }\n        }\n        filteredSpecs = filteredSpecs.filter((s: any) => s.material === bestMaterial);\n    }\n\n    if (filteredSpecs.length === 0) {\n        console.warn(\"[complexTablePipeline] ì „ìš© DBì— ë°ì´í„° ì—†ìŒ â†’ ì¼ë°˜ search í´ë°±/ì•ˆë‚´\");\n        // Fallback to normal semantic search if missing\n        const analysis = await analyzeIntent(question, history);\n        return searchPipeline(analysis, question, history, startTime);\n    }\n\n    // Step 1.5: ë‹¤ì¤‘ ì¡°í•©(ì¬ì§ˆ, ë°°ê´€ì¥ì†Œ, ì ‘í•©ë°©ì‹)ì¼ ê²½ìš° ì‚¬ìš©ìì—ê²Œ Clarification ìš”ì²­\n    const uniqueCombos = [...new Set(filteredSpecs.map(s => `${s.material}||${s.pipe_location}||${s.joint_type}`))];\n    if (uniqueCombos.length > 1) {\n        const options: ClarifyOption[] = uniqueCombos.slice(0, 15).map(combo => {\n            const [mat, loc, jnt] = combo.split('||');\n            return {\n                label: `${mat} (${loc} ${jnt})`, // ê°„ê²°í•˜ê²Œ í‘œì‹œ\n                query: `í”ŒëœíŠ¸ ë°°ê´€ ì„¤ì¹˜ ${mat} ${loc} ${jnt}`,\n                option_type: 'section',\n                section_id: query.section_code\n            };\n        });\n\n        // forceSelector=true ë¡œ ì²´í¬ë°•ìŠ¤ UI ê°•ì œ í™œì„±í™”\n        const selector = buildSelectorPanel(options, `[${query.section_code}] ë°°ê´€ ì„¤ì¹˜`, true);\n\n        return makeClarifyResponse(\n            `\"${question}\"ì— í•´ë‹¹í•˜ëŠ” í’ˆì…ˆ ê¸°ì¤€ì´ ì—¬ëŸ¬ ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¨ì¼ ê¸°ì¤€ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.`,\n            startTime,\n            {\n                options,\n                reason: \"ì¬ì§ˆ, ë°°ê´€êµ¬ë¶„, ì ‘í•©ë°©ì‹ì´ ëª…í™•í•˜ì§€ ì•Šì•„ ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n                original_query: question,\n                ...(selector ? { selector } : {})\n            }\n        );\n    }\n\n    // ë‹¨ì¼ ì¡°í•© í™•ì •\n    const exactMat = filteredSpecs[0].material;\n    const exactLoc = filteredSpecs[0].pipe_location;\n    const exactJnt = filteredSpecs[0].joint_type;\n\n    // Step 2: 2026 ë…¸ì„ë‹¨ê°€ ì‚¬ì „ì—°ì‚°\n    const jobNames = [...new Set(filteredSpecs.map((s: any) => s.job_name as string))];\n    const laborCosts = await fetchLaborCosts(jobNames);\n    const costMap = new Map(laborCosts.map(lc => [lc.job_name, lc.cost_2026]));\n\n    const quantityMultiplier = query.quantity_value || 1;\n    const quantityUnit = filteredSpecs[0]?.quantity_unit || \"ì¸/100m\";\n    const unitLabel = quantityUnit === \"ì¸/100m\" ? \"100m\" : quantityUnit.replace(\"ì¸/\", \"\");\n\n    let context = `## ğŸ“‹ [${query.section_code}] ${filteredSpecs[0]?.section_name}\\n\\n`;\n    context += `**ì¬ì§ˆ**: ${exactMat} | **ë°°ê´€êµ¬ë¶„**: ${exactLoc} | **ì ‘í•©ë°©ì‹**: ${exactJnt}\\n\\n`;\n\n    const uniqueSpecs = [...new Set(filteredSpecs.map((s: any) => s.spec_mm))].sort((a, b) => a - b);\n    const hasMultipleSpecs = uniqueSpecs.length > 1;\n\n    context += `## [2026ë…„ ë…¸ì„ë‹¨ê°€ ê¸°ë°˜ ì‚°ì¶œ ê²°ê³¼ (ë°±ì—”ë“œ ê³„ì‚° ì™„ë£Œ)]\\n\\n`;\n\n    let totalCost = 0;\n    if (hasMultipleSpecs) {\n        // [ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§]: êµ¬ê²½(mm)ì´ ì»¬ëŸ¼ì´ ë˜ëŠ” í…Œì´ë¸”\n        const specHeaders = uniqueSpecs.map(s => `${s}mm`).join(\" | \");\n        const specSep = uniqueSpecs.map(() => \"---:\").join(\" | \");\n\n        context += `| ì§ì¢… | ë…¸ì„ë‹¨ê°€(ì›/ì¼) | ${specHeaders} |\\n`;\n        context += `|---|---:|${specSep}|\\n`;\n\n        for (const job of jobNames) {\n            const matched = findBestCostMatch(job, costMap);\n            const unitCost = matched?.cost ?? 0;\n\n            const rowValues = uniqueSpecs.map(spec => {\n                const item = filteredSpecs.find((s: any) => s.job_name === job && s.spec_mm === spec);\n                return item ? item.quantity : \"-\";\n            });\n\n            context += `| ${job} | ${unitCost.toLocaleString()} | ` + rowValues.join(\" | \") + ` |\\n`;\n        }\n\n        if (quantityMultiplier !== 1) {\n            context += `\\n> ğŸ’¡ **ì°¸ê³ **: ìˆ˜ëŸ‰(${quantityMultiplier}${unitLabel.replace(\"100m\", \"m\")})ì„ ì „ì²´ ë…¸ì„ë¹„ë¡œ ê³„ì‚°í•˜ì‹œë ¤ë©´, íŠ¹ì • êµ¬ê²½(mm) í•˜ë‚˜ë¥¼ ì´ì–´ì„œ ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.\\n`;\n        }\n    } else {\n        // [í”Œë« í…Œì´ë¸” ë Œë”ë§]: ë‹¨ì¼ êµ¬ê²½ì˜ ì„¸ë¶€ ì¡°ê±´ê³¼ í•©ì‚°ëœ ë…¸ë¬´ë¹„ (ê¸°ì¡´ ë¡œì§)\n        const specInfo = filteredSpecs[0];\n        context += `**êµ¬ê²½**: ${specInfo.spec_mm}mm | **ì™¸ê²½**: ${specInfo.outer_dia_mm}mm | **ë‘ê»˜**: ${specInfo.thickness_mm}mm | **ë‹¨ìœ„ì¤‘ëŸ‰**: ${specInfo.unit_weight}kg/m\\n\\n`;\n\n        context += `| ì§ì¢… | í’ˆ(${unitLabel}ë‹¹) | ë…¸ì„ë‹¨ê°€(ì›/ì¼) | `;\n        if (quantityMultiplier > 1) {\n            const displayUnit = unitLabel === \"100m\" ? \"m\" : unitLabel;\n            context += `${quantityMultiplier}${displayUnit} í™˜ì‚° ê¸ˆì•¡(ì›) | `;\n        }\n        context += `ë¹„ê³  |\\n|---|---:|---:|`;\n        if (quantityMultiplier > 1) context += `---:|`;\n        context += `---|\\n`;\n\n        for (const spec of filteredSpecs) {\n            const matched = findBestCostMatch(spec.job_name, costMap);\n            const unitCost = matched?.cost ?? 0;\n            const qtyPer100m = parseFloat(spec.quantity);\n\n            const actualQty = quantityUnit === \"ì¸/100m\"\n                ? qtyPer100m * (quantityMultiplier / 100)\n                : qtyPer100m * quantityMultiplier;\n            const amount = Math.round(actualQty * unitCost);\n            totalCost += amount;\n\n            context += `| ${spec.job_name} | ${spec.quantity} | ${unitCost.toLocaleString()} | `;\n            if (quantityMultiplier > 1) {\n                context += `${amount.toLocaleString()} | `;\n            }\n            context += `${query.section_code} |\\n`;\n        }\n\n        if (quantityMultiplier > 1) {\n            const toolCost = Math.round(totalCost * 0.03);\n            context += `| ê³µêµ¬ì†ë£Œ (3%) | - | - | ${toolCost.toLocaleString()} | ì¸ë ¥í’ˆì˜ 3% |\\n`;\n            totalCost += toolCost;\n            context += `| **í•©ê³„** | | | **${totalCost.toLocaleString()}** | |\\n`;\n        }\n    }\n\n    context += `\\n> âš ï¸ ìœ„ ê¸ˆì•¡ì€ **ì „ìš© ì •í˜•í™” DBì—ì„œ ì •í™•íˆ ì¡°íšŒ**ë˜ì–´ ë°±ì—”ë“œì—ì„œ ê³„ì‚°í•œ í™•ì •ê°’ì…ë‹ˆë‹¤.\\n`;\n    context += `> LLMì€ ì´ ìˆ«ìë¥¼ ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\\n`;\n\n    // Step 3: LLM í¬ì¥\n    const llmResult = await generateAnswer(question, context, history, {\n        intent: \"cost_calculate\",\n        quantity: query.quantity_value,\n    });\n\n    const sources: SourceInfo[] = [{\n        entity_name: `${filteredSpecs[0]?.section_name} (${filteredSpecs[0]?.material})`,\n        entity_type: \"ComplexTable\" as any,\n        source_section: query.section_code,\n        section_label: `${filteredSpecs[0]?.section_name}`,\n        similarity: 1.0\n    }];\n\n    return makeAnswerResponse(llmResult.answer, startTime, {\n        sources,\n        embeddingTokens: 0,\n        llmResult,\n    });\n}\n\nasync function handleChat(\n    question: string,\n    history: ChatMessage[],\n    entityId?: string,\n    sectionId?: string,\n    sessionContext?: SessionContext,\n    answerOptions?: AnswerOptions\n): Promise<ChatResponse> {\n    const startTime = Date.now();\n\n    // â•â•â• Route 0.5: íŠ¹ìˆ˜ ë³µí•© í…Œì´ë¸” ì „ìš© ë¼ìš°í„° (Phase 1.5) â•â•â•\n    const complexTableMatch = detectComplexTable(question);\n    if (complexTableMatch) {\n        console.log(`[handleChat] ğŸ¯ Route 0.5: íŠ¹ìˆ˜ í…Œì´ë¸” ê°ì§€ â†’ ${complexTableMatch.section_code}`);\n        return complexTablePipeline(complexTableMatch, question, history, startTime);\n    }\n\n    // â•â•â• Route 1: entity_id ì§ì ‘ ì¡°íšŒ (ì¹© ì„ íƒ ì‹œ) â•â•â•\n    if (entityId) {\n        const entityIds = entityId.split(',').map(s => s.trim()).filter(Boolean);\n        console.log(`[handleChat] entity_ids=[${entityIds.join(',')}] â†’ answerPipeline`);\n        const { data: directEntities } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties, source_section\")\n            .in(\"id\", entityIds);\n\n        if (directEntities && directEntities.length > 0) {\n            const entities: EntityResult[] = directEntities.map((de: any) => ({\n                id: de.id, name: de.name, type: de.type,\n                properties: de.properties || {},\n                source_section: de.source_section,\n                similarity: 1.0,\n            }));\n            const firstSpec = entities[0]?.properties?.spec as string || \"\";\n            const specNum = firstSpec.match(/^(\\d+)/)?.[1];\n            return answerPipeline(entities, question, history, startTime, {\n                skipSiblings: true,\n                specFilter: specNum,\n                answerOptions,\n            });\n        }\n    }\n\n    // â•â•â• Route 2: section_id â†’ full_view or Step 2 clarify â•â•â•\n    if (sectionId) {\n        console.log(`[handleChat] section_id=${sectionId} â†’ ì„¹ì…˜ ë‚´ íƒìƒ‰`);\n        const isSubSection = sectionId.includes(\":sub=\");\n        const isFullView = isSubSection || question.includes(\"ì „ì²´\") || question.includes(\"ëª©ë¡\");\n\n        if (isFullView) return fullViewPipeline(sectionId, question, history, startTime);\n\n        // Step 2: í•´ë‹¹ ì„¹ì…˜ ë‚´ í•˜ëª© ì„ íƒ ì˜µì…˜ ì œì‹œ\n        const clarifyAnalysis: IntentAnalysis = {\n            intent: \"clarify_needed\",\n            work_name: question.replace(/í’ˆì…ˆ|ì „ì²´|\\s/g, \"\") || null,\n            spec: null,\n            keywords: [],\n            ambiguity_reason: \"ì„¹ì…˜ ë‚´ í•˜ëª© ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n        };\n        const clarifyResult = await graphClarify(clarifyAnalysis, sectionId);\n        return makeClarifyResponse(clarifyResult.message, startTime, {\n            options: clarifyResult.options,\n            reason: \"ì„¹ì…˜ ë‚´ í•˜ìœ„ ì‘ì—…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.\",\n            original_query: question,\n            selector: clarifyResult.selector,\n        });\n    }\n\n    // â•â•â• Route 3: ì˜ë„ ë¶„ì„ (DeepSeek v3.2) â•â•â•\n    const analysis = await analyzeIntent(question, history, sessionContext);\n    analysis.spec = normalizeSpec(analysis.spec);\n\n    // â”€â”€â”€ ì¸ì‚¬/ë„ì›€ë§ â”€â”€â”€\n    if (analysis.intent === \"greeting\") {\n        return makeAnswerResponse(\n            \"ì•ˆë…•í•˜ì„¸ìš”! ê±´ì„¤ ê³µì‚¬ í‘œì¤€í’ˆì…ˆ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸ—ï¸\\n\\n\" +\n            \"ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:\\n\" +\n            \"- **í’ˆì…ˆ ê²€ìƒ‰**: \\\"ê°•ê´€ìš©ì ‘ 200mm SCH 40 í’ˆì…ˆ\\\"\\n\" +\n            \"- **ì¸ë ¥ íˆ¬ì…ëŸ‰**: \\\"ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ ì¸ë ¥\\\"\\n\" +\n            \"- **ë¹„ìš© ì‚°ì¶œ**: \\\"ê±°í‘¸ì§‘ ì„¤ì¹˜ ì¼ìœ„ëŒ€ê°€\\\"\\n\\n\" +\n            \"ê³µì¢…ëª…ê³¼ ê·œê²©ì„ í•¨ê»˜ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n            startTime\n        );\n    }\n\n    // â”€â”€â”€ ë¹„ìš© ì‚°ì¶œ (cost_calculate) â”€â”€â”€\n    if (analysis.intent === \"cost_calculate\") {\n        const targetEntityId = sessionContext?.last_entity_id;\n        if (!targetEntityId) {\n            return makeAnswerResponse(\n                \"ë…¸ë¬´ë¹„ë¥¼ ê³„ì‚°í•˜ë ¤ë©´ ë¨¼ì € í’ˆì…ˆì„ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.\\n\\n\" +\n                \"ì˜ˆì‹œ: \\\"ê°•ê´€ìš©ì ‘ 200mm SCH 40\\\" ë˜ëŠ” \\\"TIGìš©ì ‘ í’ˆì…ˆ\\\"\",\n                startTime\n            );\n        }\n        console.log(`[handleChat] cost_calculate: entity=${targetEntityId} â†’ ì¬ê·€ í˜¸ì¶œ`);\n        return handleChat(question, history, targetEntityId, undefined, sessionContext, {\n            intent: \"cost_calculate\",\n            quantity: analysis.quantity || sessionContext?.last_quantity || undefined,\n        });\n    }\n\n    // â”€â”€â”€ ë³€ê²½ ìš”ì²­ (modify_request) â”€â”€â”€\n    if (analysis.intent === \"modify_request\") {\n        if (analysis.modify_type === \"quantity\" && sessionContext?.last_entity_id) {\n            console.log(`[handleChat] modify_request(quantity=${analysis.quantity}): entity=${sessionContext.last_entity_id}`);\n            return handleChat(question, history, sessionContext.last_entity_id, undefined, sessionContext, {\n                intent: \"cost_calculate\",\n                quantity: analysis.quantity || undefined,\n                modifyType: \"quantity\",\n            });\n        }\n        if (analysis.modify_type === \"work_change\" && analysis.work_name) {\n            console.log(`[handleChat] modify_request(work_change): ${analysis.work_name}, spec=${sessionContext?.last_spec}`);\n            const modifiedAnalysis: IntentAnalysis = {\n                ...analysis,\n                intent: analysis.spec || sessionContext?.last_spec ? \"search\" : \"clarify_needed\",\n                spec: analysis.spec || sessionContext?.last_spec || null,\n            };\n            Object.assign(analysis, modifiedAnalysis);\n        }\n        if (analysis.modify_type === \"exclude_labor\" || (!analysis.modify_type && sessionContext?.last_entity_id)) {\n            return makeAnswerResponse(\n                \"ì§ì¢… ì œì™¸/ìˆ˜ì • ê¸°ëŠ¥ì€ ì•„ì§ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. í˜„ì¬ëŠ” ìˆ˜ëŸ‰ ë³€ê²½ê³¼ ê³µì¢… ë³€ê²½ë§Œ ì§€ì›í•©ë‹ˆë‹¤.\\n\\n\" +\n                \"ì˜ˆì‹œ: \\\"50më¡œ ë°”ê¿”ì„œ ë‹¤ì‹œ\\\" ë˜ëŠ” \\\"TIGë¡œ ë°”ê¿”ì¤˜\\\"\",\n                startTime\n            );\n        }\n        if (!sessionContext?.last_entity_id && !analysis.work_name) {\n            return makeAnswerResponse(\n                \"ë³€ê²½í•  ì´ì „ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í’ˆì…ˆì„ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.\",\n                startTime\n            );\n        }\n    }\n\n    // â”€â”€â”€ ì‚°ì¶œì„œ ìš”ì²­ (report_request) â”€â”€â”€\n    if (analysis.intent === \"report_request\") {\n        const targetEntityId = sessionContext?.last_entity_id;\n        if (!targetEntityId) {\n            return makeAnswerResponse(\n                \"ì‚°ì¶œì„œë¥¼ ë§Œë“¤ë ¤ë©´ ë¨¼ì € í’ˆì…ˆì„ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.\\n\\n\" +\n                \"ì˜ˆì‹œ: \\\"ê°•ê´€ìš©ì ‘ 200mm SCH 40\\\"\",\n                startTime\n            );\n        }\n        console.log(`[handleChat] report_request: entity=${targetEntityId} â†’ ì¬ê·€ í˜¸ì¶œ`);\n        return handleChat(question, history, targetEntityId, undefined, sessionContext, {\n            intent: \"report_request\",\n            quantity: sessionContext?.last_quantity || undefined,\n        });\n    }\n\n    // â”€â”€â”€ ëª…í™•í™” í•„ìš” â†’ graphClarify â”€â”€â”€\n    if (analysis.intent === \"clarify_needed\") {\n        const clarifyResult = await graphClarify(analysis);\n        return makeClarifyResponse(clarifyResult.message, startTime, {\n            options: clarifyResult.options,\n            reason: analysis.ambiguity_reason || \"ì§ˆë¬¸ì˜ ë²”ìœ„ê°€ ë„“ì–´ êµ¬ì²´ì ì¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤\",\n            original_query: question,\n            selector: clarifyResult.selector,\n        });\n    }\n\n    // â•â•â• Route 4: search â†’ searchPipeline â•â•â•\n    return searchPipeline(analysis, question, history, startTime, answerOptions);\n}\n\n// â”â”â” ì„œë²„ ì§„ì…ì  â”â”â”\n\nDeno.serve(async (req: Request) => {\n    const corsHeaders = getCorsHeaders(req);\n\n    // OPTIONS preflight\n    if (req.method === \"OPTIONS\") {\n        return new Response(null, { status: 204, headers: corsHeaders });\n    }\n\n    // POSTë§Œ í—ˆìš©\n    if (req.method !== \"POST\") {\n        return new Response(\n            JSON.stringify({ error: \"method_not_allowed\" }),\n            { status: 405, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n        );\n    }\n\n    // (Codex F1) API Key ê²€ì¦\n    if (RAG_API_KEY) {\n        const clientKey = req.headers.get(\"x-api-key\") || \"\";\n        if (clientKey !== RAG_API_KEY) {\n            return new Response(\n                JSON.stringify({ error: \"unauthorized\" }),\n                { status: 401, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n            );\n        }\n    }\n\n    // (Codex F1) Rate Limiting\n    const clientIp =\n        req.headers.get(\"x-forwarded-for\")?.split(\",\")[0]?.trim() ||\n        req.headers.get(\"cf-connecting-ip\") ||\n        \"unknown\";\n    if (!checkRateLimit(clientIp)) {\n        return new Response(\n            JSON.stringify({ error: \"rate_limited\" }),\n            { status: 429, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n        );\n    }\n\n    // Body í¬ê¸° ì œí•œ (10KB)\n    const contentLength = parseInt(req.headers.get(\"content-length\") || \"0\", 10);\n    if (contentLength > 10_240) {\n        return new Response(\n            JSON.stringify({ error: \"payload_too_large\" }),\n            { status: 413, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n        );\n    }\n\n    try {\n        const body = (await req.json()) as ChatRequest;\n\n        // ì…ë ¥ ê²€ì¦\n        if (!body.question || body.question.trim().length === 0) {\n            return new Response(\n                JSON.stringify({ error: \"question_required\" }),\n                { status: 400, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n            );\n        }\n\n        // (Codex F5) 500ì ì´ˆê³¼ ì‹œ truncate (ì—ëŸ¬ê°€ ì•„ë‹Œ ìë™ ì ˆì‚­)\n        const question = body.question.trim().substring(0, 500);\n        const history = (body.history || []).slice(-5);\n\n        // RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n        const entityId = body.entity_id || undefined;\n        const sectionId = body.section_id || undefined;\n        const sessionContext = body.session_context || undefined;\n        const result = await handleChat(question, history, entityId, sectionId, sessionContext);\n\n        return new Response(JSON.stringify(result), {\n            status: 200,\n            headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        });\n    } catch (err) {\n        // ì—ëŸ¬ ì¢…ë¥˜ë³„ ë¶„ê¸°\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        console.error(\"rag-chat error:\", errorMsg);\n\n        // Gemini API ì—ëŸ¬ â†’ 502\n        if (errorMsg.includes(\"Embedding API failed\")) {\n            return new Response(\n                JSON.stringify({ error: \"embedding_failed\" }),\n                { status: 502, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n            );\n        }\n        if (errorMsg.includes(\"LLM API failed\")) {\n            // (Codex ê¶Œì¥) LLM ì‹¤íŒ¨ ì‹œ êµ¬ì¡° ì‘ë‹µ í´ë°±\n            return new Response(\n                JSON.stringify({\n                    error: \"llm_failed\",\n                    message: \"LLM ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n                }),\n                { status: 502, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n            );\n        }\n\n        // ê¸°íƒ€ ì„œë²„ ì—ëŸ¬\n        return new Response(\n            JSON.stringify({ error: \"internal_error\" }),\n            { status: 500, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n        );\n    }\n});\n"}, {"name": "types.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// types.ts â€” ê³µí†µ íƒ€ì…/ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nexport interface ChatMessage {\n    role: \"user\" | \"assistant\";\n    content: string;\n}\n\nexport interface ChatRequest {\n    question: string;\n    history?: ChatMessage[];\n    entity_id?: string;   // ì¹© ì„ íƒ ì‹œ ì§ì ‘ entity ì¡°íšŒìš©\n    section_id?: string;  // Step 2 íŠ¸ë¦¬ê±°ìš© section_id (I-6 ìˆ˜ì •)\n    session_context?: SessionContext;  // ì„¸ì…˜ ìƒíƒœ (ì´ì „ í„´ í’ˆì…ˆ/ìˆ˜ëŸ‰ ì •ë³´)\n}\n\n// ì„¸ì…˜ ìƒíƒœ (í”„ë¡ íŠ¸ì—”ë“œ â†’ ì„œë²„ ì „ë‹¬)\n// Why: \"ì•„ê¹Œ ê±´\", \"ê·¸ê±° ë§ê³ \" ê°™ì€ ë§¥ë½ ì°¸ì¡° ì§ˆë¬¸ í•´ì„ì— í•„ìš”\nexport interface SessionContext {\n    last_entity_id: string | null;       // ë§ˆì§€ë§‰ í™•ì • í’ˆì…ˆ entity ID (ì˜ˆ: \"W-0788\")\n    last_work_name: string | null;       // \"ê°•ê´€ìš©ì ‘(200, SCH 40)\"\n    last_spec: string | null;            // \"200 SCH 40\"\n    last_quantity: number | null;        // 50\n    last_section_id: string | null;      // \"13-2-3\"\n}\n\nexport interface SourceInfo {\n    entity_id?: string;\n    entity_name: string;\n    entity_type: string;\n    source_section?: string;\n    section_label?: string;\n    similarity?: number;\n}\n\nexport interface TokenUsage {\n    embedding_tokens: number;\n    llm_input_tokens: number;\n    llm_output_tokens: number;\n    total_tokens: number;\n    estimated_cost_krw: number;\n}\n\nexport interface SearchInfo {\n    entities_found: number;\n    relations_expanded: number;\n    ilwi_matched: number;\n    chunks_retrieved: number;\n    latency_ms: number;\n    token_usage?: TokenUsage;\n}\n\n// ëª…í™•í™” ì„ íƒ ì˜µì…˜\nexport interface ClarifyOption {\n    label: string;           // í‘œì‹œ í…ìŠ¤íŠ¸: \"200mm SCH 40\"\n    query: string;           // í´ë¦­ ì‹œ ì „ì†¡í•  ì§ˆë¬¸\n    entity_id?: string;      // ì§ì ‘ ê²€ìƒ‰ìš© ID (ì˜µì…˜)\n    source_section?: string; // ì¶œì²˜ ì ˆë²ˆí˜¸\n    section_id?: string;     // Step 2 íŠ¸ë¦¬ê±°ìš© section_id (graph_chunks í‚¤)\n    option_type?: 'section' | 'worktype' | 'full_view';  // ì˜µì…˜ ìœ í˜•\n}\n\nexport interface ClarificationInfo {\n    options: ClarifyOption[];\n    reason: string;\n    original_query: string;\n    selector?: SelectorPanel;  // 6ê°œ ì´ˆê³¼ ì‹œ ë“œë¡­ë‹¤ìš´+ì²´í¬ë°•ìŠ¤ íŒ¨ë„\n}\n\n// â”€â”€â”€ Selector Panel íƒ€ì… (ëª…í™•í™” UI ê°œì„ ) â”€â”€â”€\n\nexport interface FilterAxis {\n    key: string;       // \"diameter\" | \"sch\"\n    label: string;     // \"í˜¸ì¹­ê²½(mm)\" | \"SCH\"\n    values: string[];  // [\"15\",\"20\",\"25\",...]\n}\n\nexport interface SelectorItem {\n    label: string;\n    query: string;\n    entity_id?: string;\n    source_section?: string;\n    option_type?: string;  // 'worktype' | 'section'\n    specs: Record<string, string>;  // { diameter: \"200\", sch: \"40\" }\n}\n\nexport interface SelectorPanel {\n    title: string;              // \"ê°•ê´€ìš©ì ‘ â€” ê·œê²© ì„ íƒ\"\n    filters: FilterAxis[];      // í•„í„° ì¶• (í˜¸ì¹­ê²½, SCH ë“±)\n    items: SelectorItem[];      // ì „ì²´ í•­ëª© (í•„í„°ë§ ì „)\n    original_query: string;\n}\n\nexport interface ChatResponse {\n    type: \"answer\" | \"clarify\";     // ì‘ë‹µ ìœ í˜•\n    answer: string;\n    sources: SourceInfo[];\n    search_info: SearchInfo;\n    clarification?: ClarificationInfo; // ëª…í™•í™” ì •ë³´ (type=clarify ì‹œ)\n}\n\n// ì˜ë„ ë¶„ì„ ê²°ê³¼\nexport interface IntentAnalysis {\n    intent: \"search\" | \"clarify_needed\" | \"followup\" | \"greeting\" | \"quantity_input\" | \"cost_calculate\" | \"modify_request\" | \"report_request\";\n    work_name: string | null;\n    spec: string | null;\n    keywords: string[];\n    ambiguity_reason: string | null;\n    modify_type?: \"quantity\" | \"work_change\" | \"exclude_labor\" | null;  // modify_request ì„¸ë¶€ ìœ í˜•\n    quantity?: number | null;  // quantity_input/modify_request ì‹œ ìˆ˜ëŸ‰ ê°’\n}\n\n// ê²€ìƒ‰ ê²°ê³¼ ì—”í‹°í‹°\nexport interface EntityResult {\n    id: string;\n    name: string;\n    type: string;\n    properties: Record<string, unknown>;\n    similarity: number;\n    source_section?: string; // ì¶”ê°€ ì¡°íšŒë¡œ ì±„ì›€\n}\n\n// ê·¸ë˜í”„ ê´€ê³„\nexport interface RelatedResource {\n    direction: string;\n    relation: string;\n    related_id: string;\n    related_name: string;\n    related_type: string;\n    properties: Record<string, unknown>;\n}\n\n// ì¼ìœ„ëŒ€ê°€ í•­ëª©\nexport interface IlwiItem {\n    id: number;\n    name: string;\n    spec: string;\n    labor_cost: number;\n    material_cost: number;\n    expense_cost: number;\n    total_cost: number;\n}\n\n// í’ˆì…ˆ í‘œ ë°ì´í„° (graph_chunks.tables JSON êµ¬ì¡°)\nexport interface TableData {\n    table_id: string;\n    type: string;\n    headers: string[];\n    rows: Record<string, any>[];\n    raw_row_count: number;\n    parsed_row_count: number;\n    notes_in_table?: string[];\n}\n\n// ì›ë¬¸ ì²­í¬\nexport interface ChunkResult {\n    id: string;\n    section_id: string;\n    title: string;\n    department: string;\n    chapter: string;\n    section: string;\n    text: string; // DB ì»¬ëŸ¼ëª…: text (not content)\n    tables?: TableData[];   // í’ˆì…ˆ í‘œ ë°ì´í„°\n    notes?: any[];          // ì£¼ì˜ì‚¬í•­\n}\n\n// ëª…í™•í™” ê²°ê³¼\nexport interface ClarifyResult {\n    message: string;\n    options: ClarifyOption[];\n    selector?: SelectorPanel;  // 6ê°œ ì´ˆê³¼ ì‹œ Selector Panel ë°ì´í„°\n}\n\n// LLM ì‘ë‹µ ê²°ê³¼\nexport interface LLMResult {\n    answer: string;\n    inputTokens: number;\n    outputTokens: number;\n}\n\n// â”€â”€â”€ ë‹µë³€ ìƒì„± ì˜µì…˜ (intentâ†’ë‹µë³€ ì—°ê²°) â”€â”€â”€\nexport interface AnswerOptions {\n    intent?: string;       // \"cost_calculate\" | \"report_request\" | \"modify_request\" ë“±\n    quantity?: number;     // ì‚¬ìš©ì ì§€ì • ìˆ˜ëŸ‰ (50m, 10ê°œì†Œ ë“±)\n    modifyType?: string;   // \"quantity\" | \"work_change\"\n}\n\n// â”€â”€â”€ ë…¸ì„ë‹¨ê°€ í•­ëª© â”€â”€â”€\nexport interface LaborCostEntry {\n    job_name: string;\n    cost_2026: number;\n}\n"}, {"name": "config.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// config.ts â€” í™˜ê²½ ì„¤ì •, Supabase í´ë¼ì´ì–¸íŠ¸, CORS, Rate Limit\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport { createClient } from \"https://esm.sh/@supabase/supabase-js@2\";\n\n// â”â”â” í™˜ê²½ë³€ìˆ˜ â”â”â”\nexport const GEMINI_API_KEY = Deno.env.get(\"GEMINI_API_KEY\")!;\nexport const SUPABASE_URL = Deno.env.get(\"SUPABASE_URL\")!;\nexport const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get(\"SUPABASE_SERVICE_ROLE_KEY\")!;\nexport const RAG_API_KEY = Deno.env.get(\"RAG_API_KEY\") || \"\";\n// DeepSeek v3.2 â€” ì˜ë„ ë¶„ì„ ì „ìš© LLM\nexport const DEEPSEEK_API_KEY = Deno.env.get(\"DEEPSEEK_API_KEY\") || \"\";\nexport const DEEPSEEK_URL = \"https://api.deepseek.com/chat/completions\";\n\n// â”â”â” Supabase í´ë¼ì´ì–¸íŠ¸ â”â”â”\nexport const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);\n\n// â”â”â” CORS â”â”â”\n// (Codex F1) CORS allowlist â€” '*' ê¸ˆì§€\nexport const ALLOWED_ORIGINS = [\n    \"http://localhost:3000\",\n    \"http://localhost:5500\",\n    \"http://127.0.0.1:5500\",\n    \"https://pumsem-chat.pages.dev\",\n    \"https://antigravity-chatbot.pages.dev\",\n];\n// Cloudflare Pages preview URL íŒ¨í„´ (ex: 1e3f64d6.antigravity-chatbot.pages.dev)\nexport const ALLOWED_SUFFIXES = [\n    \".antigravity-chatbot.pages.dev\",\n    \".pumsem-chat.pages.dev\",\n];\n\nexport function getCorsHeaders(req: Request): Record<string, string> {\n    const origin = req.headers.get(\"Origin\") || \"\";\n    const isAllowed = ALLOWED_ORIGINS.includes(origin) ||\n        ALLOWED_SUFFIXES.some(suffix => {\n            try { return new URL(origin).hostname.endsWith(suffix); } catch { return false; }\n        });\n    return {\n        \"Access-Control-Allow-Origin\": isAllowed ? origin : \"\",\n        \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",\n        \"Access-Control-Allow-Headers\": \"Content-Type, x-api-key\",\n        \"Vary\": \"Origin\",\n    };\n}\n\n// â”â”â” Rate Limiting â”â”â”\n// (Codex F1) IP ê¸°ë°˜ Rate Limiting â€” ë¶„ë‹¹ 10íšŒ\nexport const rateLimitMap = new Map<string, { count: number; resetAt: number }>();\nexport const RATE_LIMIT_MAX = 10;\nexport const RATE_LIMIT_WINDOW_MS = 60_000;\n\nexport function checkRateLimit(ip: string): boolean {\n    const now = Date.now();\n    const entry = rateLimitMap.get(ip);\n    if (!entry || now > entry.resetAt) {\n        rateLimitMap.set(ip, { count: 1, resetAt: now + RATE_LIMIT_WINDOW_MS });\n        return true;\n    }\n    entry.count++;\n    return entry.count <= RATE_LIMIT_MAX;\n}\n"}, {"name": "embedding.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// embedding.ts â€” Gemini ì„ë² ë”© ìƒì„±\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport { GEMINI_API_KEY } from \"./config.ts\";\n\n// Why gemini-embedding-001: Step 2.7ì—ì„œ ë™ì¼ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±\nconst EMBEDDING_URL =\n    \"https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:embedContent\";\n\nexport async function generateEmbedding(text: string): Promise<number[]> {\n    // DBì— 768ì°¨ì›ìœ¼ë¡œ ì €ì¥ë¨ â†’ outputDimensionality ëª…ì‹œ í•„ìˆ˜\n    // gemini-embedding-001 ê¸°ë³¸ ì¶œë ¥ 3072ì°¨ì›ì´ë¯€ë¡œ ë¯¸ì§€ì • ì‹œ ë²¡í„° íŒŒì‹± ì‹¤íŒ¨\n    const embeddingBody = {\n        model: \"models/gemini-embedding-001\",\n        content: { parts: [{ text }] },\n        outputDimensionality: 768,\n    };\n\n    const response = await fetch(`${EMBEDDING_URL}?key=${GEMINI_API_KEY}`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify(embeddingBody),\n    });\n\n    if (!response.ok) {\n        // 1íšŒ ì¬ì‹œë„ (Codex ê¶Œì¥ í´ë°±)\n        const retry = await fetch(`${EMBEDDING_URL}?key=${GEMINI_API_KEY}`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify(embeddingBody),\n        });\n        if (!retry.ok) {\n            throw new Error(`Embedding API failed: ${retry.status}`);\n        }\n        const data = await retry.json();\n        return data.embedding?.values ?? [];\n    }\n\n    const data = await response.json();\n    return data.embedding?.values ?? [];\n}\n"}, {"name": "search.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// search.ts â€” ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ (ë²¡í„° + í‚¤ì›Œë“œ + íƒ€ê²Ÿ + ì²­í¬ í´ë°±)\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport { supabase } from \"./config.ts\";\nimport type { EntityResult, IntentAnalysis } from \"./types.ts\";\n\n// â”€â”€â”€ ì•½ì¹­(Abbreviation) â†’ ì •ì‹ ëª…ì¹­ ë§¤í•‘ â”€â”€â”€\n// Why: \"TIGìš©ì ‘\" ê²€ìƒ‰ ì‹œ ì—”í‹°í‹°ëª… \"TIG(Tungsten Inert Gas)ìš©ì ‘\"ì—\n//      ILIKE %TIG%ìš©ì ‘%ì´ ë§¤ì¹­ ì•ˆ ë¨ â†’ ì •ì‹ ëª…ì¹­ì„ ë³‘ë ¬ ê²€ìƒ‰\nconst ABBREVIATION_MAP: Record<string, string[]> = {\n    \"TIG\": [\"TIG(Tungsten Inert Gas)\", \"Tungsten Inert Gas\"],\n    \"MIG\": [\"MIG(Metal Inert Gas)\", \"Metal Inert Gas\"],\n    \"MAG\": [\"MAG(Metal Active Gas)\", \"Metal Active Gas\"],\n    \"CO2\": [\"CO2 ì•„í¬\", \"COâ‚‚\"],\n    \"SMAW\": [\"SMAW(Shielded Metal Arc Welding)\", \"í”¼ë³µì•„í¬ìš©ì ‘\"],\n    \"SAW\": [\"SAW(Submerged Arc Welding)\", \"ì„œë¸Œë¨¸ì§€ë“œì•„í¬ìš©ì ‘\"],\n};\n\n// â”€â”€â”€ ê±´ì„¤ ë„ë©”ì¸ ë™ì˜ì–´ ì‚¬ì „ (í™•ì¥ v2) â”€â”€â”€\n// Why: \"PEê´€\" ê²€ìƒ‰ ì‹œ \"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\" ë“±\n//      ì´ë¦„ì— \"PE\"ê°€ ì—†ì§€ë§Œ PEê´€ ì‘ì—…ì¸ entityë¥¼ ê²€ìƒ‰ë§ì— í¬í•¨\n// Note: expandDomainSynonyms()ì˜ ì–‘ë°©í–¥ includes ë§¤ì¹­ìœ¼ë¡œ ì¸í•´\n//       ë‹¨ê¸€ì ë™ì˜ì–´(\"ì¹ \" ë“±)ëŠ” ì˜¤íƒ(False Positive)ì„ ìœ ë°œí•˜ë¯€ë¡œ ê¸ˆì§€\nconst DOMAIN_SYNONYM_MAP: Record<string, string[]> = {\n    // 1. ë°°ê´€/ìš©ì ‘/ê¸°ê³„ì„¤ë¹„\n    \"PEê´€\": [\"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\", \"ìƒˆë“¤ìœµì°©\", \"í´ë¦¬ì—í‹¸ë Œ\", \"HDPE\", \"ë²„íŠ¸ìœµì°©\", \"ê°€êµí™”\"],\n    \"í´ë¦¬ì—í‹¸ë Œê´€\": [\"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\", \"ìƒˆë“¤ìœµì°©\", \"PEê´€\", \"HDPE\"],\n    \"ìœµì°©\": [\"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\", \"ìƒˆë“¤ìœµì°©\", \"PEê´€\", \"í´ë¦¬ì—í‹¸ë Œ\", \"ë²„íŠ¸ ìœµì°©ì‹\"],\n    \"ê°€ìŠ¤ê´€\": [\"PEê´€\", \"í´ë¦¬ì—í‹¸ë Œ\", \"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\"],\n    \"ìš©ì ‘\": [\"TIG\", \"MIG\", \"MAG\", \"CO2\", \"ì•„í¬ìš©ì ‘\", \"ê°€ìŠ¤ìš©ì ‘\", \"í”¼ë³µì•„í¬\", \"ì „ê¸°ì•„í¬ìš©ì ‘\"],\n    \"ë°°ê´€\": [\"ê°•ê´€\", \"í´ë¦¬ì—í‹¸ë Œê´€\", \"PVCê´€\", \"PEê´€\", \"ë™ê´€\", \"ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€\", \"ì£¼ì² ê´€\"],\n    // 2. ê±´ì¶•/ë§ˆê°/ë°©ìˆ˜\n    \"ë„ì¥\": [\"í˜ì¸íŠ¸\", \"ë„ë£Œ\", \"ë°©ì²­\", \"í•˜ë„\", \"ìƒë„\", \"ì¤‘ë„\", \"ë¶“ì¹ \", \"ë¿œì¹ \", \"ë¡¤ëŸ¬ì¹ \"],\n    \"ë°©ìˆ˜\": [\"ì•„ìŠ¤íŒ”íŠ¸ë°©ìˆ˜\", \"ì‹œíŠ¸ë°©ìˆ˜\", \"ë„ë§‰ë°©ìˆ˜\", \"ì‹¤ë§\", \"ì½”í‚¹\", \"ìš°ë ˆíƒ„\", \"ì—í­ì‹œ\"],\n    // 3. í† ëª©/ê¸°ì´ˆ/ê³¨ì¡°\n    \"ì² ê·¼\": [\"ë°°ê·¼\", \"ì´ìŒ\", \"ì •ì°©\", \"ê°€ê³µì¡°ë¦½\", \"ì² ê·¼ê°€ê³µ\", \"ìŠ¤í˜ì´ì„œ\"],\n    \"ì½˜í¬ë¦¬íŠ¸\": [\"íƒ€ì„¤\", \"ê±°í‘¸ì§‘\", \"ì–‘ìƒ\", \"ë ˆë¯¸ì½˜\", \"ë¬´ê·¼ì½˜í¬ë¦¬íŠ¸\", \"ì² ê·¼ì½˜í¬ë¦¬íŠ¸\", \"íŒí”„ì¹´\"],\n    \"í¬ì¥\": [\"ì•„ìŠ¤íŒ”íŠ¸\", \"ì½˜í¬ë¦¬íŠ¸í¬ì¥\", \"ë‹¤ì§\", \"í‘œì¸µ\", \"ê¸°ì¸µ\", \"ë³´ì¡°ê¸°ì¸µ\", \"ì•„ìŠ¤ì½˜\", \"íƒì½”íŠ¸\", \"í”„ë¼ì„ì½”íŠ¸\"],\n    \"êµ´ì°©\": [\"í„°íŒŒê¸°\", \"ë˜ë©”ìš°ê¸°\", \"í† ê³µ\", \"ì”í† ì²˜ë¦¬\", \"ë°œíŒŒ\", \"ë¸Œë ˆì´ì¹´\", \"ë°±í˜¸\", \"í¬ë¡¤ëŸ¬ë“œë¦´\", \"êµ´ì‚­ê¸°\"],\n};\n\n// â”€â”€â”€ ì§ˆë¬¸ì—ì„œ ì•½ì¹­ ê°ì§€ â†’ í™•ì¥ íŒ¨í„´ ëª©ë¡ ë°˜í™˜ â”€â”€â”€\nexport function expandAbbreviations(question: string): string[] {\n    const expanded: string[] = [];\n    for (const [abbr, aliases] of Object.entries(ABBREVIATION_MAP)) {\n        // ëŒ€ì†Œë¬¸ì ë¬´ê´€ ê²€ìƒ‰ (\"tig\" â†’ \"TIG\")\n        if (question.toUpperCase().includes(abbr)) {\n            expanded.push(...aliases);\n        }\n    }\n    return expanded;\n}\n\n// â”€â”€â”€ ë„ë©”ì¸ ë™ì˜ì–´ í™•ì¥ â”€â”€â”€\n// Why: ì‚¬ìš©ìê°€ \"PEê´€\"ì„ ê²€ìƒ‰í•˜ë©´ ILIKE '%ë°”íŠ¸ìœµì°©%' ë“±ë„ ë³‘ë ¬ ê²€ìƒ‰\nexport function expandDomainSynonyms(terms: string[]): string[] {\n    const expanded: string[] = [];\n    for (const term of terms) {\n        const termUpper = term.toUpperCase();\n        for (const [key, synonyms] of Object.entries(DOMAIN_SYNONYM_MAP)) {\n            const keyUpper = key.toUpperCase();\n            // ì–‘ë°©í–¥ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ): \"peê´€\" âŠƒ \"PEê´€\" ë˜ëŠ” \"PEê´€\" âŠƒ \"peê´€\"\n            if (termUpper.includes(keyUpper) || keyUpper.includes(termUpper)) {\n                expanded.push(...synonyms);\n            }\n        }\n    }\n    return [...new Set(expanded)]; // ì¤‘ë³µ ì œê±°\n}\n\n// â”€â”€â”€ ì˜í•œ í˜¼í•©ì–´ ë¶„ë¦¬ íŒ¨í„´ ìƒì„± â”€â”€â”€\n// Why: \"PEê´€\" ê²€ìƒ‰ ì‹œ ILIKE '%PEê´€%'ì€ \"ê°€ìŠ¤ìš© í´ë¦¬ì—í‹¸ë Œ(PE)ê´€\"ì— ë§¤ì¹­ ì•ˆ ë¨\n//      PEì™€ ê´€ ì‚¬ì´ì— ')' ê´„í˜¸ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸.\n//      \"PEê´€\" â†’ \"%PE%ê´€%\" ë¡œ ë¶„ë¦¬í•˜ì—¬ ì¤‘ê°„ ë¬¸ìë¥¼ í—ˆìš©í•˜ëŠ” ì™„í™” íŒ¨í„´ ìƒì„±\nexport function expandMixedTerms(terms: string[]): string[] {\n    const extra: string[] = [];\n    for (const t of terms) {\n        // ì˜ë¬¸+í•œê¸€ ê²½ê³„ì—ì„œ ë¶„ë¦¬: \"PEê´€\" â†’ [\"PE\", \"ê´€\"], \"HDPEê´€\" â†’ [\"HDPE\", \"ê´€\"]\n        const parts = t.match(/[A-Za-z0-9]+|[ê°€-í£]+/g);\n        if (parts && parts.length >= 2) {\n            // ì›ë³¸(\"PEê´€\")ê³¼ ë‹¤ë¥¸ ì™„í™” íŒ¨í„´(\"%PE%ê´€%\") ì¶”ê°€\n            const relaxed = \"%\" + parts.join(\"%\") + \"%\";\n            const strict = `%${t}%`;\n            if (relaxed !== strict) {\n                extra.push(relaxed);\n            }\n        }\n    }\n    return extra;\n}\n\n// â”€â”€â”€ ì§ˆë¬¸ì—ì„œ ê·œê²© ìˆ«ì ì¶”ì¶œ â”€â”€â”€\n// \"ê°•ê´€ìš©ì ‘ 200mm SCH 40\" â†’ [\"200\", \"SCH 40\"]\n// \"ê°•ê´€ìš©ì ‘ Ï†350 SCH 20\"  â†’ [\"350\", \"SCH 20\"]\nexport function extractSpecNumbers(question: string): string[] {\n    const nums: string[] = [];\n\n    // êµ¬ê²½ ìˆ«ì ì¶”ì¶œ (200mm, Ï†200, 200A ë“±ì—ì„œ ìˆ«ìë§Œ)\n    const diameterMatch = question.match(/(?:[Ï†Î¦Ã¸âˆ…]?\\s*)(\\d{2,4})\\s*(?:mm|A|ãœ)?/);\n    if (diameterMatch) nums.push(diameterMatch[1]);\n\n    // SCH ì¶”ì¶œ (SCH 40, SCH40 ë“±)\n    const schMatch = question.match(/SCH\\s*(\\d+)/i);\n    if (schMatch) nums.push(`SCH ${schMatch[1]}`);\n\n    return nums;\n}\n\n// â”€â”€â”€ ILIKE ê¸°ë°˜ í‚¤ì›Œë“œ í´ë°± ê²€ìƒ‰ â”€â”€â”€\nexport async function keywordFallbackSearch(question: string, specNumbers: string[]): Promise<EntityResult[]> {\n    // ì§ˆë¬¸ì—ì„œ ê³µì¢…ëª… ì¶”ì¶œ (í•œê¸€ 2ê¸€ì ì´ìƒ ë‹¨ì–´)\n    const koreanWords = question.match(/[ê°€-í£]{2,}/g) || [];\n    // í’ˆì…ˆ, mm ë“± ì¼ë°˜ í‚¤ì›Œë“œ ì œì™¸\n    const stopWords = new Set([\"í’ˆì…ˆ\", \"ì¸ë ¥\", \"ì¸ê³µ\", \"ìˆ˜ëŸ‰\", \"ë‹¨ìœ„\", \"ì¥ë¹„\", \"ìì¬\", \"ì•Œë ¤ì¤˜\", \"ì–¼ë§ˆ\", \"ê´€ë ¨\"]);\n    const workKeywords = koreanWords.filter(w => !stopWords.has(w));\n\n    if (workKeywords.length === 0) return [];\n\n    // ë‹¨ì¼ ILIKE íŒ¨í„´ ì¡°í•©: \"%ê°•ê´€ìš©ì ‘%200%SCH 40%\"\n    // Why: supabase-js v2ì˜ .ilike() ì²´ì´ë‹ ì‹œ TypeScript íƒ€ì… ì†Œì‹¤ ë¬¸ì œ íšŒí”¼\n    //      ë‹¨ì¼ í˜¸ì¶œë¡œ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì—”í‹°í‹° ê²€ìƒ‰\n    const allTokens = [...workKeywords, ...specNumbers];\n    const pattern = \"%\" + allTokens.join(\"%\") + \"%\";\n\n    // â”€â”€â”€ ì•½ì¹­ í™•ì¥: TIG â†’ TIG(Tungsten Inert Gas) ë“± â”€â”€â”€\n    const abbrExpansions = expandAbbreviations(question);\n    const orClauses = [`name.ilike.${pattern}`, `properties->>'korean_alias'.ilike.${pattern}`];\n    for (const alias of abbrExpansions) {\n        orClauses.push(`name.ilike.%${alias}%`);\n    }\n    const { data, error } = await supabase\n        .from(\"graph_entities\")\n        .select(\"id, name, type, properties, source_section\")\n        .in(\"type\", [\"WorkType\", \"Standard\"])\n        .or(`name.ilike.${pattern},properties->>\"korean_alias\".ilike.${pattern}`)\n        .limit(3);\n\n    if (error || !data) {\n        console.error(\"keywordFallbackSearch error:\", error?.message);\n        return [];\n    }\n\n    // EntityResult í˜•íƒœë¡œ ë³€í™˜ (similarityëŠ” 1.0ìœ¼ë¡œ ì„¤ì • â€” ì •í™• ë§¤ì¹­)\n    console.log(`[keywordFallback] ${data.length}ê±´ ë§¤ì¹­ (ì•½ì¹­í™•ì¥: ${abbrExpansions.length}ê°œ)`);\n    return (data as any[]).map((e: any) => ({\n        id: e.id,\n        name: e.name,\n        type: e.type,\n        properties: e.properties || {},\n        similarity: 1.0, // í‚¤ì›Œë“œ ì •í™• ë§¤ì¹­\n        source_section: e.source_section,\n    }));\n}\n\n// â”€â”€â”€ Layer 4: chunk ë³¸ë¬¸ í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ê²€ìƒ‰ â”€â”€â”€\n// Why: \"ì¥ë¹„í¸ì„±\", \"ì¸ë ¥í¸ì„±\" ë“± ì—”í‹°í‹° ì´ë¦„ì— ì—†ì§€ë§Œ\n//      chunk ë³¸ë¬¸ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì†Œì œëª©/ìš©ì–´ë¥¼ ê²€ìƒ‰\n//      ê¸°ì¡´ Layer 1~3ì— ì˜í–¥ ì—†ì´, ì¡°ê±´ë¶€ë¡œë§Œ ì‹¤í–‰\nexport async function chunkTextFallbackSearch(\n    question: string\n): Promise<EntityResult[]> {\n    // 1. ì§ˆë¬¸ì—ì„œ í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ (ê²½ëŸ‰ stopWords â€” \"ì¥ë¹„\",\"ì¸ë ¥\" ë“±ì€ ë³´ì¡´)\n    const koreanWords = question.match(/[ê°€-í£]{2,}/g) || [];\n    const contextStopWords = new Set([\n        \"í’ˆì…ˆ\", \"ì•Œë ¤ì¤˜\", \"ì–¼ë§ˆ\", \"ê´€ë ¨\", \"ì–´ë–»ê²Œ\", \"ë¬´ì—‡\", \"í™•ì¸\", \"ê²€ìƒ‰\",\n    ]);\n    const filteredWords = koreanWords.filter(w => !contextStopWords.has(w));\n    if (filteredWords.length === 0) return [];\n\n    // 2. ë³µí•©ì–´ ìƒì„±: [\"ì¥ë¹„\", \"í¸ì„±\"] â†’ \"ì¥ë¹„í¸ì„±\"\n    const compoundPatterns: string[] = [];\n    for (let i = 0; i < filteredWords.length - 1; i++) {\n        compoundPatterns.push(filteredWords[i] + filteredWords[i + 1]);\n    }\n    if (filteredWords.length >= 2) {\n        compoundPatterns.push(filteredWords.join(''));\n    }\n\n    // ê°€ë“œ: ë‹¨ì¼ í‚¤ì›Œë“œë§Œ ë‚¨ìœ¼ë©´ chunk ê²€ìƒ‰ skip (\"ì¥ë¹„\"ë§Œìœ¼ë¡œ ê²€ìƒ‰ â†’ ìˆ˜ë°± ê±´ ë…¸ì´ì¦ˆ)\n    if (filteredWords.length < 2 && compoundPatterns.length === 0) {\n        console.log(`[chunkTextFallback] ë‹¨ì¼ í‚¤ì›Œë“œë§Œ â†’ skip`);\n        return [];\n    }\n\n    // 3. chunk textì—ì„œ ILIKE ê²€ìƒ‰ (ë³µí•©ì–´ ìš°ì„  â†’ ì›ë³¸ í‚¤ì›Œë“œ ì¡°í•© ìˆœ)\n    const searchPatterns = [\n        ...compoundPatterns.map(p => `%${p}%`),\n        `%${filteredWords.join('%')}%`,\n    ];\n\n    for (const pattern of searchPatterns) {\n        const { data: matchedChunks } = await supabase\n            .from(\"graph_chunks\")\n            .select(\"section_id, title, department, chapter\")\n            .ilike(\"text\", pattern)\n            .limit(10);\n\n        if (matchedChunks && matchedChunks.length > 0) {\n            // ì¤‘ë³µ section_id ì œê±°\n            const uniqueSections = new Map<string, any>();\n            matchedChunks.forEach((c: any) => {\n                if (!uniqueSections.has(c.section_id)) {\n                    uniqueSections.set(c.section_id, c);\n                }\n            });\n\n            const sectionIds = Array.from(uniqueSections.keys());\n            console.log(`[chunkTextFallback] pattern=\"${pattern}\" â†’ ${sectionIds.length}ê°œ ì„¹ì…˜: ${sectionIds.join(', ')}`);\n\n            // 4. ë§¤ì¹­ëœ ì„¹ì…˜ì˜ WorkType ì¡°íšŒ\n            const { data: wtData } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .eq(\"type\", \"WorkType\")\n                .in(\"source_section\", sectionIds)\n                .limit(15);\n\n            if (wtData && wtData.length > 0) {\n                console.log(`[chunkTextFallback] WorkType ${wtData.length}ê±´ ë°˜í™˜`);\n                return (wtData as any[]).map(e => ({\n                    id: e.id, name: e.name, type: e.type,\n                    properties: e.properties || {},\n                    similarity: 0.85,\n                    source_section: e.source_section,\n                }));\n            }\n\n            // WorkType ì—†ìœ¼ë©´ â†’ Section ì—”í‹°í‹° ë°˜í™˜\n            const { data: sectionEntities } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .eq(\"type\", \"Section\")\n                .in(\"source_section\", sectionIds)\n                .limit(10);\n\n            if (sectionEntities && sectionEntities.length > 0) {\n                console.log(`[chunkTextFallback] Section ${sectionEntities.length}ê±´ ë°˜í™˜`);\n                return (sectionEntities as any[]).map(e => ({\n                    id: e.id, name: e.name, type: e.type,\n                    properties: e.properties || {},\n                    similarity: 0.80,\n                    source_section: e.source_section,\n                }));\n            }\n        }\n    }\n\n    return [];\n}\n\n// â”€â”€â”€ WorkType ì¤‘ë³µ ì œê±° (í´ë¦° DBë¡œ ì¸í•´ ì‚­ì œë¨ ë¨) â”€â”€â”€\n// C-1. ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ í´ë°±\nexport async function searchEntities(embedding: number[], question: string): Promise<EntityResult[]> {\n    const { data, error } = await supabase.rpc(\"search_entities_by_embedding\", {\n        query_embedding_text: JSON.stringify(embedding),\n        match_count: 5,\n        match_threshold: 0.4, // ê±´ì„¤ ìš©ì–´ íŠ¹ìˆ˜ì„± ê³ ë ¤ threshold ì™„í™”\n    });\n\n    if (error) {\n        console.error(\"searchEntities error:\", error.message);\n        return [];\n    }\n\n    let entities = (data || []) as EntityResult[];\n\n    // â”€â”€â”€ í‚¤ì›Œë“œ í´ë°±: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì— ì§ˆë¬¸ì˜ í•µì‹¬ ê·œê²©ì´ ì—†ìœ¼ë©´ ILIKE ë³´ì™„ â”€â”€â”€\n    // Why: ì„ë² ë”© ëª¨ë¸ì´ \"200mm\"ì™€ \"(200,\"ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ì˜ ëª»í•˜ì—¬\n    //       \"ê°•ê´€ìš©ì ‘(250, SCH 140)\"ì´ \"ê°•ê´€ìš©ì ‘(200, SCH 40)\"ë³´ë‹¤ ë†’ì€ ìœ ì‚¬ë„ ë°˜í™˜\n    //       â†’ ê·œê²© ìˆ«ì ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì •í™•í•œ ì—”í‹°í‹°ë¥¼ í´ë°± ê²€ìƒ‰\n    const specNumbers = extractSpecNumbers(question);\n    if (specNumbers.length > 0) {\n        // ë²¡í„° ê²°ê³¼ì— ì§ˆë¬¸ì˜ ê·œê²© ìˆ«ìê°€ í¬í•¨ëœ ì—”í‹°í‹°ê°€ ìˆëŠ”ì§€ í™•ì¸\n        const hasExactMatch = entities.some(e =>\n            specNumbers.every(num => e.name.includes(num))\n        );\n\n        if (!hasExactMatch) {\n            console.log(`[í‚¤ì›Œë“œ í´ë°±] ë²¡í„° ê²°ê³¼ì— ${specNumbers.join(',')} ë¯¸í¬í•¨, ILIKE í´ë°± ì‹¤í–‰`);\n            const fallbackEntities = await keywordFallbackSearch(question, specNumbers);\n            if (fallbackEntities.length > 0) {\n                // í´ë°± ê²°ê³¼ë¥¼ ìµœìƒìœ„ì— ì‚½ì…, ê¸°ì¡´ ë²¡í„° ê²°ê³¼ì—ì„œ ì¤‘ë³µ ì œê±°\n                const fallbackIds = new Set(fallbackEntities.map(e => e.id));\n                entities = [\n                    ...fallbackEntities,\n                    ...entities.filter(e => !fallbackIds.has(e.id)),\n                ].slice(0, 5);\n            }\n        }\n    }\n\n    // (Codex F4) ì´ì œ search_entities_by_embedding ì—ì„œ source_sectionì„ ì§ì ‘ ë°˜í™˜í•˜ë¯€ë¡œ ì¶”ê°€ ì¿¼ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n    return entities;\n}\n\n// â”€â”€â”€ E-3. íƒ€ê²Ÿ ê²€ìƒ‰ (3ë‹¨ê³„ ìºìŠ¤ì¼€ì´ë“œ) â”€â”€â”€\n// Why: ì˜ë„ ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì •í™•ë„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ê²€ìƒ‰.\n//      ë²¡í„° ê²€ìƒ‰ì€ ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œë§Œ ì‚¬ìš©.\nexport async function targetSearch(\n    analysis: IntentAnalysis,\n    embedding: number[],\n    question: string\n): Promise<EntityResult[]> {\n\n    const toEntityResults = (data: any[], similarity: number): EntityResult[] =>\n        (data as any[]).map((e: any) => ({\n            id: e.id, name: e.name, type: e.type,\n            properties: e.properties || {},\n            similarity,\n            source_section: e.source_section,\n        }));\n\n    // 1ë‹¨ê³„: ILIKE ì •í™• ë§¤ì¹­ (work_name + spec, korean_alias í¬í•¨)\n    if (analysis.work_name && analysis.spec) {\n        const pattern = `%${analysis.work_name}%${analysis.spec}%`;\n        const { data } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties, source_section\")\n            .in(\"type\", [\"WorkType\", \"Section\"])\n            .or(`name.ilike.${pattern},properties->>\"korean_alias\".ilike.${pattern}`)\n            .limit(5);\n\n        if (data && data.length > 0) {\n            console.log(`[targetSearch] 1ë‹¨ê³„ ILIKE ì •í™• ë§¤ì¹­: ${data.length}ê±´`);\n            return toEntityResults(data, 1.0);\n        }\n\n        // 1ë‹¨ê³„ ì‹¤íŒ¨ â†’ work_nameë§Œìœ¼ë¡œ ì¬ì‹œë„ (specì´ ì—”í‹°í‹°ëª…ì— ì—†ëŠ” ê²½ìš°)\n        // Why: \"PEê´€\" â†’ \"%PEê´€%\" ë§¤ì¹­ ì‹¤íŒ¨ ëŒ€ë¹„, ì˜í•œ í˜¼í•©ì–´ ì™„í™” íŒ¨í„´ë„ ì¶”ê°€\n        const fallbackPattern = `%${analysis.work_name}%`;\n        const mixedPatterns = expandMixedTerms([analysis.work_name]);\n        // ğŸ’¡ [Track B-1] 1ë‹¨ê³„ì—ë„ ë„ë©”ì¸ ë™ì˜ì–´ í™•ì¥ ì ìš©\n        const stage1Synonyms = expandDomainSynonyms([analysis.work_name]);\n        const fallbackOrClauses = [\n            `name.ilike.${fallbackPattern}`,\n            `properties->>\"korean_alias\".ilike.${fallbackPattern}`,\n            ...mixedPatterns.map(p => `name.ilike.${p}`),\n            ...stage1Synonyms.map(s => `name.ilike.%${s}%`),\n        ].join(\",\");\n        const { data: fallback } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties, source_section\")\n            .in(\"type\", [\"WorkType\", \"Section\"])\n            .or(fallbackOrClauses)\n            .limit(20);\n\n        if (fallback && fallback.length > 0) {\n            console.log(`[targetSearch] 1ë‹¨ê³„ work_name í´ë°±(+ë™ì˜ì–´): ${fallback.length}ê±´`);\n            return toEntityResults(fallback, 0.98);\n        }\n\n        // 1ë‹¨ê³„ ì•½ì¹­ í™•ì¥ í´ë°±: TIG â†’ TIG(Tungsten Inert Gas) ë“±\n        const abbrExpansions = expandAbbreviations(analysis.work_name);\n        if (abbrExpansions.length > 0) {\n            const abbrOrClauses = abbrExpansions.map(a => `name.ilike.%${a}%`).join(\",\");\n            const { data: abbrData } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .in(\"type\", [\"WorkType\", \"Section\", \"Standard\"])\n                .or(abbrOrClauses)\n                .limit(5);\n\n            if (abbrData && abbrData.length > 0) {\n                console.log(`[targetSearch] 1ë‹¨ê³„ ì•½ì¹­ í™•ì¥: ${abbrData.length}ê±´`);\n                return toEntityResults(abbrData, 0.96);\n            }\n        }\n    }\n\n    // 2ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ILIKE (korean_alias í¬í•¨)\n    const searchTerms = analysis.keywords.length > 0\n        ? analysis.keywords\n        : (analysis.work_name ? [analysis.work_name] : []);\n\n    if (searchTerms.length > 0) {\n        // â­ ILIKE ê²€ìƒ‰ì—ëŠ” noiseê°€ ì ì€ í‚¤ì›Œë“œë§Œ ì‚¬ìš©\n        //    - í•œê¸€ í‚¤ì›Œë“œ: í•­ìƒ í¬í•¨ (PEê´€, PEë“œëŸ¼, í´ë¦¬ì—í‹¸ë Œ ë“±)\n        //    - ì˜ë¬¸ í‚¤ì›Œë“œ â‰¥ 4ì: í¬í•¨ (HDPE ë“±)\n        //    - ì˜ë¬¸ í‚¤ì›Œë“œ â‰¤ 3ì: ì œì™¸ (PE â†’ Type, Pipe, Speed ë“± noise)\n        const dedupTerms = [...new Set(searchTerms.filter(t => t.length >= 2))];\n        const ilikeTerms = dedupTerms.filter(t => {\n            const isAllEnglish = /^[A-Za-z]+$/.test(t);\n            return !isAllEnglish || t.length >= 4;  // ì˜ë¬¸ë§Œì´ë©´ 4ì ì´ìƒë§Œ\n        });\n\n        if (ilikeTerms.length === 0 && dedupTerms.length > 0) {\n            // ì „ë¶€ ì§§ì€ ì˜ë¬¸ â†’ work_name í´ë°±\n            ilikeTerms.push(...dedupTerms);\n        }\n\n        // â”€â”€â”€ ì˜í•œ í˜¼í•©ì–´ ì™„í™” íŒ¨í„´ ì¶”ê°€ â”€â”€â”€\n        // Why: \"PEê´€\" â†’ ILIKE '%PEê´€%' ì€ \"ê°€ìŠ¤ìš© í´ë¦¬ì—í‹¸ë Œ(PE)ê´€\"ì— ë§¤ì¹­ ì•ˆ ë¨\n        //      PEì™€ ê´€ ì‚¬ì´ì— ')' ê´„í˜¸ê°€ ìˆê¸° ë•Œë¬¸ â†’ '%PE%ê´€%' íŒ¨í„´ ì¶”ê°€\n        const mixedExpansions = expandMixedTerms(ilikeTerms);\n        // ğŸ’¡ [Track B-1] ë„ë©”ì¸ ë™ì˜ì–´ í™•ì¥: \"PEê´€\" â†’ \"ë°”íŠ¸ìœµì°©\", \"ì†Œì¼“ìœµì°©\" ë“± ë³‘ë ¬ ê²€ìƒ‰\n        const domainExpansions = expandDomainSynonyms(ilikeTerms);\n        const orClauses = [\n            ...ilikeTerms.map(t => `name.ilike.%${t}%`),\n            ...mixedExpansions.map(p => `name.ilike.${p}`),\n            ...domainExpansions.map(s => `name.ilike.%${s}%`),\n        ].join(\",\");\n        const { data } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties, source_section\")\n            .in(\"type\", [\"WorkType\", \"Section\"])\n            .or(orClauses)\n            .limit(50);\n\n        if (data && data.length > 0) {\n            // ê´€ë ¨ë„ ì •ë ¬: ë§¤ì¹­ í‚¤ì›Œë“œ ìˆ˜ + ì›ë¬¸ ì§ˆë¬¸ì–´ ë§¤ì¹­ ë³´ë„ˆìŠ¤\n            const questionKorean = question.match(/[ê°€-í£]+/g) || [];\n            const scored = data.map((e: any) => {\n                let score = 0;\n                const nameLower = e.name.toLowerCase();\n                // ëª¨ë“  í‚¤ì›Œë“œ(ì§§ì€ ì˜ë¬¸ í¬í•¨) ë§¤ì¹­ ì¹´ìš´íŠ¸\n                for (const t of dedupTerms) {\n                    if (nameLower.includes(t.toLowerCase())) score += 2;\n                }\n                // ì›ë¬¸ í•œê¸€ì–´ ë§¤ì¹­ ë³´ë„ˆìŠ¤ (ì˜ˆ: \"ê´€\" â†’ \"PEê´€\", \"í´ë¦¬ì—í‹¸ë Œê´€\" ê°€ì¤‘)\n                for (const k of questionKorean) {\n                    if (nameLower.includes(k)) score += 1;\n                }\n                return { ...e, _score: score };\n            });\n            scored.sort((a: any, b: any) => b._score - a._score);\n            const top = scored.slice(0, 20);\n            console.log(`[targetSearch] 2ë‹¨ê³„ í‚¤ì›Œë“œ ë§¤ì¹­: ${data.length}ê±´ â†’ ìƒìœ„ ${top.length}ê±´ (scores: ${top.slice(0, 5).map((s: any) => s._score).join(',')})`);\n            return toEntityResults(top, 0.95);\n        }\n\n        // 2ë‹¨ê³„ ì‹¤íŒ¨ â†’ work_name ë‹¨ë… ì¬ì‹œë„ (keywordsì— ê·œê²©ì´ í¬í•¨ë˜ì–´ ëª» ì°¾ëŠ” ê²½ìš°)\n        if (analysis.work_name && searchTerms.length > 1) {\n            const wnPattern = `%${analysis.work_name}%`;\n            const { data: wnData } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, properties, source_section\")\n                .in(\"type\", [\"WorkType\", \"Section\"])\n                .or(`name.ilike.${wnPattern},properties->>\"korean_alias\".ilike.${wnPattern}`)\n                .limit(20);\n\n            if (wnData && wnData.length > 0) {\n                console.log(`[targetSearch] 2ë‹¨ê³„ work_name í´ë°±: ${wnData.length}ê±´`);\n                return toEntityResults(wnData, 0.90);\n            }\n        }\n    }\n\n    // 3ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ (íƒ€ì… í•„í„° ì ìš© â€” Note/Equipment ì œì™¸)\n    const { data, error } = await supabase.rpc(\"search_entities_typed\", {\n        query_embedding_text: JSON.stringify(embedding),\n        match_count: 5,\n        match_threshold: 0.4,\n        type_filter: [\"Section\", \"WorkType\"],\n    });\n\n    if (error) {\n        console.error(\"[targetSearch] ë²¡í„° ê²€ìƒ‰ ì—ëŸ¬:\", error.message);\n        return searchEntities(embedding, question);\n    }\n\n    console.log(`[targetSearch] 3ë‹¨ê³„ ë²¡í„° ê²€ìƒ‰: ${(data || []).length}ê±´`);\n    const vectorResults = (data || []) as EntityResult[];\n\n    // 4ë‹¨ê³„: chunk text fallback (Layer 4)\n    // Why: ë²¡í„° ê²°ê³¼ê°€ Sectionë§Œì´ê±°ë‚˜ WorkType ìœ ì‚¬ë„ê°€ ë‚®ì„ ë•Œ,\n    //      chunk ë³¸ë¬¸ì—ë§Œ ì¡´ì¬í•˜ëŠ” ìš©ì–´(\"ì¥ë¹„í¸ì„±\", \"ì¸ë ¥í¸ì„±\" ë“±)ë¥¼ ê²€ìƒ‰\n    const hasGoodMatch = vectorResults.some(\n        e => e.type === 'WorkType' && e.similarity >= 0.7\n    );\n    if (!hasGoodMatch) {\n        console.log(`[targetSearch] 4ë‹¨ê³„ chunk text fallback ì‹œë„ (WorkType+simâ‰¥0.7 ì—†ìŒ)`);\n        const chunkResults = await chunkTextFallbackSearch(question);\n        if (chunkResults.length > 0) {\n            console.log(`[targetSearch] 4ë‹¨ê³„ chunk text: ${chunkResults.length}ê±´ â†’ ë²¡í„° ê²°ê³¼ì™€ ë³‘í•©`);\n            const chunkIds = new Set(chunkResults.map(e => e.id));\n            return [\n                ...chunkResults,\n                ...vectorResults.filter(e => !chunkIds.has(e.id)),\n            ];\n        }\n    }\n\n    return vectorResults;\n}\n\n// â”€â”€â”€ ê²€ìƒ‰ì–´ ì •ì œ ìœ í‹¸ë¦¬í‹° â”€â”€â”€\n// Why: LLMì´ work_nameê³¼ ì¤‘ë³µë˜ëŠ” í‚¤ì›Œë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,\n//      work_nameì— í¬í•¨ëœ í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ì—¬ ILIKE íŒ¨í„´ ì˜¤ì—¼ ë°©ì§€\nexport function buildSearchTerms(work_name: string | null, keywords: string[]): string[] {\n    if (!work_name) return keywords;\n    const nameLower = work_name.toLowerCase();\n    return keywords.filter(kw => {\n        const kwLower = kw.toLowerCase();\n        // work_nameì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œê±°\n        if (nameLower.includes(kwLower)) return false;\n        // í‚¤ì›Œë“œì— work_nameì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œê±°\n        if (kwLower.includes(nameLower)) return false;\n        return true;\n    });\n}\n"}, {"name": "graph.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// graph.ts â€” ê·¸ë˜í”„ í™•ì¥ (1-hop ê´€ê³„ + ê³„ì¸µ) + ì¼ìœ„ëŒ€ê°€ + ì›ë¬¸ ì²­í¬\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport { supabase } from \"./config.ts\";\nimport type { EntityResult, RelatedResource, IlwiItem, ChunkResult } from \"./types.ts\";\n\n// C-2. ê·¸ë˜í”„ í™•ì¥ (1-hop ê´€ê³„ + ê³„ì¸µ)\n// skipSectionExpansion: true â†’ ë™ì¼ sectionì˜ í˜•ì œ WorkType í™•ì¥ ìƒëµ\n//   Phase -1ì—ì„œ entity_idê°€ ì§ì ‘ ì „ë‹¬ëœ ê²½ìš° ì‚¬ìš©\n//   Why: ì‚¬ìš©ìê°€ íŠ¹ì • ê·œê²©(50 SCH20 ë“±)ì„ ì„ íƒí–ˆì„ ë•Œ,\n//        ê°™ì€ sectionì˜ ëª¨ë“  WorkType(15,20,25,...,600)ì„ í™•ì¥í•˜ë©´\n//        ìˆ˜ë°± ê°œ ê´€ê³„ê°€ contextì— í¬í•¨ë˜ì–´ LLMì´ í˜¼ë™í•¨\nexport async function expandGraph(\n    entityId: string,\n    entityType: string,\n    skipSectionExpansion: boolean = false\n): Promise<RelatedResource[]> {\n    // 1-hop ê´€ê³„ ì¡°íšŒ\n    const { data: relations, error: relErr } = await supabase.rpc(\n        \"get_related_resources\",\n        { p_entity_id: entityId }\n    );\n\n    if (relErr) {\n        console.error(\"expandGraph error:\", relErr.message);\n        return [];\n    }\n\n    let allRelations = (relations || []) as RelatedResource[];\n\n    // â”€â”€â”€ ë™ì¼ Sectionì˜ WorkType í™•ì¥ í•¨ìˆ˜ (ì¬ì‚¬ìš©) â”€â”€â”€\n    // Why: Section, WorkType, Note, Standard ë“± ì–´ë–¤ ì—”í‹°í‹°ì—ì„œë“ \n    //      source_sectionì´ ê°™ìœ¼ë©´ í•´ë‹¹ ì ˆì˜ ì „ì²´ ìì›ì„ íƒìƒ‰í•´ì•¼ í•¨\n    async function expandSectionWorkTypes(sourceSection: string): Promise<void> {\n        const { data: workTypes } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, properties\")\n            .eq(\"source_section\", sourceSection)\n            .eq(\"type\", \"WorkType\")\n            .limit(30);\n\n        if (!workTypes || workTypes.length === 0) return;\n\n        // ì´ë¯¸ allRelationsì— í¬í•¨ëœ WorkType ID ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€)\n        const existingIds = new Set(\n            allRelations\n                .filter(r => r.related_type === \"WorkType\")\n                .map(r => r.related_id)\n        );\n\n        // ê° WorkTypeì˜ ê´€ê³„ë¥¼ ë³‘ë ¬ ì¡°íšŒ\n        const workRelPromises = (workTypes as any[]).map(async (wt: any) => {\n            const { data: wtRels } = await supabase.rpc(\n                \"get_related_resources\",\n                { p_entity_id: wt.id }\n            );\n            return { workType: wt, relations: (wtRels || []) as RelatedResource[] };\n        });\n\n        const workRelResults = await Promise.all(workRelPromises);\n\n        for (const { workType, relations: wtRels } of workRelResults) {\n            // WorkType ìì²´ë¥¼ ê°€ìƒ ê´€ê³„ë¡œ ì¶”ê°€ (ì¤‘ë³µ ì œì™¸)\n            if (!existingIds.has(workType.id)) {\n                allRelations.push({\n                    direction: \"outbound\",\n                    relation: \"CONTAINS_WORK\",\n                    related_id: workType.id,\n                    related_name: workType.name,\n                    related_type: \"WorkType\",\n                    properties: workType.properties || {},\n                });\n            }\n            // WorkTypeì˜ REQUIRES_LABOR, REQUIRES_EQUIPMENT, USES_MATERIAL ê´€ê³„ ì¶”ê°€\n            // Why: ê° ê´€ê³„ì— work_type_nameì„ ì£¼ì…í•˜ì—¬, ì¶œë ¥ ì‹œ ì–´ë–¤ ê·œê²©(15mm, SCH 20 ë“±)ì˜ ì¸ë ¥ì¸ì§€ í‘œì‹œ\n            // Phase 5: sub_section ì†ì„±ì´ ìˆìœ¼ë©´ [sub_section] ì ‘ë‘ì‚¬ ì¶”ê°€ â†’ context.tsì—ì„œ ê·¸ë£¹ë³„ ì¶œë ¥\n            const subSection = (workType.properties as any)?.sub_section;\n            const displayWtName = subSection ? `[${subSection}] ${workType.name}` : workType.name;\n            const relevantRels = wtRels.filter((r: RelatedResource) =>\n                [\"REQUIRES_LABOR\", \"REQUIRES_EQUIPMENT\", \"USES_MATERIAL\", \"HAS_NOTE\"].includes(r.relation)\n            );\n            relevantRels.forEach(r => {\n                (r.properties as any).work_type_name = displayWtName;\n            });\n            allRelations = allRelations.concat(relevantRels);\n\n            // Fix A3: REQUIRES_LABOR ê´€ê³„ ì—†ì§€ë§Œ propertiesì— quantity/unitì´ ìˆëŠ” WT\n            // Why: 986ê°œ WT ì¤‘ 285ê°œê°€ ì´ íŒ¨í„´ (LLMì´ ê´€ê³„ ëŒ€ì‹  propertiesì— ì§ì ‘ ì €ì¥)\n            //      â†’ ê°€ìƒ REQUIRES_LABOR ê´€ê³„ë¥¼ ìƒì„±í•˜ì—¬ ì¸ë ¥ í…Œì´ë¸”ì— í¬í•¨\n            const hasLaborRel = relevantRels.some(r => r.relation === \"REQUIRES_LABOR\");\n            const wtProps = workType.properties || {} as any;\n            if (!hasLaborRel && wtProps.quantity && wtProps.unit) {\n                allRelations.push({\n                    direction: \"outbound\",\n                    relation: \"REQUIRES_LABOR\",\n                    related_id: workType.id + \"_prop\",\n                    related_name: wtProps.unit?.includes(\"ì¸\") ? workType.name : workType.name,\n                    related_type: \"Labor\",\n                    properties: {\n                        quantity: wtProps.quantity,\n                        unit: wtProps.unit,\n                        work_type_name: displayWtName,\n                        source: \"properties\",\n                    },\n                });\n            }\n\n            // Phase 1: Labor ê´€ê³„ë„ ì—†ê³  propertiesì—ë„ quantity ì—†ëŠ” WT â†’ unit_costs ì›ë¬¸ í´ë°±\n            // Why: TIGìš©ì ‘ ë“± ê·¸ë˜í”„ì— ê·œê²©ë³„ ì¸ë ¥ ë¯¸ì €ì¥ WTëŠ” unit_costs ì›ë¬¸ í…Œì´ë¸”ì„ ì§ì ‘ í™œìš©\n            if (!hasLaborRel && !(wtProps.quantity && wtProps.unit)) {\n                const { data: rawData } = await supabase\n                    .from(\"unit_costs\")\n                    .select(\"content, name\")\n                    .ilike(\"content\", `%${workType.name}%`)\n                    .limit(1);\n\n                if (rawData && rawData.length > 0) {\n                    allRelations.push({\n                        direction: \"outbound\",\n                        relation: \"RAW_TABLE\",\n                        related_id: workType.id + \"_raw\",\n                        related_name: (rawData[0] as any).name || workType.name,\n                        related_type: \"RawTable\",\n                        properties: {\n                            raw_content: (rawData[0] as any).content,\n                            work_type_name: workType.name,\n                            source: \"unit_costs_fallback\",\n                        },\n                    });\n                    console.log(`[expandGraph] RAW_TABLE fallback for ${workType.name}`);\n                }\n            }\n        }\n    }\n\n    // â”€â”€â”€ Section íƒ€ì…: ê³„ì¸µ + WorkType í™•ì¥ â”€â”€â”€\n    if (entityType === \"Section\") {\n        const { data: hierarchy, error: hierErr } = await supabase.rpc(\n            \"get_entity_hierarchy\",\n            { p_entity_id: entityId }\n        );\n\n        if (!hierErr && hierarchy) {\n            allRelations = allRelations.concat(hierarchy as RelatedResource[]);\n        }\n\n        // source_section ê¸°ì¤€ìœ¼ë¡œ WorkType 2-hop í™•ì¥ (skipSectionExpansionì´ë©´ ìƒëµ)\n        if (!skipSectionExpansion) {\n            const { data: sectionEntities } = await supabase\n                .from(\"graph_entities\")\n                .select(\"source_section\")\n                .eq(\"id\", entityId)\n                .limit(1);\n\n            const sectionEntity = (sectionEntities as any[])?.[0];\n            if (sectionEntity?.source_section) {\n                await expandSectionWorkTypes(sectionEntity.source_section);\n            }\n        }\n    }\n\n    // â”€â”€â”€ WorkType/Note/Standard íƒ€ì…: í˜•ì œ WorkType í™•ì¥ â”€â”€â”€\n    // Why: \"TIGìš©ì ‘\"(WorkType)ì„ ê²€ìƒ‰í•˜ë©´ W-0634ë§Œ ë‚˜ì˜¤ê³ ,\n    //      ê°™ì€ section(13-2-3)ì˜ ê°•ê´€ìš©ì ‘(W-0792~) â†’ REQUIRES_LABORê°€ ëˆ„ë½ë¨.\n    //      Note/Standardë„ ë§ˆì°¬ê°€ì§€ â€” í•´ë‹¹ section ì „ì²´ ìì›ì„ ë³´ì—¬ì¤˜ì•¼ í•¨.\n    // skipSectionExpansionì´ë©´ ìƒëµ: ì‚¬ìš©ìê°€ ì´ë¯¸ íŠ¹ì • entityë¥¼ ì„ íƒí•œ ìƒíƒœ\n    if (!skipSectionExpansion && [\"WorkType\", \"Note\", \"Standard\"].includes(entityType)) {\n        // í˜„ì¬ ì—”í‹°í‹°ì˜ source_section ì¡°íšŒ\n        const { data: selfEntities } = await supabase\n            .from(\"graph_entities\")\n            .select(\"source_section\")\n            .eq(\"id\", entityId)\n            .limit(1);\n\n        const selfEntity = (selfEntities as any[])?.[0];\n        if (selfEntity?.source_section) {\n            await expandSectionWorkTypes(selfEntity.source_section);\n        }\n    }\n\n    // â”€â”€â”€ HAS_NOTE ê´€ê³„ì˜ ì‹¤ì œ ë‚´ìš© ë³´ê°• â”€â”€â”€\n    // get_related_resourcesëŠ” ëŒ€ìƒ ì—”í‹°í‹°ì˜ propertiesë¥¼ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ\n    // Note ì—”í‹°í‹°ì˜ properties.contentë¥¼ ë³„ë„ ì¡°íšŒí•˜ì—¬ ê´€ê³„ì— ì£¼ì…\n    const noteRelations = allRelations.filter(r => r.relation === \"HAS_NOTE\");\n    if (noteRelations.length > 0) {\n        const noteIds = [...new Set(noteRelations.map(r => r.related_id))];\n        const { data: noteEntities } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, properties\")\n            .in(\"id\", noteIds);\n\n        if (noteEntities) {\n            const noteContentMap = new Map(\n                (noteEntities as any[]).map((e: any) => [\n                    e.id,\n                    e.properties?.content || null\n                ])\n            );\n            noteRelations.forEach(r => {\n                const content = noteContentMap.get(r.related_id);\n                if (content) {\n                    (r.properties as any).note_content = content;\n                }\n            });\n        }\n    }\n\n    return allRelations;\n}\n\n// C-3. ì¼ìœ„ëŒ€ê°€ ê²€ìƒ‰\nexport async function searchIlwi(\n    name: string,\n    spec: string | null\n): Promise<IlwiItem[]> {\n    const { data, error } = await supabase.rpc(\"search_ilwi\", {\n        search_name: name,\n        search_spec: spec,\n    });\n\n    if (error) {\n        console.error(\"searchIlwi error:\", error.message);\n        return [];\n    }\n\n    return (data || []) as IlwiItem[];\n}\n\n// C-4. ì›ë¬¸ ì²­í¬ ë³´ê°•\n// specFilter: entity ì„ íƒ ì‹œ í•´ë‹¹ spec(ë‘ê»˜ ë“±)ì— í•´ë‹¹í•˜ëŠ” tables í–‰ë§Œ í¬í•¨\n// Why: ê°•íŒ ì „ê¸°ì•„í¬ìš©ì ‘(ë‘ê»˜=4) ì„ íƒ ì‹œ ì „ ë²”ìœ„(3~50) ë°ì´í„°ê°€ contextì— ë²”ëŒí•˜ëŠ” ë¬¸ì œ ë°©ì§€\nexport async function retrieveChunks(\n    entities: EntityResult[],\n    specFilter?: string   // ì˜ˆ: \"4\" (ë‘ê»˜=4mmë§Œ í•„í„°ë§)\n): Promise<ChunkResult[]> {\n    // entity.source_section â†’ graph_chunks.section_id ë§¤ì¹­ (Codex F3)\n    const sectionIds = entities\n        .map((e) => e.source_section)\n        .filter((s): s is string => !!s);\n\n    if (sectionIds.length === 0) return [];\n\n    // ì¤‘ë³µ ì œê±°\n    const uniqueSectionIds = [...new Set(sectionIds)];\n\n    const { data, error } = await supabase\n        .from(\"graph_chunks\")\n        .select(\"id, section_id, title, department, chapter, section, text, tables\")\n        .in(\"section_id\", uniqueSectionIds)\n        .limit(15); // ê°•ê´€ìš©ì ‘ ë“± 11ê°œ chunk ì»¤ë²„\n\n    if (error) {\n        console.error(\"retrieveChunks error:\", error.message);\n        return [];\n    }\n\n    const rawChunks = (data || []) as any[];\n\n    // section_idë³„ ê·¸ë£¹í™” â†’ ë™ì¼ ì„¹ì…˜ì˜ ì—¬ëŸ¬ chunkë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©\n    // Why: ê°•ê´€ìš©ì ‘(13-2-3) ë“±ì€ 11ê°œ chunkì— tables ë¶„ì‚° â†’ í•˜ë‚˜ë¡œ í•©ì³ì•¼ LLMì´ ì „ì²´ í‘œ í™•ì¸ ê°€ëŠ¥\n    const sectionMap = new Map<string, any>();\n    for (const chunk of rawChunks) {\n        const sid = chunk.section_id;\n        if (!sectionMap.has(sid)) {\n            sectionMap.set(sid, { ...chunk, _allTables: [] });\n        }\n        const merged = sectionMap.get(sid)!;\n        // tables ìˆ˜ì§‘\n        if (chunk.tables && Array.isArray(chunk.tables)) {\n            merged._allTables.push(...chunk.tables);\n        }\n        // text ë³‘í•© (ë¹ˆ text ì œì™¸)\n        if (chunk.text && chunk.text.length > 0 && chunk.id !== merged.id) {\n            merged.text = (merged.text || \"\") + \"\\n\" + chunk.text;\n        }\n    }\n\n    // tables â†’ Markdown ë³€í™˜ í›„ textì— ì¶”ê°€\n    return Array.from(sectionMap.values()).map((chunk) => {\n        let fullText = chunk.text || \"\";\n        if (chunk._allTables && chunk._allTables.length > 0) {\n            const tablesMarkdown = chunk._allTables.map((t: any) => {\n                if (!t.rows || t.rows.length === 0) return \"\";\n                const headers: string[] = t.headers || Object.keys(t.rows[0]);\n                let rows = t.rows;\n\n                // specFilter ì ìš©: ì²« ë²ˆì§¸ header(spec ê¸°ì¤€ ì»¬ëŸ¼)ì˜ ê°’ìœ¼ë¡œ í–‰ í•„í„°ë§\n                // Why: \"ë‘ê»˜=4\" ì„ íƒ ì‹œ ë‘ê»˜=4 í–‰ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€(3,5,6...) ì œê±°\n                if (specFilter && headers.length > 0) {\n                    const specKey = headers[0]; // ì˜ˆ: \"êµ¬ë¶„ ìì„¸ ë° ì§ì¢… ë‘ê»˜(mm)\"\n                    const filtered = rows.filter((r: any) => {\n                        const val = String(r[specKey] ?? \"\");\n                        return val === specFilter;\n                    });\n                    if (filtered.length > 0) {\n                        rows = filtered;\n                        console.log(`[retrieveChunks] specFilter=\"${specFilter}\": ${t.rows.length}í–‰ â†’ ${rows.length}í–‰`);\n                    }\n                    // í•„í„° ê²°ê³¼ê°€ 0ê±´ì´ë©´ ì›ë³¸ ìœ ì§€ (fallback)\n                }\n\n                const headerRow = \"| \" + headers.join(\" | \") + \" |\";\n                const sepRow = \"| \" + headers.map(() => \"---\").join(\" | \") + \" |\";\n                const dataRows = rows.map((r: any) =>\n                    \"| \" + headers.map((h: string) => r[h] ?? \"\").join(\" | \") + \" |\"\n                );\n                return [headerRow, sepRow, ...dataRows].join(\"\\n\");\n            }).filter(Boolean).join(\"\\n\\n\");\n            fullText += \"\\n\" + tablesMarkdown;\n        }\n        delete chunk._allTables;\n        return {\n            ...chunk,\n            text: fullText.substring(0, 6000), // í™•ì¥: 2000â†’6000 (ë‹¤ìˆ˜ í‘œ í¬í•¨)\n        } as ChunkResult;\n    });\n}\n\n// â”€â”€â”€ ë…¸ì„ë‹¨ê°€ ì¡°íšŒ (labor_costs í…Œì´ë¸”) â”€â”€â”€\n// Why: cost_calculate intent ì‹œ ì‹¤ì œ ë…¸ë¬´ë¹„ ì‚°ì¶œì„ ìœ„í•´ ì§ì¢…ë³„ ë‹¨ê°€ í•„ìš”\nimport type { LaborCostEntry } from \"./types.ts\";\n\nexport async function fetchLaborCosts(jobNames: string[]): Promise<LaborCostEntry[]> {\n    if (jobNames.length === 0) return [];\n    const patterns = jobNames.map(name => name.replace(/\\s+/g, '%'));\n    const { data, error } = await supabase\n        .from(\"labor_costs\")\n        .select(\"job_name, cost_2026\")\n        .or(patterns.map(p => `job_name.ilike.%${p}%`).join(','));\n\n    if (error || !data) {\n        console.error(\"[fetchLaborCosts] error:\", error);\n        return [];\n    }\n    console.log(`[fetchLaborCosts] ì¡°íšŒ ${jobNames.length}ê°œ ì§ì¢… â†’ ${data.length}ê±´ ë§¤ì¹­`);\n    return data as LaborCostEntry[];\n}\n\n"}, {"name": "context.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// context.ts â€” LLM ì»¨í…ìŠ¤íŠ¸ ì¡°í•© + ì‘ë‹µ ì¡°ë¦½ í—¬í¼\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport type {\n    EntityResult, RelatedResource, IlwiItem, ChunkResult,\n    ChatResponse, SearchInfo, TokenUsage, SourceInfo,\n    ClarifyOption, ClarificationInfo, SelectorPanel, LLMResult,\n} from \"./types.ts\";\n\n// â”â”â” ì‘ë‹µ ì¡°ë¦½ í—¬í¼ â”â”â”\n// Why: handleChat ë‚´ 6ê³³+ ë°˜ë³µë˜ëŠ” ì‘ë‹µ ê°ì²´ ì¡°ë¦½ì„ í†µí•©í•˜ì—¬ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ\n// ì‘ë‹µ êµ¬ì¡° ë³€ê²½ ì‹œ ì´ í•¨ìˆ˜ë§Œ ìˆ˜ì •í•˜ë©´ ë¨\n\n/**\n * ë¹ˆ SearchInfo ìƒì„± (entities/relations ì—†ëŠ” ê°„ë‹¨ ì‘ë‹µìš©)\n */\nexport function makeEmptySearchInfo(startTime: number): SearchInfo {\n    return {\n        entities_found: 0,\n        relations_expanded: 0,\n        ilwi_matched: 0,\n        chunks_retrieved: 0,\n        latency_ms: Date.now() - startTime,\n    };\n}\n\n/**\n * \"answer\" íƒ€ì… ì‘ë‹µ ìƒì„±\n * @param answer - LLM ë‹µë³€ í…ìŠ¤íŠ¸\n * @param startTime - ì²˜ë¦¬ ì‹œì‘ ì‹œê°„ (latency ê³„ì‚°ìš©)\n * @param opts - ì„ íƒì  ì‘ë‹µ ë°ì´í„° (sources, entities, relations, llmResult ë“±)\n */\nexport function makeAnswerResponse(\n    answer: string,\n    startTime: number,\n    opts?: {\n        sources?: SourceInfo[];\n        entities?: EntityResult[];\n        relations?: RelatedResource[][];\n        ilwi?: IlwiItem[];\n        chunks?: ChunkResult[];\n        embeddingTokens?: number;\n        llmResult?: LLMResult;\n    }\n): ChatResponse {\n    const searchInfo: SearchInfo = {\n        entities_found: opts?.entities?.length || 0,\n        relations_expanded: opts?.relations\n            ? opts.relations.reduce((sum, r) => sum + r.length, 0)\n            : 0,\n        ilwi_matched: opts?.ilwi?.length || 0,\n        chunks_retrieved: opts?.chunks?.length || 0,\n        latency_ms: Date.now() - startTime,\n    };\n\n    // token_usageëŠ” llmResultê°€ ìˆì„ ë•Œë§Œ í¬í•¨\n    if (opts?.llmResult) {\n        const et = opts.embeddingTokens || 0;\n        const totalTokens = et + opts.llmResult.inputTokens + opts.llmResult.outputTokens;\n        searchInfo.token_usage = {\n            embedding_tokens: et,\n            llm_input_tokens: opts.llmResult.inputTokens,\n            llm_output_tokens: opts.llmResult.outputTokens,\n            total_tokens: totalTokens,\n            estimated_cost_krw: parseFloat((totalTokens * 0.0002).toFixed(2)),\n        };\n    }\n\n    return {\n        type: \"answer\",\n        answer,\n        sources: opts?.sources || [],\n        search_info: searchInfo,\n    };\n}\n\n/**\n * \"clarify\" íƒ€ì… ì‘ë‹µ ìƒì„±\n * @param message - ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€\n * @param startTime - ì²˜ë¦¬ ì‹œì‘ ì‹œê°„\n * @param clarification - ëª…í™•í™” ì˜µì…˜ ë°ì´í„°\n * @param opts - ì¶”ê°€ ê²€ìƒ‰ ì •ë³´ (entities ìˆ˜ ë“±)\n */\nexport function makeClarifyResponse(\n    message: string,\n    startTime: number,\n    clarification: {\n        options: ClarifyOption[];\n        reason: string;\n        original_query: string;\n        selector?: SelectorPanel;\n    },\n    opts?: {\n        entities?: EntityResult[];\n    }\n): ChatResponse {\n    return {\n        type: \"clarify\",\n        answer: message,\n        sources: [],\n        search_info: {\n            entities_found: opts?.entities?.length || 0,\n            relations_expanded: 0,\n            ilwi_matched: 0,\n            chunks_retrieved: 0,\n            latency_ms: Date.now() - startTime,\n        },\n        clarification: clarification as ClarificationInfo,\n    };\n}\n\n"}, {"name": "clarify.ts", "content": "ï»¿// clarify.ts - Intent analysis + graph-based clarification\nimport { DEEPSEEK_API_KEY, DEEPSEEK_URL } from \"./config.ts\";\nimport type { IntentAnalysis, ChatMessage, SessionContext, ClarifyResult, ClarifyOption } from \"./types.ts\";\nexport type { ClarifyResult };\n// â”â”â” [E] ì˜ë„ ê°ì§€ + ëª…í™•í™” â”â”â”\n\nconst COST_KEYWORDS = [\n    \"ë¹„ìš©\", \"ë‹¨ê°€\", \"ê°€ê²©\", \"ì›\", \"ì–¼ë§ˆ\", \"ì¼ìœ„ëŒ€ê°€\",\n    \"ì¬ë£Œë¹„\", \"ë…¸ë¬´ë¹„\", \"ê²½ë¹„\", \"í•©ê³„\", \"ì‚°ì¶œ\", \"ê²¬ì \",\n    \"ê³µì‚¬ë¹„\", \"ì›ê°€\", \"ê¸ˆì•¡\",\n];\n\nexport function detectCostIntent(question: string): boolean {\n    return COST_KEYWORDS.some((kw) => question.includes(kw));\n}\n\nconst SPEC_PATTERNS = [\n    /D\\d+/i,        // D80, D100\n    /\\d+mm/i,       // 100mm, 200mm\n    /\\d+í†¤/,        // 10í†¤, 25í†¤\n    /\\d+m[Â³Â²]?/,    // 0.7mÂ³, 100mÂ²\n    /\\d+-\\d+-\\d+/,  // 25-180-12 (ë ˆë¯¸ì½˜ ê·œê²©)\n];\n\nexport function extractSpec(question: string): string | null {\n    for (const pattern of SPEC_PATTERNS) {\n        const match = question.match(pattern);\n        if (match) return match[0];\n    }\n    return null;\n}\n\n// â”€â”€â”€ E-1. DeepSeek v3.2 ê¸°ë°˜ ì˜ë„ ë¶„ì„ â”€â”€â”€\n// Why: ê·œì¹™ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ì˜ í•œê³„(ì˜ë¬¸ ì•½ì–´, ë™ì˜ì–´, ë§¥ë½ ì´í•´ ë¶ˆê°€)ë¥¼\n//      LLM êµ¬ì¡°í™” ì¶œë ¥ìœ¼ë¡œ í•´ê²°. ë¹„ìš© ~â‚©1/í˜¸ì¶œë¡œ ë¬´ì‹œ ê°€ëŠ¥.\nconst INTENT_SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ê±´ì„¤ ê³µì‚¬ í’ˆì…ˆ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì˜ë„ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\nì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë°˜ë“œì‹œ ë‹¤ìŒ JSONë§Œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤.\n\n## âš ï¸ ì¤‘ìš”: intentëŠ” ë°˜ë“œì‹œ ì•„ë˜ 5ê°œ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©\n\n{\n  \"intent\": \"search\" | \"clarify_needed\" | \"followup\" | \"greeting\" | \"quantity_input\",\n  \"work_name\": \"ê³µì¢…ëª… í•œê¸€ (ì˜ˆ: ê°•ê´€ìš©ì ‘, ì¡ì² ë¬¼, TIGìš©ì ‘) ë˜ëŠ” null\",\n  \"spec\": \"ê·œê²© (ì˜ˆ: 200 SCH 40, D110, 2í†¤) ë˜ëŠ” null\",\n  \"keywords\": [\"ê²€ìƒ‰ìš©\", \"í‚¤ì›Œë“œ\"],\n  \"ambiguity_reason\": \"ëª¨í˜¸í•œ ì´ìœ  ë˜ëŠ” null\"\n}\n\n## ì˜ë„ íŒë³„ ê¸°ì¤€\n\n### search (ë°”ë¡œ ê²€ìƒ‰ ê°€ëŠ¥)\n- ê³µì¢…ëª…ì´ ëª…í™•í•˜ê³ , ê·œê²©ì´ íŠ¹ì •ë˜ì–´ ë‹¨ì¼ í’ˆì…ˆì„ ë°”ë¡œ ì°¾ì„ ìˆ˜ ìˆëŠ” ê²½ìš°\n- ì˜ˆ: \"ê°•ê´€ìš©ì ‘ 200mm SCH 40 í’ˆì…ˆ\", \"ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ ì¸ë ¥\", \"ê±°í‘¸ì§‘ ì„¤ì¹˜\"\n\n### clarify_needed (ë˜ë¬¼ì–´ì•¼ í•¨) â† ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ì´ê²ƒ ì„ íƒ\n- ê³µì¢…ëª…ì€ ìˆì§€ë§Œ ê·œê²©ë³„ ì„¸ë¶„í™”ê°€ í•„ìš”í•œë° ê·œê²© ë¯¸ì§€ì • â†’ clarify_needed\n  ì˜ˆ: \"ê°•ê´€ìš©ì ‘ í’ˆì…ˆ\" â†’ ê·œê²© í•„ìš”\n- ê³µì¢…ëª…ì´ ë„“ì€ ë²”ìœ„ì—¬ì„œ í•˜ìœ„ ë¶„ë¥˜ ì„ íƒì´ í•„ìš” â†’ clarify_needed\n  ì˜ˆ: \"ì¡ì² ë¬¼ ì œì‘\", \"ìš©ì ‘\", \"ë°°ê´€\" â†’ êµ¬ì²´ì  ê³µì¢…/ê·œê²© í™•ì¸ í•„ìš”\n- ìˆ˜ëŸ‰(2í†¤, 10m)ì€ ìˆì§€ë§Œ ìƒì„¸ ê·œê²©/ì¢…ë¥˜ê°€ ë¶ˆëª…í™• â†’ clarify_needed\n  ì˜ˆ: \"ì¡ì² ë¬¼ 2í†¤ ì œì‘\" â†’ ì¡ì² ë¬¼ì˜ ì¢…ë¥˜(ê·œê²©ì² ë¬¼? í˜„ì¥ì œì‘?) í™•ì¸ í•„ìš”\n- ì•½ì–´/ì˜ë¬¸ë§Œ ìˆì–´ í™•ì¸ í•„ìš” â†’ clarify_needed\n  ì˜ˆ: \"tig\" â†’ TIGìš©ì ‘ í™•ì¸ í•„ìš”\n\n### followup (ì´ì „ ëŒ€í™” í›„ì†)\n- ì´ì „ ëŒ€í™” ë§¥ë½ì˜ ì¶”ê°€ ì§ˆë¬¸. ì˜ˆ: \"SCH 80ì€?\", \"ì¥ë¹„ëŠ”?\"\n\n### greeting (ì¸ì‚¬/ë„ì›€ë§)\n- \"ì•ˆë…•\", \"ë­˜ í•  ìˆ˜ ìˆì–´?\"\n\n### quantity_input (ìˆ˜ëŸ‰ ê³„ì‚°)\n- ì´ì „ì— í’ˆì…ˆì´ ì´ë¯¸ ê²€ìƒ‰ëœ ìƒíƒœì—ì„œ ìˆ˜ëŸ‰ë§Œ ì…ë ¥. ì˜ˆ: \"10ê°œì†Œ\", \"50m ê³„ì‚°í•´ì¤˜\"\n\n## í‚¤ì›Œë“œ ì¶”ì¶œ ê·œì¹™\n- ì˜ë¬¸ ì•½ì–´ â†’ í•œê¸€ ë³€í™˜: \"tig\" â†’ [\"TIG\", \"TIGìš©ì ‘\"]\n- â­ í•œê¸€ ì™¸ë˜ì–´ â†’ ì˜ë¬¸ ì›ì–´ ë²ˆì—­ (í•„ìˆ˜!): ê±´ì„¤ ìš©ì–´ê°€ í•œê¸€ë¡œ ë“¤ì–´ì˜¤ë©´ ì˜ë¬¸ ì›ì–´ë„ keywordsì— ë°˜ë“œì‹œ í¬í•¨\n  ì˜ˆ: \"í¬ëŸ¬ì…”\" â†’ [\"í¬ëŸ¬ì…”\", \"Crusher\"], \"í”Œëœì§€\" â†’ [\"í”Œëœì§€\", \"Flange\"], \"ê·¸ë¼ì¸ë”©\" â†’ [\"ê·¸ë¼ì¸ë”©\", \"Grinding\"]\n  ì˜ˆ: \"ì—ì´ì¹˜ë¹”\" â†’ [\"ì—ì´ì¹˜ë¹”\", \"H-Beam\"], \"í”¼ë¸Œì´ì”¨\" â†’ [\"í”¼ë¸Œì´ì”¨\", \"PVC\"], \"í‹°ê·¸\" â†’ [\"í‹°ê·¸\", \"TIG\"]\n  ì˜ˆ: \"íˆí„°\" â†’ [\"íˆí„°\", \"Heater\"], \"íƒ±í¬\" â†’ [\"íƒ±í¬\", \"Tank\", \"STORAGE TANK\"]\n  ì˜ˆ: \"ì§€ì—”ì—ìŠ¤ì—ìŠ¤\" â†’ [\"ì§€ì—”ì—ìŠ¤ì—ìŠ¤\", \"GNSS\"], \"ìŠ¤í† ë¦¬ì§€\" â†’ [\"ìŠ¤í† ë¦¬ì§€\", \"STORAGE\"]\n- â­ work_nameë„ ë™ì¼í•˜ê²Œ: í•œê¸€ ì™¸ë˜ì–´ê°€ ê³µì¢…ëª…ì´ë©´ ì˜ë¬¸ ì›ì–´ë¥¼ work_nameì— ì‚¬ìš©\n  ì˜ˆ: \"í¬ëŸ¬ì…” ìš´ì „\" â†’ work_name: \"Crusher\", \"í”Œëœì§€ ì·¨ë¶€\" â†’ work_name: \"Flange ì·¨ë¶€\"\n- ê·œê²© ì •ê·œí™”: \"200mm\" â†’ \"200\", \"SCH40\" â†’ \"SCH 40\"\n- ë¶ˆìš©ì–´ ì œì™¸: \"í’ˆì…ˆ\", \"ì•Œë ¤ì¤˜\", \"ì–¼ë§ˆ\", \"ì¸ë ¥\", \"íˆ¬ì…\", \"ê´€ë ¨\"\n- ë™ì˜ì–´ í™•ì¥: \"PEê´€\" â†’ [\"PEê´€\", \"HDPEê´€\"], \"HDPEê´€\" â†’ [\"HDPEê´€\", \"PEê´€\", \"PEë“œëŸ¼\", \"í´ë¦¬ì—í‹¸ë Œ\"]\n- â­ ì•½ì–´/ì ‘ë‘ì–´ í™•ì¥: HDPEëŠ” PEì˜ í•˜ìœ„ ì¢…ë¥˜ì´ë¯€ë¡œ ë°˜ë“œì‹œ PEê´€ ë“± í•œê¸€ ë³µí•©ì–´ë¡œ keywordsì— í¬í•¨\n  ì˜ˆ: \"HDPEê´€\" â†’ keywords: [\"HDPEê´€\", \"PEê´€\", \"PEë“œëŸ¼\", \"í´ë¦¬ì—í‹¸ë Œ\"], work_name: \"PEê´€\"\n- â›” ê¸ˆì§€: \"PE\", \"PV\" ê°™ì€ 2ê¸€ì ì˜ë¬¸ ì•½ì–´ë¥¼ ë‹¨ë…ìœ¼ë¡œ keywordsì— ë„£ì§€ ë§ˆì„¸ìš”! ë°˜ë“œì‹œ í•œê¸€ê³¼ ê²°í•©í•œ ë³µí•©ì–´ë¡œ (PEê´€, PEë“œëŸ¼, PVCê´€)\n\n## ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš©\n- ì´ì „ ëŒ€í™”ì—ì„œ í™•ì •ëœ ê³µì¢…ëª…ì„ í›„ì† ì§ˆë¬¸ì— ë³µì›\n  ì˜ˆ: ì´ì „ \"ê°•ê´€ìš©ì ‘ 200mm SCH 40\" â†’ í˜„ì¬ \"SCH 80ì€?\" â†’ work_name: \"ê°•ê´€ìš©ì ‘\", spec: \"SCH 80\"`;\n\n// â”€â”€â”€ ê·œì¹™ ê¸°ë°˜ ì˜ë„ ë¶„ì„ (DeepSeek í´ë°±) â”€â”€â”€\n// Why: API í‚¤ ë¯¸ì„¤ì • ë˜ëŠ” API ì¥ì•  ì‹œì—ë„ ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë³´ì¥\n\n// í•œê¸€ ì™¸ë˜ì–´ â†’ ì˜ë¬¸ ì›ì–´ ë²ˆì—­ ë”•ì…”ë„ˆë¦¬\n// Why: DeepSeekì´ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì •ì„ì´ì§€ë§Œ, API ì¥ì•  ì‹œì—ë„\n//      \"í¬ëŸ¬ì…”\" â†’ \"Crusher\", \"í”Œëœì§€\" â†’ \"Flange\" ë³€í™˜ ë³´ì¥\nexport const KO_EN_DICT: Record<string, string[]> = {\n    \"í¬ëŸ¬ì…”\": [\"Crusher\"], \"í¬ë¼ì…”\": [\"Crusher\"],\n    \"í”Œëœì§€\": [\"Flange\"], \"í”Œë Œì§€\": [\"Flange\"],\n    \"ê·¸ë¼ì¸ë”©\": [\"Grinding\"], \"ê·¸ë¼ì¸ë”\": [\"Grinding\"],\n    \"ì—ì´ì¹˜ë¹”\": [\"H-Beam\"], \"íˆí„°\": [\"Heater\"],\n    \"í”¼ë¸Œì´ì”¨\": [\"PVC\"], \"ìŠ¤í† ë¦¬ì§€\": [\"STORAGE\"],\n    \"íƒ±í¬\": [\"Tank\", \"STORAGE TANK\"],\n    \"í‹°ê·¸\": [\"TIG\", \"TIGìš©ì ‘\"], \"ë¯¸ê·¸\": [\"MIG\"],\n    \"ì§€ì—”ì—ìŠ¤ì—ìŠ¤\": [\"GNSS\"], \"ì¸ë²„í„°\": [\"Inverter\"],\n    \"ì»¨ë² ì´ì–´\": [\"Conveyor\"], \"í˜¸í¼\": [\"Hopper\"],\n    \"ì½¤í”„ë ˆì„œ\": [\"Compressor\"], \"ì»´í”„ë ˆì…”\": [\"Compressor\"],\n    \"íŒí”„\": [\"Pump\"], \"ë°¸ë¸Œ\": [\"Valve\"],\n    \"ë³´ì¼ëŸ¬\": [\"Boiler\"], \"ë•íŠ¸\": [\"Duct\"],\n    \"ì—ì´ì¹˜ë””í”¼ì´\": [\"HDPE\", \"PE\"], \"í”¼ì´\": [\"PE\"],\n    \"íŠ¸ëœìŠ¤\": [\"Transformer\"], \"ì¼€ì´ë¸”\": [\"Cable\"],\n    \"ë¸Œë ˆì´ì»¤\": [\"Breaker\"], \"ë¶ˆë„ì €\": [\"Bulldozer\"],\n    \"ë¡œë”\": [\"Loader\"], \"ë¤í”„\": [\"Dump\"],\n    \"ë¡¤ëŸ¬\": [\"Roller\"], \"í¬ë ˆì¸\": [\"Crane\"],\n    \"ë°±í˜¸ìš°\": [\"Backhoe\"], \"ê·¸ë˜ë”\": [\"Grader\"],\n    \"ìŠ¤í¬ë ˆì´í¼\": [\"Scraper\"], \"í˜ì´ë²„\": [\"Paver\"],\n    \"í”¼ë‹ˆì…”\": [\"Finisher\"], \"ìŠ¤í”„ë ˆë”\": [\"Spreader\"],\n    \"ë°”ì´ë¸Œë ˆì´í„°\": [\"Vibrator\"], \"í•´ë¨¸\": [\"Hammer\"],\n    \"ì•µì»¤\": [\"Anchor\"], \"ì™€ì´ì–´\": [\"Wire\"],\n    \"ë°°ëŸ´\": [\"Barrel\"], \"ì‹¤ë§\": [\"Sealing\"],\n    \"ì½”í‚¹\": [\"Caulking\"], \"í”„ë¼ì´ë¨¸\": [\"Primer\"],\n};\n\nexport function ruleBasedIntent(question: string): IntentAnalysis {\n    // ì¸ì‚¬ ê°ì§€\n    if (/^(ì•ˆë…•|ë°˜ê°€|ë„ì›€|ë­˜\\s*í• |í• \\s*ìˆ˜|help)/i.test(question)) {\n        return { intent: \"greeting\", work_name: null, spec: null, keywords: [], ambiguity_reason: null };\n    }\n\n    // ë¶ˆìš©ì–´ ì œê±° í›„ í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ\n    const stopWords = new Set([\"í’ˆì…ˆ\", \"ì¸ë ¥\", \"ì¸ê³µ\", \"ìˆ˜ëŸ‰\", \"ë‹¨ìœ„\", \"ì¥ë¹„\", \"ìì¬\", \"ì•Œë ¤ì¤˜\", \"ì–¼ë§ˆ\", \"ê´€ë ¨\", \"ì œì‘\", \"ì„¤ì¹˜\", \"ì‹œê³µ\", \"ê³µì‚¬\"]);\n    const koreanWords = question.match(/[ê°€-í£]{2,}/g) || [];\n    const workKeywords = koreanWords.filter(w => !stopWords.has(w));\n\n    // â­ í•œê¸€ ì™¸ë˜ì–´ â†’ ì˜ë¬¸ ë²ˆì—­ (í´ë°± ë³´ì¥)\n    const translatedKeywords: string[] = [];\n    for (const kw of workKeywords) {\n        if (KO_EN_DICT[kw]) {\n            translatedKeywords.push(...KO_EN_DICT[kw]);\n        }\n    }\n    const allKeywords = [...workKeywords, ...translatedKeywords];\n\n    // ì˜ë¬¸ í‚¤ì›Œë“œë„ ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ (Crusher, Flange ë“±)\n    const englishWords = question.match(/[A-Za-z][-A-Za-z]{1,}/g) || [];\n    const engStopWords = new Set([\"SCH\", \"mm\", \"ton\", \"help\"]);\n    const engKeywords = englishWords.filter(w => !engStopWords.has(w) && w.length >= 2);\n    allKeywords.push(...engKeywords);\n\n    // â­ ì˜ë¬¸ ì•½ì–´ í™•ì¥ (HDPEâ†’PEê´€, PVCâ†’PVCê´€ ë“± í•œê¸€ ë³µí•©ì–´ë¡œ)\n    const ENG_EXPAND: Record<string, string[]> = {\n        \"HDPE\": [\"PEê´€\", \"PEë“œëŸ¼\", \"HDPEê´€\", \"í´ë¦¬ì—í‹¸ë Œ\"],\n        \"PVC\": [\"PVCê´€\"],\n    };\n    for (const ek of engKeywords) {\n        const upper = ek.toUpperCase();\n        if (ENG_EXPAND[upper]) allKeywords.push(...ENG_EXPAND[upper]);\n    }\n\n    // ê·œê²© ì¶”ì¶œ (2t, 200mm, SCH 40, D110 ë“±)\n    let spec: string | null = null;\n    const specMatch = question.match(/(\\d+)\\s*(t|ton|mm|A|ãœ)/i);\n    if (specMatch) spec = `${specMatch[1]}${specMatch[2]}`;\n    const schMatch = question.match(/SCH\\s*(\\d+)/i);\n    if (schMatch) spec = (spec ? spec + \" \" : \"\") + `SCH ${schMatch[1]}`;\n\n    // ê³µì¢…ëª… = ì²« ë²ˆì§¸ ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œ (ì˜ë¬¸ ë²ˆì—­ ìš°ì„ )\n    const work_name = translatedKeywords.length > 0\n        ? translatedKeywords[0]  // ì˜ë¬¸ ì›ì–´ ìš°ì„  (DB ì—”í‹°í‹°ëª…ê³¼ ë§¤ì¹­)\n        : (workKeywords.length > 0 ? workKeywords[0] : null);\n\n    // ìˆ˜ëŸ‰ ê°ì§€ (10ê°œì†Œ, 2t, 50m ë“±)\n    const qtyMatch = question.match(/(\\d+)\\s*(ê°œì†Œ|ê°œ|m|ã¡|ã¥|t|ton|ë³¸)/i);\n    if (qtyMatch && work_name) {\n        return {\n            intent: \"search\",\n            work_name,\n            spec,\n            keywords: allKeywords,\n            ambiguity_reason: null,\n        };\n    }\n\n    console.log(`[ruleBasedIntent] work_name=${work_name}, spec=${spec}, keywords=${allKeywords.join(\",\")}, translated=${translatedKeywords.join(\",\")}`);\n    return {\n        intent: work_name ? \"search\" : \"greeting\",\n        work_name,\n        spec,\n        keywords: allKeywords,\n        ambiguity_reason: null,\n    };\n}\n\nexport async function analyzeIntent(\n    question: string,\n    history: ChatMessage[],\n    sessionContext?: SessionContext\n): Promise<IntentAnalysis> {\n    // DeepSeek API í‚¤ê°€ ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ í´ë°±\n    if (!DEEPSEEK_API_KEY) {\n        console.warn(\"[analyzeIntent] DEEPSEEK_API_KEY ë¯¸ì„¤ì • â†’ ê·œì¹™ ê¸°ë°˜ í´ë°±\");\n        return ruleBasedIntent(question);\n    }\n\n    try {\n        // ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë¶€ì°©\n        let systemContent = INTENT_SYSTEM_PROMPT;\n        if (sessionContext?.last_entity_id) {\n            systemContent += `\\n\\n## í˜„ì¬ ì„¸ì…˜ ìƒíƒœ\\n` +\n                `last_entity_id: ${sessionContext.last_entity_id}\\n` +\n                `last_work_name: ${sessionContext.last_work_name || 'ì—†ìŒ'}\\n` +\n                `last_spec: ${sessionContext.last_spec || 'ì—†ìŒ'}\\n` +\n                `last_quantity: ${sessionContext.last_quantity || 'ì—†ìŒ'}\\n` +\n                `last_section_id: ${sessionContext.last_section_id || 'ì—†ìŒ'}`;\n        }\n\n        const response = await fetch(DEEPSEEK_URL, {\n            method: \"POST\",\n            headers: {\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": `Bearer ${DEEPSEEK_API_KEY}`,\n            },\n            body: JSON.stringify({\n                model: \"deepseek-chat\",\n                messages: [\n                    { role: \"system\", content: systemContent },\n                    // ìµœê·¼ 3í„´ë§Œ ì „ë‹¬ (í† í° ì ˆì•½)\n                    ...history.slice(-3).map(h => ({\n                        role: h.role === \"user\" ? \"user\" as const : \"assistant\" as const,\n                        content: h.content,\n                    })),\n                    { role: \"user\" as const, content: question },\n                ],\n                response_format: { type: \"json_object\" },\n                temperature: 0.1,\n                max_tokens: 300,\n            }),\n        });\n\n        if (!response.ok) {\n            console.error(`[analyzeIntent] DeepSeek API failed: ${response.status} â†’ ê·œì¹™ ê¸°ë°˜ í´ë°±`);\n            return ruleBasedIntent(question);\n        }\n\n        const data = await response.json();\n        const content = data.choices?.[0]?.message?.content ?? \"{}\";\n        const parsed = JSON.parse(content) as IntentAnalysis;\n\n        // ì•ˆì „ì„± ë³´ì¥: intentê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ í´ë°±\n        const validIntents = [\"search\", \"clarify_needed\", \"followup\", \"greeting\", \"quantity_input\", \"cost_calculate\", \"modify_request\", \"report_request\"];\n        if (!validIntents.includes(parsed.intent)) {\n            parsed.intent = parsed.ambiguity_reason ? \"clarify_needed\" : \"search\";\n        }\n        if (parsed.intent === \"search\" && parsed.ambiguity_reason) {\n            parsed.intent = \"clarify_needed\";\n        }\n        parsed.keywords = parsed.keywords || [];\n\n        console.log(`[analyzeIntent] intent=${parsed.intent}, work_name=${parsed.work_name}, spec=${parsed.spec}, keywords=${parsed.keywords.join(\",\")}${parsed.modify_type ? `, modify_type=${parsed.modify_type}` : ''}${parsed.quantity != null ? `, quantity=${parsed.quantity}` : ''}`);\n        return parsed;\n    } catch (err) {\n        console.error(\"[analyzeIntent] error:\", err, \"â†’ ê·œì¹™ ê¸°ë°˜ í´ë°±\");\n        return ruleBasedIntent(question);\n    }\n}\n\n// â”€â”€â”€ E-2. ê·¸ë˜í”„ ê¸°ë°˜ ëª…í™•í™” (graphClarify) â”€â”€â”€\n// Why: ëª¨í˜¸í•œ ì§ˆë¬¸ì— ëŒ€í•´ ê·¸ë˜í”„ì˜ Sectionâ†’WorkType ê³„ì¸µì„ íƒìƒ‰í•˜ì—¬\n//      ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í›„ë³´ë§Œ ì œì‹œ.\n// Phase 3: 2ë‹¨ê³„ drill-down\n//   sectionId ì—†ìŒ â†’ Step 1: ì„¹ì…˜(ë¶„ì•¼) ì„ íƒ\n//   sectionId ìˆìŒ â†’ Step 2: í•´ë‹¹ ì„¹ì…˜ ë‚´ í•˜ëª© ì„ íƒ\n// ClarifyResult is imported from types.ts\n\n// â•â•â• graphClarify: resolve.tsì˜ resolveSection + presentClarifyë¥¼ í˜¸ì¶œí•˜ëŠ” thin wrapper â•â•â•\n// Why: ê¸°ì¡´ graphClarifyì˜ 656ì¤„ ëª¨ë†€ë¦¬ì‹ ë¡œì§ì„ resolve.tsë¡œ ë¶„ë¦¬.\n//      ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ caller(index.ts, handleChat)ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ëŠ” ì—­í• .\nimport { resolveSection, presentClarify } from \"./resolve.ts\";\nimport type { ResolveContext } from \"./resolve.ts\";\n\nexport async function graphClarify(analysis: IntentAnalysis, sectionId?: string): Promise<ClarifyResult> {\n    const { work_name, keywords } = analysis;\n    const searchTerms = work_name ? [work_name, ...keywords] : keywords;\n\n    // searchTerms ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë‚´ ë°˜í™˜\n    if (searchTerms.length === 0 && !sectionId) {\n        return {\n            message: \"ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í’ˆì…ˆ í•­ëª©ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.\\nì˜ˆ: \\\"ê°•ê´€ìš©ì ‘ 200mm SCH 40\\\", \\\"ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤\\\", \\\"ê±°í‘¸ì§‘ ì„¤ì¹˜\\\"\",\n            options: [\n                { label: \"ê°•ê´€ìš©ì ‘\", query: \"ê°•ê´€ìš©ì ‘ í’ˆì…ˆ\" },\n                { label: \"ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤\", query: \"ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ í’ˆì…ˆ\" },\n                { label: \"ê±°í‘¸ì§‘ ì„¤ì¹˜\", query: \"ê±°í‘¸ì§‘ ì„¤ì¹˜ í’ˆì…ˆ\" },\n            ],\n        };\n    }\n\n    // sub_section ìƒíƒœ íŒŒì‹±: sectionIdì— \":sub=\" ì¸ì½”ë”©ì´ ìˆìœ¼ë©´ ë¶„ë¦¬\n    let actualSectionId = sectionId;\n    let subSectionName: string | undefined;\n    if (sectionId && sectionId.includes(':sub=')) {\n        const parts = sectionId.split(':sub=');\n        actualSectionId = parts[0];\n        subSectionName = decodeURIComponent(parts[1]);\n    }\n\n    const ctx: ResolveContext = {\n        analysis,\n        sectionId: actualSectionId,\n        subSectionName,\n    };\n\n    const resolved = await resolveSection(ctx);\n    return presentClarify(resolved, searchTerms, work_name);\n}\n\n// â”â”â” [E-3] ê·œê²© ì •ê·œí™” â”â”â”\n// Why: ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ê·œê²© í‘œê¸°ê°€ ë‹¤ì–‘í•¨ (ì¸ì¹˜, íŒŒì´, SCH ë¶™ì—¬ì“°ê¸° ë“±)\n//      DBì˜ í‘œì¤€ í‘œê¸°(mm, SCH ë„ì–´ì“°ê¸°)ë¡œ í†µì¼í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ\nexport function normalizeSpec(spec: string | null): string | null {\n    if (!spec) return spec;\n    let s = spec;\n\n    // ì¸ì¹˜ â†’ mm ë³€í™˜ (1ì¸ì¹˜ = 25.4mm, ë°˜ì˜¬ë¦¼)\n    const inchMap: Record<string, string> = {\n        '1/2': '15', '3/4': '20', '1': '25', '1-1/4': '32', '1-1/2': '40',\n        '2': '50', '2-1/2': '65', '3': '80', '4': '100', '5': '125',\n        '6': '150', '8': '200', '10': '250', '12': '300', '14': '350',\n        '16': '400', '18': '450', '20': '500', '24': '600',\n    };\n\n    // \"8ì¸ì¹˜\" â†’ \"200mm\"\n    const inchMatch = s.match(/^(\\d+(?:-\\d+\\/\\d+|\\d*\\/\\d+)?)\\s*(?:ì¸ì¹˜|inch|\"|â€³)/i);\n    if (inchMatch) {\n        const mmVal = inchMap[inchMatch[1]];\n        if (mmVal) {\n            s = s.replace(inchMatch[0], `${mmVal}mm`);\n        }\n    }\n\n    // \"íŒŒì´200\" â†’ \"200mm\" (íŒŒì´ = ì§ê²½ í‘œê¸°)\n    s = s.replace(/íŒŒì´\\s*(\\d+)/g, '$1mm');\n    // \"Î¦200\" or \"Ã¸200\" â†’ \"200mm\"\n    s = s.replace(/[Î¦Ï†Ã¸]\\s*(\\d+)/g, '$1mm');\n\n    // \"SCH40\" â†’ \"SCH 40\" (ë„ì–´ì“°ê¸° ì •ê·œí™”)\n    s = s.replace(/SCH\\s*(\\d+)/gi, 'SCH $1');\n\n    // \"200A\" â†’ \"200mm\" (A = mm in KS í‘œê¸°)\n    s = s.replace(/(\\d+)\\s*A\\b/g, '$1mm');\n\n    return s;\n}"}, {"name": "llm.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// llm.ts â€” LLM ë‹µë³€ ìƒì„± (DeepSeek ìš°ì„ , Gemini í´ë°±)\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nimport { GEMINI_API_KEY, DEEPSEEK_API_KEY, DEEPSEEK_URL } from \"./config.ts\";\nimport type { ChatMessage, LLMResult, AnswerOptions } from \"./types.ts\";\n\nexport const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ê±´ì„¤ ê³µì‚¬ í’ˆì…ˆ(æ¨™æº–å“ì…ˆ) ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n\n[ì—­í• ]\n- ì‚¬ìš©ìì˜ ê±´ì„¤ ê³µì‚¬ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ í’ˆì…ˆ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.\n- ë‹µë³€ ì‹œ ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ë©°, ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n[í’ˆì…ˆ ë„ë©”ì¸ ì§€ì‹]\n1. **í’ˆì…ˆì„œ êµ¬ì¡°**: ë¶€ë¬¸ > ì¥ > ì ˆ > í‘œë²ˆí˜¸ í˜•íƒœ. í‘œë²ˆí˜¸(ì˜ˆ: 13-2-3)ëŠ” í’ˆì…ˆì„œ ë‚´ ê³ ìœ  ì‹ë³„ìì…ë‹ˆë‹¤.\n2. **í‘œ êµ¬ì¡°**: ê° í‘œëŠ” ê³µì¢…ëª… + ê·œê²©ë³„ ì†Œí…Œì´ë¸”ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n   - ê·œê²© ì˜ˆ: \"ê°•ê´€ìš©ì ‘(200, SCH 40)\" = í˜¸ì¹­ê²½ 200mm, ìŠ¤ì¼€ì¤„ 40\n   - ê° ê·œê²© ì•„ë˜ì— ì§ì¢…/ìˆ˜ëŸ‰/ë‹¨ìœ„ í…Œì´ë¸”ì´ ë‚˜ì˜µë‹ˆë‹¤.\n3. **ì½”ë“œ ì²´ê³„**: \"7205-0540\" ê°™ì€ ìˆ«ìëŠ” ê±´ì„¤ê¸°ê³„ ë¶„ë¥˜ ì½”ë“œì…ë‹ˆë‹¤.\n   - ì• 4ìë¦¬: ëŒ€ë¶„ë¥˜, ë’¤ 4ìë¦¬: ì„¸ë¶€ ë¶„ë¥˜\n   - ì´ ì½”ë“œë¡œë¶€í„° ì¥ë¹„ëª…ì„ ìœ ì¶”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n4. **ê³„ìˆ˜/ë³´ì •ê°’**: \"ê³„ìˆ˜ A~E\" ë“±ì€ ì¡°ê±´ë³„ ë³´ì • ê³„ìˆ˜ì…ë‹ˆë‹¤.\n   ì›ë³¸ í…Œì´ë¸”ì—ì„œ ì¡°ê±´ì— ë§ëŠ” í–‰ì„ ì°¾ì•„ í•´ë‹¹ ê³„ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n5. **ë‹¨ìœ„ ì²´ê³„**:\n   - \"ì¸\" = 1ì¸ 1ì¼ ë…¸ë™ëŸ‰ (8ì‹œê°„ ê¸°ì¤€). 0.122ì¸ = ì•½ 58ë¶„(0.122 Ã— 8ì‹œê°„ Ã— 60ë¶„)ì˜ ë…¸ë™\n   - \"ëŒ€\" = ì¥ë¹„ 1ëŒ€ 1ì¼(8ì‹œê°„) ê°€ë™\n   - \"ã¡\", \"ã¥\", \"m\", \"ê°œì†Œ\", \"ë³¸\" ë“±ì€ ì‹œê³µ ë‹¨ìœ„\n6. **ì†ì„±(properties)**: ì»¨í…ìŠ¤íŠ¸ì˜ \"ì†ì„±\" í•„ë“œì— ê·œê²©, ìˆ˜ëŸ‰, ë‹¨ìœ„ ë“± ì„¸ë¶€ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤.\n   ì´ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ë‹µë³€í•˜ì„¸ìš”.\n\n[ë‹µë³€ ê·œì¹™]\n1. **í‘œë²ˆí˜¸ í•„ìˆ˜ í‘œê¸°**: ë‹µë³€ ì‹œ í•´ë‹¹ í’ˆì…ˆì˜ í‘œë²ˆí˜¸(ì˜ˆ: [í‘œ 13-5-1])ë¥¼ ë°˜ë“œì‹œ í‘œê¸°í•©ë‹ˆë‹¤. í‘œë²ˆí˜¸ëŠ” ì»¨í…ìŠ¤íŠ¸ì˜ \"í‘œë²ˆí˜¸\" í•„ë“œì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n2. **ì¶œì²˜ ëª…ì‹œ**: ë‹µë³€ì— ì‚¬ìš©í•œ í’ˆì…ˆ í•­ëª©ì˜ ì¶œì²˜(ë¶€ë¬¸ > ì¥ > ì ˆ > í‘œë²ˆí˜¸)ë¥¼ ë°˜ë“œì‹œ í‘œê¸°í•©ë‹ˆë‹¤.\n3. **í‘œ í˜•ì‹ â€” ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡° ìœ ì§€**: ì»¨í…ìŠ¤íŠ¸ì— ì œê³µëœ í…Œì´ë¸” êµ¬ì¡°ë¥¼ **ìˆëŠ” ê·¸ëŒ€ë¡œ** ìœ ì§€í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.\n   - **ë§¤íŠ¸ë¦­ìŠ¤(êµì°¨í‘œ)**: í–‰=ì§ì¢…/ì¥ë¹„/ìì¬, ì—´=ê·œê²©Â·ì¡°ê±´ì¼ ë•Œ êµì°¨ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. ì ˆëŒ€ 4ì—´ í”Œë« í…Œì´ë¸”ë¡œ ë¶„í•´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n   - **ì‹¬í”Œ í…Œì´ë¸”**: ê¸°ì¤€ì´ 1ê°œì¸ ë‹¨ìˆœ ë°ì´í„°ëŠ” ê¸°ì¡´ \\`| ì§ì¢… | ìˆ˜ëŸ‰ | ë‹¨ìœ„ | ê¸°ì¤€ |\\` êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n   - ë‹¨ìœ„ëŠ” ë°˜ë“œì‹œ ë°ì´í„°ì— í‘œê¸°ëœ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì„ì˜ ë³€ê²½ ê¸ˆì§€.\n4. **ìˆ˜ëŸ‰ ì •í™•ì„±**: ì¸ë ¥, ì¥ë¹„, ìì¬ì˜ ìˆ˜ëŸ‰ê³¼ ë‹¨ìœ„ë¥¼ ì •í™•í•˜ê²Œ í‘œê¸°í•©ë‹ˆë‹¤.\n   ì˜ˆ: \"ë³´í†µì¸ë¶€ 0.122ì¸\", \"ì½˜í¬ë¦¬íŠ¸ê³µ 0.045ì¸\"\n5. **ë¹„ìš© ë‹µë³€ ì‹œ**: ì¼ìœ„ëŒ€ê°€ ì •ë³´ê°€ ì œê³µë˜ë©´, ë…¸ë¬´ë¹„/ì¬ë£Œë¹„/ê²½ë¹„/í•©ê³„ë¥¼ í‘œ í˜•íƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\n6. **ì£¼ì˜ì‚¬í•­ í¬í•¨**: í• ì¦, ì ìš© ì¡°ê±´, ì œí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì–¸ê¸‰í•©ë‹ˆë‹¤.\n7. **ê°™ì€ ì ˆ(í‘œ) ë‚´ ë°ì´í„° í™œìš©**: ì§ˆë¬¸í•œ ì‘ì—…ì˜ ìì²´ ì¸ë ¥/ì¥ë¹„ ë°ì´í„°ê°€ ì§ì ‘ ì—†ë”ë¼ë„,\n   ì»¨í…ìŠ¤íŠ¸ì— ê°™ì€ ì ˆ(section)ì˜ í˜•ì œ ì‘ì—… ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´\n   ë°˜ë“œì‹œ í•´ë‹¹ ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. ê°™ì€ ì ˆ ë‚´ì˜ ë°ì´í„°ëŠ” ë™ì¼ í’ˆì…ˆí‘œì˜ ì¼ë¶€ì´ë¯€ë¡œ ê´€ë ¨ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n   \"ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³ ë§Œ ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n8. **ì •ë³´ ë¶€ì¡± ì‹œ**: ì»¨í…ìŠ¤íŠ¸ì— ê´€ë ¨ ë°ì´í„°ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš°ì—ë§Œ \"ì œê³µëœ í’ˆì…ˆ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µí•©ë‹ˆë‹¤.\n   ë‹¨, ê°™ì€ ì ˆì˜ í˜•ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ë¨¼ì € ì¶œë ¥í•œ í›„ \"ì§ˆë¬¸í•˜ì‹  íŠ¹ì • í•­ëª©ì˜ ë³„ë„ ë°ì´í„°ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\"ë¼ê³  ë³´ì¶©í•©ë‹ˆë‹¤.\n9. **ë§ˆí¬ë‹¤ìš´ í˜•ì‹**: ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n\n[ì¶œë ¥ í¬ë§· ì˜ˆì‹œ â€” ë§¤íŠ¸ë¦­ìŠ¤(êµì°¨í‘œ)]\n\nğŸ“‹ **[í‘œ 13-2-3] ê°•ê´€ìš©ì ‘ â€” ì „ê¸°ì•„í¬ìš©ì ‘** (ê°œì†Œë‹¹)\nğŸ“ ì¶œì²˜: ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸ > ì œ13ì¥ í”ŒëœíŠ¸ì„¤ë¹„ê³µì‚¬ > ê°•ê´€ìš©ì ‘\n\n| ì§ì¢… | 200, SCH 20 | 200, SCH 30 | 200, SCH 40 | 200, SCH 60 | 200, SCH 80 |\n| --- | ---: | ---: | ---: | ---: | ---: |\n| ìš©ì ‘ê³µ | 0.287 | 0.287 | â€” | â€” | â€” |\n| í”ŒëœíŠ¸ìš©ì ‘ê³µ | â€” | â€” | 0.287 | 0.325 | 0.362 |\n| íŠ¹ë³„ì¸ë¶€ | 0.086 | 0.086 | 0.086 | 0.098 | 0.109 |\n\nâ€» ë§¤íŠ¸ë¦­ìŠ¤ í…Œì´ë¸”ì€ í–‰ì— ì§ì¢…/ì¥ë¹„, ì—´ì— ê·œê²©Â·ì¡°ê±´ì„ ë°°ì¹˜í•˜ì—¬ í•œëˆˆì— ë¹„êµí•  ìˆ˜ ìˆê²Œ êµ¬ì„±í•©ë‹ˆë‹¤.\nâ€» ë‹¨ìœ„(ê°œì†Œë‹¹/më‹¹/tonë‹¹ ë“±)ëŠ” ë°ì´í„°ì— í¬í•¨ëœ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.\n\n[ê¸ˆì§€ ì‚¬í•­]\n- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ìˆ˜ì¹˜ë‚˜ ê¸°ì¤€ì„ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n- \"ì¼ë°˜ì ìœ¼ë¡œ\", \"ë³´í†µ\", \"ëŒ€ëµ\" ë“± ëª¨í˜¸í•œ í‘œí˜„ ëŒ€ì‹  ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n- ê±´ì„¤ ê´€ë ¨ì´ ì•„ë‹Œ ì§ˆë¬¸ì—ëŠ” \"ê±´ì„¤ í’ˆì…ˆ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\"ë¼ê³  ì‘ë‹µí•©ë‹ˆë‹¤.\n- ë‹¨ìœ„ë¥¼ ì„ì˜ë¡œ ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤. ì£¼ì–´ì§€ëŠ” ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.\n- ë§¤íŠ¸ë¦­ìŠ¤ êµì°¨í‘œë¥¼ 4ì—´ í”Œë« í…Œì´ë¸”(ì§ì¢…/ìˆ˜ëŸ‰/ë‹¨ìœ„/ê¸°ì¤€)ë¡œ ë¶„í•´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.`;\n\n// Why: ì„ë² ë”©ì€ DB ë²¡í„° í˜¸í™˜ì„± ë•Œë¬¸ì— Gemini ìœ ì§€ (13,387ê°œ ì—”í‹°í‹° ì¬ì„ë² ë”© ë¶ˆê°€)\n//       ë‹µë³€ ìƒì„±ë§Œ DeepSeek v3.2ë¡œ ì „í™˜\n\nexport async function generateAnswer(\n    question: string,\n    context: string,\n    history: ChatMessage[],\n    options?: AnswerOptions\n): Promise<LLMResult> {\n    // â”€â”€â”€ intentë³„ í”„ë¡¬í”„íŠ¸ ë™ì  ë¶€ì°© â”€â”€â”€\n    let systemContent = SYSTEM_PROMPT;\n\n    if (options?.intent === \"cost_calculate\") {\n        systemContent += `\\n\\n[íŠ¹ë³„ ì§€ì¹¨: ë…¸ë¬´ë¹„ ì‚°ì¶œ]\nì‚¬ìš©ìê°€ ë…¸ë¬´ë¹„ / ì¸ê±´ë¹„ ê³„ì‚°ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.\n1. í’ˆì…ˆ ì¸ë ¥ ë°ì´í„°(ì§ì¢…, ìˆ˜ëŸ‰, ë‹¨ìœ„)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¸ë¬´ë¹„ë¥¼ ì‚°ì¶œí•˜ì„¸ìš”.\n2. ìˆ˜ëŸ‰ì´ ${options.quantity || 'ë¯¸ì§€ì •'}${options.quantity ? ` (${options.quantity})` : ''}ìœ¼ë¡œ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.\n3. ë…¸ë¬´ë¹„ ì‚°ì¶œ í˜•ì‹(ë°˜ë“œì‹œ ì´ í…Œì´ë¸” í˜•íƒœë¡œ):\n   | ì§ì¢… | íˆ¬ì…ì¸ì›(ì¸ / ê°œì†Œ) | ìˆ˜ëŸ‰ | ì´ íˆ¬ì…(M / D) | ë…¸ì„ë‹¨ê°€(ì› / ì¼) | ì†Œê³„(ì›) |\n    4. ì»¨í…ìŠ¤íŠ¸ì—[2026ë…„ ë…¸ì„ë‹¨ê°€] ì„¹ì„ ì´ ìˆìœ¼ë©´ í•´ë‹¹ ë‹¨ê°€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n5. í•©ê³„ í–‰ì„ ì¶”ê°€í•˜ê³ , ì´ ë…¸ë¬´ë¹„ë¥¼ êµµì€ ê¸€ì”¨ë¡œ í‘œê¸°í•˜ì„¸ìš”.\n6. ìˆ˜ëŸ‰ì´ ë¯¸ì§€ì •ì´ë©´ \"1ê°œì†Œë‹¹\" ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œí•˜ì„¸ìš”.`;\n    }\n\n    if (options?.intent === \"report_request\") {\n        systemContent += `\\n\\n[íŠ¹ë³„ ì§€ì¹¨: ì‚°ì¶œì„œ í˜•íƒœ ì¶œë ¥]\nì‚¬ìš©ìê°€ ì‚°ì¶œì„œ / ë‚´ì—­ì„œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.\n1. ì •í˜•í™”ëœ ì‚°ì¶œ ë‚´ì—­ì„œ í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n2. í¬í•¨ í•­ëª©: í’ˆì…ˆ ì¶œì²˜(í‘œë²ˆí˜¸, ì ˆ), ê·œê²©, ì¸ë ¥ íˆ¬ì… í…Œì´ë¸”, ë…¸ë¬´ë¹„ ì‚°ì¶œ í…Œì´ë¸”, í•©ê³„\n3. ìˆ˜ëŸ‰ì´ ${options.quantity || 'ë¯¸ì§€ì •'}ìœ¼ë¡œ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.\n4. í‘œë²ˆí˜¸, ì¶œì²˜ ì •ë³´ë¥¼ ìƒë‹¨ì— ëª…ì‹œí•˜ì„¸ìš”.\n5. ìµœì¢… í•©ê³„ ê¸ˆì•¡ì„ ê°•ì¡° í‘œì‹œí•˜ì„¸ìš”.`;\n    }\n\n    if (options?.quantity && options.intent !== \"cost_calculate\" && options.intent !== \"report_request\") {\n        systemContent += `\\n\\n[ìˆ˜ëŸ‰ ì •ë³´]\nì‚¬ìš©ìê°€ ìˆ˜ëŸ‰ ${options.quantity}ì„ ì§€ì •í–ˆìŠµë‹ˆë‹¤.\ní’ˆì…ˆ ì¸ë ¥ / ì¥ë¹„ ìˆ˜ëŸ‰ì— ì´ ê°’ì„ ê³±í•˜ì—¬ ì´ íˆ¬ì…ëŸ‰ì„ ê³„ì‚°í•´ ì£¼ì„¸ìš”.`;\n    }\n\n    // â”€â”€â”€ DeepSeek ìš°ì„  ì‹œë„ â”€â”€â”€\n    if (DEEPSEEK_API_KEY) {\n        try {\n            const messages = [\n                { role: \"system\" as const, content: systemContent },\n                ...history.slice(-5).map((msg) => ({\n                    role: msg.role === \"user\" ? \"user\" as const : \"assistant\" as const,\n                    content: msg.content,\n                })),\n                {\n                    role: \"user\" as const,\n                    content: `[ì§ˆë¬¸]\\n${question} \\n\\n[ì°¸ê³  ë°ì´í„°]\\n${context} `,\n                },\n            ];\n\n            const response = await fetch(DEEPSEEK_URL, {\n                method: \"POST\",\n                headers: {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": `Bearer ${DEEPSEEK_API_KEY} `,\n                },\n                body: JSON.stringify({\n                    model: \"deepseek-chat\",\n                    messages,\n                    temperature: 0.3,\n                    max_tokens: 4096,\n                }),\n            });\n\n            if (response.ok) {\n                const data = await response.json();\n                const answer = data.choices?.[0]?.message?.content ?? \"ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\";\n                const usage = data.usage || {};\n                return {\n                    answer,\n                    inputTokens: usage.prompt_tokens || 0,\n                    outputTokens: usage.completion_tokens || 0,\n                };\n            }\n            console.error(`[generateAnswer] DeepSeek failed: ${response.status}, falling back to Gemini`);\n        } catch (err) {\n            console.error(\"[generateAnswer] DeepSeek error:\", err, \"falling back to Gemini\");\n        }\n    }\n\n    // â”€â”€â”€ Gemini í´ë°± â”€â”€â”€\n    const GEMINI_LLM_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\";\n    const contents = [\n        ...history.slice(-5).map((msg) => ({\n            role: msg.role === \"user\" ? \"user\" : \"model\",\n            parts: [{ text: msg.content }],\n        })),\n        {\n            role: \"user\",\n            parts: [{ text: `[ì§ˆë¬¸]\\n${question} \\n\\n[ì°¸ê³  ë°ì´í„°]\\n${context} ` }],\n        },\n    ];\n\n    const response = await fetch(`${GEMINI_LLM_URL}?key = ${GEMINI_API_KEY} `, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({\n            system_instruction: { parts: [{ text: systemContent }] },\n            contents,\n            generationConfig: { temperature: 0.3, maxOutputTokens: 4096 },\n        }),\n    });\n\n    if (!response.ok) {\n        throw new Error(`LLM API failed: ${response.status} `);\n    }\n\n    const data = await response.json();\n    const answer = data.candidates?.[0]?.content?.parts?.[0]?.text ?? \"ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\";\n    const usage = data.usageMetadata || {};\n    return {\n        answer,\n        inputTokens: usage.promptTokenCount || 0,\n        outputTokens: usage.candidatesTokenCount || 0,\n    };\n}\n"}, {"name": "resolve.ts", "content": "// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n// resolve.ts â€” ê³„ì¸µ íƒìƒ‰ + ëª…í™•í™” í”„ë ˆì  í…Œì´ì…˜\n// Why: graphClarifyì˜ 656ì¤„ ëª¨ë†€ë¦¬ì‹ í•¨ìˆ˜ë¥¼ ì±…ì„ ë¶„ë¦¬\n//   resolveSection : DB íƒìƒ‰ â†’ ResolveResult ë°˜í™˜\n//   presentClarify : ResolveResult â†’ ClarifyResult UI ë³€í™˜\n// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nimport { supabase } from \"./config.ts\";\nimport { chunkTextFallbackSearch, expandMixedTerms, expandDomainSynonyms } from \"./search.ts\";\nimport type {\n    IntentAnalysis, ClarifyOption, ClarifyResult,\n    SelectorPanel, SelectorItem, FilterAxis,\n} from \"./types.ts\";\n\n// â”€â”€â”€ ResolveContext: ìƒíƒœ ë³´ì¡´ + ì˜ì¡´ì„± ì£¼ì… â”€â”€â”€\n// Why: íŒŒë¼ë¯¸í„° íŒŒí¸í™” ë°©ì§€. í–¥í›„ í•„í„° ì¡°ê±´ ì¶”ê°€ ì‹œ í•¨ìˆ˜ ì„œëª… ë³€ê²½ ë¶ˆí•„ìš”\nexport interface ResolveContext {\n    analysis: IntentAnalysis;\n    sectionId?: string;\n    subSectionName?: string;       // sub_section ë“œë¦´ë‹¤ìš´ ìƒíƒœ ë³´ì¡´\n    preMatchedSections?: any[];    // searchPipeline ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì£¼ì… (DB ì´ì¤‘ ì¿¼ë¦¬ ë°©ì§€)\n}\n\n// â”€â”€â”€ ChunkMeta: graph_chunks ë©”íƒ€ë°ì´í„° â”€â”€â”€\nexport interface ChunkMeta {\n    department: string;\n    chapter: string;\n    title: string;\n}\n\n// â”€â”€â”€ ResolveResult: resolveSectionì˜ ì¶œë ¥ â”€â”€â”€\nexport interface ResolveResult {\n    level: 'multi_section' | 'single_section' | 'sub_section' | 'worktype_many' | 'worktype_few' | 'empty';\n    sections: any[];\n    workTypes: any[];\n    subSections?: Map<string, any[]>;   // sub_section ê·¸ë£¹ (drill-downìš©)\n    chunkMeta: Map<string, ChunkMeta>;  // source_section â†’ ë¶€ë¬¸/ì¥/ì ˆ\n    sectionPath?: string;               // ë‹¨ì¼ ì„¹ì…˜ì˜ ê²½ë¡œ ë¬¸ìì—´\n    sectionName?: string;               // ë‹¨ì¼ ì„¹ì…˜ì˜ ì´ë¦„\n    primarySectionId?: string;          // ì£¼ ì„¹ì…˜ ID\n    chunkTextResults: any[];            // ì „ëµ 4 chunk text ê²°ê³¼\n    sectionSourceSections: Set<string>; // ì „ëµ 1ì—ì„œ ì°¾ì€ source_section ì§‘í•©\n    childSections: any[];               // í•˜ìœ„ ì ˆ ëª©ë¡\n    subFilter?: string | null;          // sub_section í•„í„°\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// â”€â”€â”€ í—¬í¼: # ì ‘ë¯¸ì‚¬ ì œê±° â”€â”€â”€\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction displayCode(code: string | null | undefined): string {\n    return code ? code.replace(/#.*$/, '') : '';\n}\n\n// â”€â”€â”€ ë²”ìš© ë™ì‚¬ ëª©ë¡ (ì „ëµ 3 ë…ë¦½ê²€ìƒ‰ì—ì„œ ì œì™¸) â”€â”€â”€\nconst ACTION_VERBS = new Set([\n    \"ì œì‘\", \"ì„¤ì¹˜\", \"ì‹œê³µ\", \"ê³µì‚¬\", \"ìš´ë°˜\", \"ë³´ìˆ˜\", \"í•´ì²´\", \"ì¡°ë¦½\",\n    \"ì² ê±°\", \"ê°€ê³µ\", \"íƒ€ì„¤\", \"ì–‘ìƒ\", \"í¬ì„¤\", \"ë‹¤ì§\", \"ì ˆë‹¨\", \"ìš©ì ‘\",\n    \"ë„ì¥\", \"ë°°ê´€\", \"ë°°ì„ \", \"ì¸¡ëŸ‰\", \"ê²€ì‚¬\", \"ì¸ì–‘\", \"ì ì¬\",\n]);\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// resolveSection: DB íƒìƒ‰ â†’ ê³„ì¸µ íŒì • â†’ ResolveResult\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nexport async function resolveSection(ctx: ResolveContext): Promise<ResolveResult> {\n    const { analysis, sectionId, subSectionName, preMatchedSections } = ctx;\n    const { work_name, keywords } = analysis;\n    let searchTerms = work_name ? [work_name, ...keywords] : keywords;\n\n    // â”€â”€â”€ searchTerms[0] ì •ê·œí™” â”€â”€â”€\n    if (searchTerms.length > 0 && searchTerms[0].length > 0) {\n        const raw = searchTerms[0];\n        const koreanTokens = [...new Set(raw.match(/[ê°€-í£]{2,}/g) || [])];\n        if (koreanTokens.length > 0) {\n            searchTerms[0] = koreanTokens.join('');\n        }\n        if (searchTerms[0].length > 15 || !/[ê°€-í£]/.test(searchTerms[0])) {\n            const originalQuery = analysis.ambiguity_reason || work_name || '';\n            const fallbackTokens = [...new Set(originalQuery.match(/[ê°€-í£]{2,}/g) || [])];\n            if (fallbackTokens.length > 0) searchTerms[0] = fallbackTokens.join('');\n        }\n        console.log(`[resolveSection] searchTerms ì •ê·œí™”: \"${raw}\" â†’ \"${searchTerms[0]}\"`);\n    }\n\n    if (searchTerms.length === 0) {\n        return emptyResult();\n    }\n\n    // â•â•â• sectionId ê²½ë¡œ: í•´ë‹¹ ì„¹ì…˜ ë‚´ íƒìƒ‰ â•â•â•\n    if (sectionId) {\n        return await resolveBySectionId(sectionId, subSectionName, searchTerms);\n    }\n\n    // â•â•â• ê²€ìƒ‰ ê²½ë¡œ: 4ì „ëµ ì‹¤í–‰ â•â•â•\n    return await resolveBySearch(analysis, searchTerms, keywords, work_name, preMatchedSections);\n}\n\n// â”€â”€â”€ sectionId ê¸°ë°˜ íƒìƒ‰ (ê¸°ì¡´ Step 2) â”€â”€â”€\nasync function resolveBySectionId(\n    sectionId: string,\n    subSectionName?: string,\n    searchTerms: string[] = []\n): Promise<ResolveResult> {\n    // sub_section í•„í„° ì¶”ì¶œ: \"13-2-3:sub=2. TIGìš©ì ‘\" â†’ sectionId=13-2-3, subFilter=\"2. TIGìš©ì ‘\"\n    let actualSectionId = sectionId;\n    let subFilter: string | null = subSectionName || null;\n    if (sectionId.includes(':sub=')) {\n        const parts = sectionId.split(':sub=');\n        actualSectionId = parts[0];\n        subFilter = decodeURIComponent(parts[1]);\n    }\n\n    console.log(`[resolveSection] sectionId=${actualSectionId}, subFilter=${subFilter}`);\n\n    // graph_chunks ë©”íƒ€ë°ì´í„° ì¡°íšŒ\n    const { data: chunkData } = await supabase\n        .from(\"graph_chunks\")\n        .select(\"section_id, department, chapter, title, text\")\n        .eq(\"section_id\", actualSectionId)\n        .limit(1);\n\n    const chunk = (chunkData as any[])?.[0];\n    const sectionPath = chunk\n        ? `${chunk.department} > ${chunk.chapter} > ${chunk.title}`\n        : actualSectionId;\n    const chunkMeta = new Map<string, ChunkMeta>();\n    if (chunk) {\n        chunkMeta.set(actualSectionId, {\n            department: chunk.department || \"\",\n            chapter: chunk.chapter || \"\",\n            title: chunk.title || \"\",\n        });\n    }\n\n    // í•˜ìœ„ WorkType ì¡°íšŒ\n    const { data: exactWTs } = await supabase\n        .from(\"graph_entities\")\n        .select(\"id, name, type, source_section, properties\")\n        .eq(\"type\", \"WorkType\")\n        .eq(\"source_section\", actualSectionId)\n        .limit(200);\n\n    let workTypes = (exactWTs || []) as any[];\n    console.log(`[resolveSection] exact=${workTypes.length}ê°œ WorkType`);\n\n    // sub_section drill-down íŒì •\n    let subSections: Map<string, any[]> | undefined;\n    if (workTypes.length > 0 && !subFilter) {\n        const subMap = buildSubSectionMap(workTypes);\n        if (subMap.size >= 2) {\n            subSections = subMap;\n            return {\n                level: 'sub_section',\n                sections: [],\n                workTypes,\n                subSections,\n                chunkMeta,\n                sectionPath,\n                sectionName: chunk?.title || actualSectionId,\n                primarySectionId: actualSectionId,\n                chunkTextResults: [],\n                sectionSourceSections: new Set([actualSectionId]),\n                childSections: [],\n                subFilter: null,\n            };\n        }\n    }\n\n    // sub_section í•„í„° ì ìš©\n    if (subFilter && workTypes.length > 0) {\n        const beforeCount = workTypes.length;\n        workTypes = workTypes.filter((wt: any) => wt.properties?.sub_section === subFilter);\n        console.log(`[resolveSection] subFilter=\"${subFilter}\" â†’ ${beforeCount} â†’ ${workTypes.length}ê°œ`);\n    }\n\n    // WT 0ê±´ â†’ í•˜ìœ„ ì ˆ(children) íƒìƒ‰\n    let childSections: any[] = [];\n    if (workTypes.length === 0 && !subFilter) {\n        const baseSectionId = actualSectionId.includes('#') ? actualSectionId.split('#')[0] : actualSectionId;\n        const childPrefix = baseSectionId + '-';\n        const dept = chunk?.department || '';\n\n        console.log(`[resolveSection] WT 0ê±´ â†’ í•˜ìœ„ ì ˆ íƒìƒ‰ (prefix=${childPrefix})`);\n\n        const { data: childChunks } = await supabase\n            .from(\"graph_chunks\")\n            .select(\"section_id, title, department\")\n            .ilike(\"section_id\", `${childPrefix}%`)\n            .eq(\"department\", dept);\n\n        const uniqueChildren = new Map<string, any>();\n        (childChunks || []).forEach((c: any) => {\n            if (!uniqueChildren.has(c.section_id)) {\n                uniqueChildren.set(c.section_id, c);\n            }\n        });\n        childSections = Array.from(uniqueChildren.values());\n\n        if (childSections.length > 0) {\n            const childSectionIds = childSections.map(c => c.section_id);\n            const { data: childWTs } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, source_section, properties\")\n                .eq(\"type\", \"WorkType\")\n                .in(\"source_section\", childSectionIds)\n                .limit(50);\n            workTypes = (childWTs || []) as any[];\n        }\n    }\n\n    // ì´ë¦„ ì •ê·œí™” ê¸°ì¤€ ì¤‘ë³µ ì œê±° (í´ë¦° DBë¡œ ì¸í•´ ì‚­ì œë¨)\n\n    // WT 0ê±´: Note ìˆ˜ ì¡°íšŒí•˜ì—¬ level íŒì •\n    if (workTypes.length === 0 && childSections.length === 0) {\n        const { count: noteCount } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id\", { count: \"exact\", head: true })\n            .eq(\"type\", \"Note\")\n            .eq(\"source_section\", actualSectionId);\n\n        // emptyì´ì§€ë§Œ noteê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ workTypesì— noteCount ì •ë³´ë¥¼ metaë¡œ ì „ë‹¬\n        return {\n            level: 'empty',\n            sections: [],\n            workTypes: [],\n            chunkMeta,\n            sectionPath,\n            sectionName: chunk?.title || actualSectionId,\n            primarySectionId: actualSectionId,\n            chunkTextResults: [],\n            sectionSourceSections: new Set([actualSectionId]),\n            childSections: [],\n            subFilter,\n            // noteCountë¥¼ sections í•„ë“œë¡œ ì „ë‹¬ (ì„ì‹œ)\n            ...(noteCount ? { sections: [{ _noteCount: noteCount }] } : {}),\n        };\n    }\n\n    const level = workTypes.length > 3 ? 'worktype_many' : 'worktype_few';\n\n    return {\n        level,\n        sections: [],\n        workTypes,\n        chunkMeta,\n        sectionPath,\n        sectionName: chunk?.title || actualSectionId,\n        primarySectionId: actualSectionId,\n        chunkTextResults: [],\n        sectionSourceSections: new Set([actualSectionId]),\n        childSections,\n        subFilter,\n    };\n}\n\n// â”€â”€â”€ ê²€ìƒ‰ ì „ëµ ê¸°ë°˜ íƒìƒ‰ (ê¸°ì¡´ Step 1) â”€â”€â”€\nasync function resolveBySearch(\n    analysis: IntentAnalysis,\n    searchTerms: string[],\n    keywords: string[],\n    work_name: string | null,\n    preMatchedSections?: any[]\n): Promise<ResolveResult> {\n    const sectionSourceSections = new Set<string>();\n\n    // â”€â”€â”€ ì „ëµ 1: Section ë ˆë²¨ íƒìƒ‰ â”€â”€â”€\n    let effectiveSections: any[] = [];\n\n    if (preMatchedSections && preMatchedSections.length > 0) {\n        // âœ… preMatchedSections ì£¼ì…ë¨ â†’ DB ì´ì¤‘ ì¿¼ë¦¬ ë°©ì§€\n        effectiveSections = preMatchedSections;\n        console.log(`[resolveSection] ì „ëµ 1: preMatched ${effectiveSections.length}ê°œ ì‚¬ìš©`);\n    } else {\n        // ì „ëµ 1-A: Section ì´ë¦„ ILIKE (+ ë„ë©”ì¸ ë™ì˜ì–´)\n        const sectionPattern = \"%\" + searchTerms[0] + \"%\";\n        // ğŸ’¡ [Track B-1] ë„ë©”ì¸ ë™ì˜ì–´ë¡œ Section ê²€ìƒ‰ í™•ì¥ (raw work_name ì‚¬ìš©)\n        const synonymSrc1A = work_name ? [work_name, searchTerms[0]] : [searchTerms[0]];\n        const sectionSynonyms = expandDomainSynonyms([...new Set(synonymSrc1A)]);\n        const sectionOrClauses = [\n            `name.ilike.${sectionPattern}`,\n            ...sectionSynonyms.map(s => `name.ilike.%${s}%`),\n        ].join(\",\");\n        const { data: sections } = await supabase\n            .from(\"graph_entities\")\n            .select(\"id, name, type, source_section, properties\")\n            .eq(\"type\", \"Section\")\n            .or(sectionOrClauses)\n            .limit(10);\n\n        // ì „ëµ 1-B: í† í° ë¶„ë¦¬ ILIKE í´ë°±\n        let tokenFallbackSections: any[] = [];\n        if ((!sections || sections.length === 0) && searchTerms[0].length >= 4) {\n            let tokens = searchTerms[0].match(/[ê°€-í£]{2,}|[a-zA-Z]+/g) || [];\n            if (tokens.length === 1 && tokens[0].length >= 4) {\n                const word = tokens[0];\n                const halfLen = Math.ceil(word.length / 2);\n                tokens = [word.substring(0, halfLen), word.substring(halfLen)];\n            }\n            if (tokens.length >= 2) {\n                let query = supabase.from(\"graph_entities\")\n                    .select(\"id, name, type, source_section, properties\")\n                    .eq(\"type\", \"Section\");\n                for (const token of tokens) {\n                    query = query.ilike(\"name\", `%${token}%`);\n                }\n                const { data: tokenSections } = await query.limit(10);\n                if (tokenSections) tokenFallbackSections = tokenSections;\n                console.log(`[resolveSection] ì „ëµ 1-B: \"${tokens.join('\",\"')}\" â†’ ${tokenFallbackSections.length}ê±´`);\n            }\n        }\n        effectiveSections = (sections && sections.length > 0) ? sections : tokenFallbackSections;\n    }\n\n    // Sectionì˜ source_sectionìœ¼ë¡œ í•˜ìœ„ WorkType ì¡°íšŒ\n    let sectionChildWorkTypes: any[] = [];\n    if (effectiveSections.length > 0) {\n        const sourceSections = effectiveSections.map((s: any) => s.source_section).filter(Boolean);\n        sourceSections.forEach((ss: string) => sectionSourceSections.add(ss));\n        if (sourceSections.length > 0) {\n            const { data: childWTs } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, source_section, properties\")\n                .eq(\"type\", \"WorkType\")\n                .in(\"source_section\", sourceSections)\n                .limit(200);\n            if (childWTs) sectionChildWorkTypes = childWTs;\n            console.log(`[resolveSection] Section ${sourceSections.join(\",\")} í•˜ìœ„ WorkType ${childWTs?.length || 0}ê°œ`);\n        }\n    }\n\n    // ì „ëµ 2: WorkType ì§ì ‘ íƒìƒ‰\n    const safeWorkTerms = searchTerms.filter((t: string) => {\n        const isAllEng = /^[A-Za-z]+$/.test(t);\n        return t.length >= 2 && (!isAllEng || t.length >= 4);\n    });\n    const wTerms = safeWorkTerms.length > 0 ? safeWorkTerms : searchTerms.filter((t: string) => t.length >= 2);\n    // Why: \"PEê´€\" â†’ \"%PEê´€%\" ë§¤ì¹­ ì‹¤íŒ¨ ëŒ€ë¹„, ì˜í•œ í˜¼í•©ì–´ ì™„í™” íŒ¨í„´(\"%PE%ê´€%\")ë„ ì¶”ê°€\n    const mixedExp = expandMixedTerms(wTerms);\n    // ğŸ’¡ [Track B-1] ë„ë©”ì¸ ë™ì˜ì–´ë¡œ WorkType ê²€ìƒ‰ í™•ì¥\n    // Why: searchTerms[0]ì´ í•œê¸€ ì •ê·œí™”(\"PEê´€\"â†’\"ê´€\")ë˜ì–´ ì›ë³¸ì´ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ\n    //      raw work_nameë„ ë™ì˜ì–´ í™•ì¥ ì†ŒìŠ¤ì— í¬í•¨\n    const synonymSource = work_name ? [...new Set([work_name, ...wTerms])] : wTerms;\n    const domainExp = expandDomainSynonyms(synonymSource);\n    console.log(`[resolveSection] ì „ëµ 2: wTerms=${JSON.stringify(wTerms)}, synonymSource=${JSON.stringify(synonymSource)}, domainExp=${JSON.stringify(domainExp)}`);\n    const workOrClauses = [\n        ...wTerms.map((t: string) => `name.ilike.%${t}%`),\n        ...mixedExp.map(p => `name.ilike.${p}`),\n        ...domainExp.map(s => `name.ilike.%${s}%`),\n    ].join(\",\");\n    const { data: workTypes } = await supabase\n        .from(\"graph_entities\")\n        .select(\"id, name, type, source_section, properties\")\n        .eq(\"type\", \"WorkType\")\n        .or(workOrClauses)\n        .limit(200);\n\n    // ì „ëµ 3: í‚¤ì›Œë“œë³„ ë…ë¦½ ê²€ìƒ‰ (ë²”ìš© ë™ì‚¬ ì œì™¸)\n    let extraWorkTypes: any[] = [];\n    for (const kw of keywords) {\n        if (kw.length >= 2 && !ACTION_VERBS.has(kw)) {\n            const { data: kwResults } = await supabase\n                .from(\"graph_entities\")\n                .select(\"id, name, type, source_section, properties\")\n                .in(\"type\", [\"WorkType\", \"Section\"])\n                .or(`name.ilike.%${kw}%,properties->>korean_alias.ilike.%${kw}%`)\n                .limit(10);\n            if (kwResults) extraWorkTypes = extraWorkTypes.concat(kwResults);\n        }\n    }\n\n    // ì „ëµ 4: chunk ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰\n    let chunkTextResults: any[] = [];\n    const prelimResults = [...effectiveSections, ...sectionChildWorkTypes, ...(workTypes || []), ...extraWorkTypes];\n    const kwTokens = keywords.length > 0\n        ? keywords\n        : (work_name ? work_name.split(/\\s+/).filter((w: string) => w.length >= 2) : []);\n    const compoundTerms: string[] = [];\n    for (let i = 0; i < kwTokens.length - 1; i++) {\n        compoundTerms.push(kwTokens[i] + kwTokens[i + 1]);\n    }\n    if (kwTokens.length >= 2) {\n        compoundTerms.push(kwTokens.join(''));\n    }\n    const compoundMatchFound = compoundTerms.length > 0 && prelimResults.some(\n        (r: any) => compoundTerms.some(ct => r.name && r.name.includes(ct))\n    );\n\n    if (compoundTerms.length > 0 && !compoundMatchFound) {\n        console.log(`[resolveSection] ì „ëµ 4: chunk text fallback (ë³µí•©ì–´ \"${compoundTerms.join(',')}\" ë¯¸ë§¤ì¹­)`);\n        const chunkQuestion = searchTerms.join(' ');\n        const chunkFallback = await chunkTextFallbackSearch(chunkQuestion);\n        if (chunkFallback.length > 0) {\n            chunkTextResults = chunkFallback.map(e => ({\n                id: e.id, name: e.name, type: e.type,\n                source_section: e.source_section,\n                properties: e.properties,\n            }));\n        }\n    }\n\n    // â”€â”€â”€ ê²°ê³¼ ë³‘í•© + ì¤‘ë³µ ì œê±° â”€â”€â”€\n    const allResults = [...effectiveSections, ...sectionChildWorkTypes, ...(workTypes || []), ...extraWorkTypes, ...chunkTextResults];\n    const uniqueResults = Array.from(\n        new Map(allResults.map(r => [r.id, r])).values()\n    );\n\n    if (uniqueResults.length === 0) {\n        return emptyResult();\n    }\n\n    // â”€â”€â”€ graph_chunks ë©”íƒ€ë°ì´í„° ì¡°íšŒ â”€â”€â”€\n    const allSourceSections = [...new Set(uniqueResults.map(r => r.source_section).filter(Boolean))];\n    const chunkMeta = new Map<string, ChunkMeta>();\n    if (allSourceSections.length > 0) {\n        const { data: chunks } = await supabase\n            .from(\"graph_chunks\")\n            .select(\"section_id, department, chapter, title\")\n            .in(\"section_id\", allSourceSections);\n        if (chunks) {\n            for (const c of chunks as any[]) {\n                chunkMeta.set(c.section_id, {\n                    department: c.department || \"\",\n                    chapter: c.chapter || \"\",\n                    title: c.title || \"\",\n                });\n            }\n        }\n    }\n\n    // â”€â”€â”€ ê´€ë ¨ì„± ì ìˆ˜ ì‚°ì¶œ â”€â”€â”€\n    const scoredResults = uniqueResults.map(r => {\n        let score = 0;\n        const name = r.name || \"\";\n        const nameLC = name.toLowerCase();\n\n        if (r.type === \"WorkType\" && sectionSourceSections.has(r.source_section)) score += 50;\n        if (work_name && nameLC.includes(work_name.toLowerCase())) score += 30;\n        for (const kw of keywords) {\n            if (nameLC.includes(kw.toLowerCase())) score += 10;\n        }\n        if (r.type === \"Section\") score -= 5;\n\n        return { ...r, _score: score };\n    });\n    scoredResults.sort((a, b) => b._score - a._score);\n\n    console.log(`[resolveSection] ê´€ë ¨ì„± ìƒìœ„:`,\n        scoredResults.slice(0, 5).map(r => `${r.name}(${r._score})`).join(\", \"));\n\n    // â”€â”€â”€ ê³„ì¸µ íŒì • â”€â”€â”€\n    const matchedSections = scoredResults.filter(r => r.type === \"Section\");\n    const matchedWorkTypes = scoredResults.filter(r => r.type === \"WorkType\");\n\n    // Phase 3-C: chunk text fallback WorkType ìš°ì„ \n    const chunkWorkTypes = chunkTextResults.filter((r: any) => r.type === 'WorkType');\n    if (chunkWorkTypes.length > 0) {\n        // sub_section drill-down ì‹œë„\n        const allWTsForDrill = sectionChildWorkTypes.length > 0 ? sectionChildWorkTypes : chunkWorkTypes;\n        const drillSectionId = matchedSections[0]?.source_section || chunkWorkTypes[0]?.source_section || '';\n        const subMap = buildSubSectionMap(allWTsForDrill);\n\n        const drillSectionName = matchedSections[0]?.name || work_name || searchTerms[0];\n        const drillMeta = drillSectionId ? chunkMeta.get(drillSectionId) : null;\n        const drillSectionPath = drillMeta\n            ? `${drillMeta.department} > ${drillMeta.chapter} > ${drillMeta.title}`\n            : drillSectionName;\n\n        if (subMap.size >= 2) {\n            return {\n                level: 'sub_section',\n                sections: matchedSections,\n                workTypes: allWTsForDrill,\n                subSections: subMap,\n                chunkMeta,\n                sectionPath: drillSectionPath,\n                sectionName: drillSectionName,\n                primarySectionId: drillSectionId,\n                chunkTextResults,\n                sectionSourceSections,\n                childSections: [],\n            };\n        }\n\n        // sub_section ì—†ìœ¼ë©´ chunk WorkTypeì„ ê·¸ëŒ€ë¡œ ë°˜í™˜\n        return {\n            level: 'worktype_few',\n            sections: matchedSections,\n            workTypes: chunkWorkTypes,\n            chunkMeta,\n            sectionPath: drillSectionPath,\n            sectionName: drillSectionName,\n            primarySectionId: drillSectionId,\n            chunkTextResults,\n            sectionSourceSections,\n            childSections: [],\n        };\n    }\n\n    // ë³µìˆ˜ ì„¹ì…˜ íŒì • (ğŸ’¡ [Track B-1] WorkTypeì˜ source_sectionë„ ê³ ë ¤)\n    const sectionOnlyIds = [...new Set(matchedSections.map(s => s.source_section).filter(Boolean))];\n    const workTypeOnlyIds = [...new Set(matchedWorkTypes.map(w => w.source_section).filter(Boolean))];\n    const allUniqueSectionIds = [...new Set([...sectionOnlyIds, ...workTypeOnlyIds])];\n    if (allUniqueSectionIds.length > 1) {\n        return {\n            level: 'multi_section',\n            sections: matchedSections,\n            workTypes: matchedWorkTypes,\n            chunkMeta,\n            chunkTextResults,\n            sectionSourceSections,\n            childSections: [],\n        };\n    }\n\n    // ë‹¨ì¼ ì„¹ì…˜ + WorkType ë§ìŒ\n    if (matchedWorkTypes.length > 3) {\n        const sectionNameA = matchedSections[0]?.name || work_name || searchTerms[0];\n        const sectionMetaA = matchedSections[0] ? chunkMeta.get(matchedSections[0].source_section) : null;\n        const fullSectionPathA = sectionMetaA\n            ? `${sectionMetaA.department} > ${sectionMetaA.chapter} > ${sectionMetaA.title}`\n            : sectionNameA;\n        const primarySectionIdA = matchedSections[0]?.source_section || matchedWorkTypes[0]?.source_section || '';\n\n        // sub_section drill-down ì‹œë„\n        const subMap = buildSubSectionMap(matchedWorkTypes);\n        if (subMap.size >= 2) {\n            return {\n                level: 'sub_section',\n                sections: matchedSections,\n                workTypes: matchedWorkTypes,\n                subSections: subMap,\n                chunkMeta,\n                sectionPath: fullSectionPathA,\n                sectionName: sectionNameA,\n                primarySectionId: primarySectionIdA,\n                chunkTextResults,\n                sectionSourceSections,\n                childSections: [],\n            };\n        }\n\n        return {\n            level: 'worktype_many',\n            sections: matchedSections,\n            workTypes: matchedWorkTypes,\n            chunkMeta,\n            sectionPath: fullSectionPathA,\n            sectionName: sectionNameA,\n            primarySectionId: primarySectionIdA,\n            chunkTextResults,\n            sectionSourceSections,\n            childSections: [],\n        };\n    }\n\n    // Section 1ê°œ + WorkType ì†Œìˆ˜\n    if (matchedSections.length === 1 && matchedWorkTypes.length > 0) {\n        const section = matchedSections[0];\n        const meta = chunkMeta.get(section.source_section);\n        const sectionPath = meta\n            ? `${meta.department} > ${meta.chapter} > ${meta.title}`\n            : section.name;\n\n        return {\n            level: 'worktype_few',\n            sections: matchedSections,\n            workTypes: matchedWorkTypes,\n            chunkMeta,\n            sectionPath,\n            sectionName: section.name,\n            primarySectionId: section.source_section || matchedWorkTypes[0]?.source_section || '',\n            chunkTextResults,\n            sectionSourceSections,\n            childSections: [],\n        };\n    }\n\n    // ì†Œìˆ˜ ê²°ê³¼ (Section + WorkType í˜¼í•©)\n    return {\n        level: 'worktype_few',\n        sections: matchedSections,\n        workTypes: scoredResults, // ì „ì²´ scored ê²°ê³¼\n        chunkMeta,\n        chunkTextResults,\n        sectionSourceSections,\n        childSections: [],\n    };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// presentClarify: ResolveResult â†’ ClarifyResult (UI ë³€í™˜)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nexport function presentClarify(\n    resolved: ResolveResult,\n    searchTerms: string[],\n    workName: string | null\n): ClarifyResult {\n    const { level, sections, workTypes, subSections, chunkMeta,\n        sectionPath, sectionName, primarySectionId,\n        childSections, subFilter } = resolved;\n\n    // â”€â”€â”€ label ìƒì„± í—¬í¼ â”€â”€â”€\n    const makeLabel = (r: any): string => {\n        const meta = chunkMeta.get(r.source_section);\n        if (meta && meta.department) {\n            const dept = meta.department.replace(/ë¶€ë¬¸$/, \"\");\n            const secTag = r.source_section ? ` (${displayCode(r.source_section)})` : \"\";\n            return `[${dept}${secTag}] ${r.name}`;\n        }\n        const sectionTag = r.source_section ? `[${displayCode(r.source_section)}]` : \"\";\n        return `${sectionTag} ${r.name}`;\n    };\n\n    // â”€â”€â”€ empty â”€â”€â”€\n    if (level === 'empty') {\n        const noteCount = sections[0]?._noteCount || 0;\n        const options: ClarifyOption[] = [{\n            label: `ğŸ“‹ ${sectionName || primarySectionId} ì „ì²´ ë‚´ìš© ë³´ê¸°`,\n            query: `${sectionName || primarySectionId} ì „ì²´ í’ˆì…ˆ`,\n            section_id: primarySectionId,\n            option_type: \"full_view\",\n        }];\n\n        const message = noteCount > 0\n            ? `**${sectionPath}** í’ˆì…ˆì€ ê°œë³„ ì‘ì—…ì´ ë¶„ë¥˜ë˜ì–´ ìˆì§€ ì•Šê³ , **ê¸°ì¤€ ë° ì£¼ì˜ì‚¬í•­ ${noteCount}ê±´**ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\nì•„ë˜ \"ì „ì²´ ë‚´ìš© ë³´ê¸°\"ë¥¼ í†µí•´ í™•ì¸í•´ ì£¼ì„¸ìš”.`\n            : `**${sectionPath}** í’ˆì…ˆì˜ ìƒì„¸ ì‘ì—…ì´ ê°œë³„ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\\nì•„ë˜ \"ì „ì²´ ë‚´ìš© ë³´ê¸°\" ë²„íŠ¼ìœ¼ë¡œ í•´ë‹¹ ì ˆì˜ í’ˆì…ˆ ë°ì´í„°ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.`;\n\n        return { message, options };\n    }\n\n    // â”€â”€â”€ sub_section drill-down â”€â”€â”€\n    if (level === 'sub_section' && subSections) {\n        const options: ClarifyOption[] = [];\n        const prefix = sectionName || workName || searchTerms[0];\n\n        options.push({\n            label: `ğŸ“‹ ${sectionName || primarySectionId} ì „ì²´ ë‚´ìš© ë³´ê¸°`,\n            query: `${prefix} ì „ì²´ í’ˆì…ˆ`,\n            section_id: primarySectionId,\n            option_type: \"full_view\",\n        });\n\n        // sub_sectionë³„ ì˜µì…˜ (sub_section_no ìˆœ ì •ë ¬)\n        const sorted = [...subSections.entries()].sort((a, b) => {\n            const noA = a[1][0]?.properties?.sub_section_no || 99;\n            const noB = b[1][0]?.properties?.sub_section_no || 99;\n            return Number(noA) - Number(noB);\n        });\n\n        for (const [subName, subWTs] of sorted) {\n            options.push({\n                label: `ğŸ“‚ ${subName} (${subWTs.length}ê±´)`,\n                query: `${prefix} ${subName} í’ˆì…ˆ`,\n                section_id: `${primarySectionId}:sub=${encodeURIComponent(subName)}`,\n                option_type: \"section\" as any,\n            });\n        }\n\n        return {\n            message: `**${sectionPath}** í’ˆì…ˆì—ëŠ” ${subSections.size}ê°œ ë¶„ë¥˜(ì´ ${workTypes.length}ê°œ ì‘ì—…)ê°€ ìˆìŠµë‹ˆë‹¤.\\në¶„ë¥˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.`,\n            options,\n        };\n    }\n\n    // â”€â”€â”€ multi_section â”€â”€â”€\n    if (level === 'multi_section') {\n        // ğŸ’¡ [Track B-1] Section ì—”í‹°í‹° + WorkTypeì˜ source_section ë³‘í•©\n        const sectionSrcSet = new Set(sections.map(s => s.source_section).filter(Boolean));\n        const options: ClarifyOption[] = sections.slice(0, 10).map(s => {\n            const meta = chunkMeta.get(s.source_section);\n            const secTag = s.source_section ? ` (${displayCode(s.source_section)})` : \"\";\n            const label = meta\n                ? `${meta.department} > ${meta.chapter} > ${meta.title}${secTag}`\n                : `[${displayCode(s.source_section)}] ${s.name}`;\n            return {\n                label,\n                query: `${s.name} í’ˆì…ˆ`,\n                source_section: s.source_section,\n                section_id: s.source_section,\n                option_type: 'section' as const,\n            };\n        });\n\n        // WorkTypeì˜ source_section ì¤‘ Sectionì— ì—†ëŠ” ê²ƒë“¤ë„ optionìœ¼ë¡œ ì¶”ê°€\n        const wtBySrc = new Map<string, any>();\n        for (const wt of workTypes) {\n            if (wt.source_section && !sectionSrcSet.has(wt.source_section) && !wtBySrc.has(wt.source_section)) {\n                wtBySrc.set(wt.source_section, wt);\n            }\n        }\n        for (const [srcSec, wt] of wtBySrc) {\n            const meta = chunkMeta.get(srcSec);\n            const secTag = ` (${displayCode(srcSec)})`;\n            const label = meta\n                ? `${meta.department} > ${meta.chapter} > ${meta.title}${secTag}`\n                : `[${displayCode(srcSec)}] ${wt.name}`;\n            options.push({\n                label,\n                query: `${meta?.title || wt.name} í’ˆì…ˆ`,\n                source_section: srcSec,\n                section_id: srcSec,\n                option_type: 'section' as const,\n            });\n        }\n\n        const allUniqueIds = [...new Set([...sections.map(s => s.source_section), ...workTypes.map(w => w.source_section)].filter(Boolean))];\n        const selector = buildSelectorPanel(options, searchTerms[0]);\n        return {\n            message: `\"${searchTerms.join(\" \")}\" ê´€ë ¨ í’ˆì…ˆì´ **${allUniqueIds.length}ê°œ ë¶„ì•¼**ì— ìˆìŠµë‹ˆë‹¤.\\nì–´ë–¤ ë¶„ì•¼ì˜ í’ˆì…ˆì„ ì°¾ìœ¼ì‹œë‚˜ìš”?`,\n            options,\n            selector,\n        };\n    }\n\n    // â”€â”€â”€ sectionId ê²½ë¡œ: worktype_many / worktype_few â”€â”€â”€\n    if (primarySectionId && childSections.length >= 0) {\n        const options: ClarifyOption[] = [];\n\n        // \"ì „ì²´ ë‚´ìš© ë³´ê¸°\" ì˜µì…˜\n        if (primarySectionId) {\n            options.push({\n                label: `ğŸ“‹ ${sectionName || primarySectionId}${subFilter ? ` > ${subFilter}` : ''} ì „ì²´ ë‚´ìš© ë³´ê¸°`,\n                query: `${sectionName || primarySectionId} ì „ì²´ í’ˆì…ˆ`,\n                section_id: primarySectionId,\n                option_type: \"full_view\",\n            });\n        }\n\n        if (childSections.length > 0 && workTypes.length > 10) {\n            // í•˜ìœ„ ì ˆ ë‹¨ìœ„ ì˜µì…˜\n            for (const child of childSections) {\n                options.push({\n                    label: `ğŸ“‚ ${child.title}`,\n                    query: `${child.title} í’ˆì…ˆ`,\n                    section_id: child.section_id,\n                    option_type: \"section\" as any,\n                });\n            }\n        } else {\n            // ê°œë³„ WorkType ì˜µì…˜\n            for (const wt of workTypes) {\n                if (options.find(o => o.entity_id === wt.id)) continue;\n                options.push({\n                    label: (level === 'worktype_many' || !sections.length) ? makeLabel(wt) : wt.name,\n                    query: `${wt.name} í’ˆì…ˆ`,\n                    entity_id: wt.id,\n                    source_section: wt.source_section,\n                    option_type: (wt.type === 'Section' ? 'section' : 'worktype') as 'section' | 'worktype',\n                    ...(wt.type === 'Section' ? { section_id: wt.source_section } : {}),\n                });\n            }\n        }\n\n        // ë©”ì‹œì§€ ë¶„ê¸°\n        let message: string;\n        if (subFilter) {\n            message = `**${sectionPath} > ${subFilter}** í’ˆì…ˆì€ ${workTypes.length}ê°œ ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\nì–´ë–¤ ì‘ì—…ì˜ í’ˆì…ˆì„ ì°¾ìœ¼ì‹œë‚˜ìš”?`;\n        } else if (level === 'worktype_many') {\n            message = `**${sectionPath || sectionName}** í’ˆì…ˆì€ ${workTypes.length}ê°œ ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\nì–´ë–¤ ì‘ì—…ì˜ í’ˆì…ˆì„ ì°¾ìœ¼ì‹œë‚˜ìš”?`;\n        } else if (sections.length === 1 && workTypes.length > 0) {\n            message = `**${sectionPath || sectionName}** í•˜ìœ„ ${workTypes.length}ê°œ ì‘ì—…ì´ ìˆìŠµë‹ˆë‹¤.\\nì–´ë–¤ ì‘ì—…ì˜ í’ˆì…ˆì„ ì°¾ìœ¼ì‹œë‚˜ìš”?`;\n        } else if (workTypes.length > 0) {\n            message = `ë‹¤ìŒ ì¤‘ ì°¾ìœ¼ì‹œëŠ” í•­ëª©ì´ ìˆë‚˜ìš”?`;\n        } else {\n            message = `\"${searchTerms.join(\" \")}\"ì™€ ê´€ë ¨ëœ í’ˆì…ˆ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\\nì •í™•í•œ ê³µì¢…ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.`;\n        }\n\n        const selector = buildSelectorPanel(options, workName || searchTerms[0]);\n        return {\n            message,\n            options,\n            ...(selector ? { selector } : {}),\n        };\n    }\n\n    // â”€â”€â”€ ìµœì¢… í´ë°± â”€â”€â”€\n    return {\n        message: `\"${searchTerms.join(\" \")}\"ì™€ ê´€ë ¨ëœ í’ˆì…ˆ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\\nì •í™•í•œ ê³µì¢…ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.`,\n        options: [],\n    };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction emptyResult(): ResolveResult {\n    return {\n        level: 'empty',\n        sections: [],\n        workTypes: [],\n        chunkMeta: new Map(),\n        chunkTextResults: [],\n        sectionSourceSections: new Set(),\n        childSections: [],\n    };\n}\n\n// sub_sectionë³„ ê·¸ë£¹ ìƒì„±\nfunction buildSubSectionMap(workTypes: any[]): Map<string, any[]> {\n    const subMap = new Map<string, any[]>();\n    for (const wt of workTypes) {\n        const sub = wt.properties?.sub_section || null;\n        if (sub) {\n            if (!subMap.has(sub)) subMap.set(sub, []);\n            subMap.get(sub)!.push(wt);\n        }\n    }\n    return subMap;\n}\n\n\n// â”€â”€â”€ Selector Panel ê´€ë ¨ í•¨ìˆ˜ (clarify.tsì—ì„œ ì´ë™) â”€â”€â”€\n\nfunction parseWorkTypeName(name: string): Record<string, string> {\n    // 1. ê°•ê´€ (ì˜¥ì™¸ ìš©ì ‘ì‹) í˜•ì‹ì„ ì‹ë³„ (ComplexTablePipeline ìš©)\n    const mComplex = name.match(/^([^()]+)\\s*\\(([^)\\s]+)\\s+([^)\\s]+)\\)$/);\n    if (mComplex) {\n        return {\n            'ì¬ì§ˆ': mComplex[1].trim(),\n            'ë°°ê´€ì¥ì†Œ': mComplex[2].trim(),\n            'ì ‘í•©ë°©ì‹': mComplex[3].trim()\n        };\n    }\n\n    // 2. (XX, SCH YY) í˜•ì‹ ì‹ë³„\n    const m = name.match(/\\((\\d+),\\s*SCH\\s*([\\d~]+)\\)$/);\n    if (m) return { diameter: m[1], sch: m[2] };\n\n    // 3. (A, B) í˜•ì‹\n    const m2 = name.match(/\\(([^,]+),\\s*(.+)\\)$/);\n    if (m2) return { spec1: m2[1].trim(), spec2: m2[2].trim() };\n\n    // 4. (A) ë‹¨ì¼ í˜•ì‹\n    const m3 = name.match(/\\(([^)]+)\\)$/);\n    if (m3) return { spec1: m3[1].trim() };\n\n    // 5. ì–¸ë”ìŠ¤ì½”ì–´(_) ë¡œ êµ¬ë¶„ëœ ì„œë¸Œíƒ€ì…\n    const parts = name.split('_');\n    if (parts.length >= 2) return { subtype: parts.slice(1).join('_') };\n\n    return {};\n}\n\nfunction extractFilterAxes(items: SelectorItem[]): FilterAxis[] {\n    const axisMap = new Map<string, Set<string>>();\n    for (const item of items) {\n        for (const [key, val] of Object.entries(item.specs)) {\n            if (!axisMap.has(key)) axisMap.set(key, new Set());\n            axisMap.get(key)!.add(val);\n        }\n    }\n\n    function extractNumber(s: string): number {\n        const m = s.match(/[\\d.]+/);\n        return m ? parseFloat(m[0]) : NaN;\n    }\n\n    function normalizeValues(values: Set<string>): { normalized: string[]; unit: string } {\n        const arr = [...values];\n        const unitMatch = arr[0]?.match(/[a-zA-Z/Â²]+$/);\n        const detectedUnit = unitMatch ? unitMatch[0] : '';\n        const allSameUnit = detectedUnit && arr.every(v => {\n            const m = v.match(/[a-zA-Z/Â²]+$/);\n            return m && m[0] === detectedUnit;\n        });\n        const hasUnit = arr.some(v => /[a-zA-Z/Â²]+$/.test(v));\n        const noUnit = arr.some(v => /^\\d+\\.?\\d*$/.test(v));\n\n        if (hasUnit && noUnit && detectedUnit) {\n            const fixed = arr.map(v => /^\\d+\\.?\\d*$/.test(v) ? `${v}${detectedUnit}` : v);\n            const sorted = fixed.sort((a, b) => {\n                const na = extractNumber(a), nb = extractNumber(b);\n                return (!isNaN(na) && !isNaN(nb)) ? na - nb : a.localeCompare(b, 'ko');\n            });\n            return { normalized: sorted, unit: detectedUnit };\n        }\n        const sorted = arr.sort((a, b) => {\n            const na = extractNumber(a), nb = extractNumber(b);\n            return (!isNaN(na) && !isNaN(nb)) ? na - nb : a.localeCompare(b, 'ko');\n        });\n        return { normalized: sorted, unit: allSameUnit ? detectedUnit : '' };\n    }\n\n    function inferAxisLabel(key: string, values: Set<string>): string {\n        const fixed: Record<string, string> = { diameter: 'í˜¸ì¹­ê²½(mm)', sch: 'SCH', subtype: 'ìœ í˜•' };\n        if (fixed[key]) return fixed[key];\n        const sample = [...values].find(v => v.length > 0) || '';\n        if (/^\\d+\\s*mm$/i.test(sample)) return 'êµ¬ê²½(mm)';\n        if (/kg\\/cm[Â²2]?$/i.test(sample)) return 'ì••ë ¥(kg/cmÂ²)';\n        if (/^\\d+\\s*R?T$/i.test(sample)) return 'ìš©ëŸ‰(RT)';\n        if (/^\\d+\\s*HP$/i.test(sample)) return 'ë§ˆë ¥(HP)';\n        if (/^\\d+\\s*kW$/i.test(sample)) return 'ì¶œë ¥(kW)';\n        if (/^SCH/i.test(sample)) return 'SCH';\n        if (/^\\d+$/.test(sample)) return 'í˜¸ì¹­ê²½';\n        return key === 'spec1' ? 'ê·œê²©1' : key === 'spec2' ? 'ê·œê²©2' : key;\n    }\n\n    const axes: FilterAxis[] = [];\n    for (const [key, vals] of axisMap) {\n        if (vals.size > 1) {\n            const { normalized } = normalizeValues(vals);\n            axes.push({ key, label: inferAxisLabel(key, vals), values: normalized });\n        }\n    }\n    return axes;\n}\n\nexport function buildSelectorPanel(\n    options: ClarifyOption[],\n    workName: string,\n    forceSelector: boolean = false\n): SelectorPanel | undefined {\n    if (!forceSelector && options.length <= 6) return undefined;\n\n    const selectorItems: SelectorItem[] = options\n        .filter(o => (o.option_type === 'worktype' || o.option_type === 'section') && (o.entity_id || o.section_id))\n        .map(o => ({\n            label: o.label,\n            query: o.query,\n            entity_id: o.entity_id || o.section_id,\n            source_section: o.source_section,\n            option_type: o.option_type,\n            specs: parseWorkTypeName(o.label),\n        }));\n\n    if (!forceSelector && selectorItems.length < 6) return undefined;\n\n    selectorItems.sort((a, b) => {\n        const numA = parseInt((a.label.match(/\\d+/) || ['0'])[0], 10);\n        const numB = parseInt((b.label.match(/\\d+/) || ['0'])[0], 10);\n        if (numA !== numB) return numA - numB;\n        return a.label.localeCompare(b.label, 'ko');\n    });\n\n    const filters = extractFilterAxes(selectorItems);\n\n    return {\n        title: `${workName} â€” ê·œê²© ì„ íƒ`,\n        filters,\n        items: selectorItems,\n        original_query: workName,\n    };\n}\n"}, {"name": "seed_13_1_1.ts", "content": "import { supabase } from \"./config.ts\";\n\nconst data = JSON.parse(Deno.readTextFileSync(\"../pipeline/scripts/records_13_1_1.json\"));\n\nasync function seed() {\n    console.log(`Starting insertion of ${data.length} records...`);\n\n    // Batch upsert using Supabase\n    const batchSize = 100;\n    for (let i = 0; i < data.length; i += batchSize) {\n        const batch = data.slice(i, i + batchSize);\n        const { error } = await supabase.from(\"complex_table_specs\").upsert(batch, {\n            onConflict: \"section_code, material, spec_mm, thickness_mm, pipe_location, joint_type, job_name\"\n        });\n\n        if (error) {\n            console.error(`Error inserting batch ${i / batchSize + 1}:`, error);\n        } else {\n            console.log(`Successfully inserted batch ${i / batchSize + 1}`);\n        }\n    }\n    console.log(\"Seed complete.\");\n}\n\nseed();\n"}]